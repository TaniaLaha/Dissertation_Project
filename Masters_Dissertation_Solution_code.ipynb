{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABZhA936C-Wm"
      },
      "source": [
        "### Extraction of title from pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeFFkIcuC-Wo"
      },
      "outputs": [],
      "source": [
        "# importing necessary libraries and packages\n",
        "import fitz\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbTCiKO3C-Wp"
      },
      "outputs": [],
      "source": [
        "# Input pdf path\n",
        "pdf_path = '1805.06130.pdf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP8gxDiw2Rjp"
      },
      "outputs": [],
      "source": [
        "def extract_title(pdf_file):\n",
        "    with open(pdf_file, 'rb') as pdf_file_obj:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file_obj)\n",
        "\n",
        "        # Attempt to extract the title from the first line of the text\n",
        "        pdf_text = pdf_reader.pages[0].extract_text()\n",
        "        line = pdf_text.split('\\n')[:2]\n",
        "        first_line = ' '.join(line).strip()\n",
        "\n",
        "        # If the first line is not empty, use it as the title\n",
        "        if first_line:\n",
        "            pdf_title = first_line\n",
        "        elif pdf_title == '':\n",
        "            # If the first line is empty, use the PDF file name\n",
        "            pdf_title = pdf_file.split('/')[-1]\n",
        "        else:\n",
        "            document_info = pdf_reader.metadata\n",
        "            pdf_title = document_info.get('/Title')\n",
        "\n",
        "        return pdf_title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En2wq8sjC-Wq"
      },
      "outputs": [],
      "source": [
        "title = extract_title(pdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztV4VWr7C-Wq",
        "outputId": "2669a5ce-361c-447a-81ab-b1b0262f54e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Towards Robust Neural Machine Translation Yong Cheng?, Zhaopeng Tu?, Fandong Meng?, Junjie Zhai?and Yang Liuy',\n",
              " str)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "title, type(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ggR3NRlC-Wr"
      },
      "outputs": [],
      "source": [
        "# Getting the details of fontname and fontsize attribute for each line within pdfs\n",
        "\n",
        "import fitz\n",
        "\n",
        "def scrape(filePath):\n",
        "    results = [] # list of tuples that store the information as (text, font size, font name)\n",
        "    pdf = fitz.open(filePath) # filePath is a string that contains the path to the pdf\n",
        "    for page in pdf:\n",
        "        dict = page.get_text(\"dict\")\n",
        "        blocks = dict[\"blocks\"]\n",
        "        for block in blocks:\n",
        "            if \"lines\" in block.keys():\n",
        "                spans = block['lines']\n",
        "                for span in spans:\n",
        "                    data = span['spans']\n",
        "                    for lines in data:\n",
        "                            results.append((lines['text'], lines['size'], lines['font']))\n",
        "                            # lines['text'] -> string, lines['size'] -> font size, lines['font'] -> font name\n",
        "    pdf.close()\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf72jOTEC-Wr",
        "outputId": "44ece68a-8682-419f-c754-168f138590d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Towards Robust Neural Machine Translation',\n",
              "  14.346199989318848,\n",
              "  'NimbusRomNo9L-Medi'),\n",
              " ('Yong Cheng', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('⋆', 7.970099925994873, 'CMMI8'),\n",
              " (', Zhaopeng Tu', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('⋆', 7.970099925994873, 'CMMI8'),\n",
              " (', Fandong Meng', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('⋆', 7.970099925994873, 'CMMI8'),\n",
              " (', Junjie Zhai', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('⋆', 7.970099925994873, 'CMMI8'),\n",
              " (' ', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('and Yang Liu', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('†', 7.970099925994873, 'CMSY8'),\n",
              " ('⋆', 7.970099925994873, 'CMMI8'),\n",
              " ('Tencent AI Lab, China', 11.9552001953125, 'NimbusRomNo9L-Regu'),\n",
              " ('†', 7.970099925994873, 'CMSY8'),\n",
              " ('State Key Laboratory of Intelligent Technology and Systems',\n",
              "  11.9552001953125,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('Beijing National Research Center for Information Science and Technology',\n",
              "  11.9552001953125,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('Department of Computer Science and Technology, Tsinghua University, Beijing, China',\n",
              "  11.9552001953125,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('Beijing Advanced Innovation Center for Language Resources',\n",
              "  11.9552001953125,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('chengyong3001@gmail.com', 11.9552001953125, 'NimbusMonL-Regu'),\n",
              " ('{', 11.9552001953125, 'CMSY10'),\n",
              " ('zptu, fandongmeng, jasonzhai', 11.9552001953125, 'NimbusMonL-Regu'),\n",
              " ('}', 11.9552001953125, 'CMSY10'),\n",
              " ('@tencent.com', 11.9552001953125, 'NimbusMonL-Regu'),\n",
              " ('liuyang2011@tsinghua.edu.cn', 11.9552001953125, 'NimbusMonL-Regu'),\n",
              " ('Abstract', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Small perturbations in the input can',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('severely distort intermediate representa-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('tions and thus impact translation quality of',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('neural machine translation (NMT) mod-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('els. In this paper, we propose to improve',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('the robustness of NMT models with adver-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('sarial stability training. The basic idea is',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('to make both the encoder and decoder in',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('NMT models robust against input pertur-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('bations by enabling them to behave sim-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('ilarly for the original input and its per-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('turbed counterpart. Experimental results',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('on Chinese-English, English-German and',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('English-French translation tasks show that',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('our approaches can not only achieve sig-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('niﬁcant improvements over strong NMT',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('systems but also improve the robustness of',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('NMT models.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('1', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Introduction', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Neural machine translation (NMT) models have',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('advanced the state of the art by building a sin-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('gle neural network that can better learn represen-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('tations (', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Cho et al.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (',', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 2014', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (';', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' Sutskever et al.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (',', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 2014', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (').', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('The neural network consists of two components:',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('an encoder network that encodes the input sen-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('tence into a sequence of distributed representa-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('tions, based on which a decoder network generates',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('the translation with an attention model (',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('Bahdanau', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('et al.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (',', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 2015', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (';', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' Luong et al.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (',', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 2015', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('). A variety of NMT', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('models derived from this encoder-decoder frame-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('work have further improved the performance of',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('machine translation systems (', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Gehring et al.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (',', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 2017', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (';', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Vaswani et al.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (',', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 2017', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('). NMT is capable of general-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('izing better to unseen text by exploiting word simi-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('larities in embeddings and capturing long-distance',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('reordering by conditioning on larger contexts in a',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('continuous way.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Input', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('tamen', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' bupa', 10.909099578857422, 'NimbusRomNo9L-ReguItal'),\n",
              " (' kunnan zuochu weiqi AI.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Output', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('They are not afraid of difﬁculties to',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('make Go AI.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Input', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('tamen', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' bu', 10.909099578857422, 'NimbusRomNo9L-ReguItal'),\n",
              " ('wei', 10.909099578857422, 'NimbusRomNo9L-ReguItal'),\n",
              " (' kunnan zuochu weiqi AI.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Output', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('They are not afraid to make Go AI.',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('Table 1: The non-robustness problem of neural',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('machine translation. Replacing a Chinese word',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('with its synonym (i.e., “', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('bupa', 10.909099578857422, 'NimbusRomNo9L-ReguItal'),\n",
              " ('”', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' →', 10.909099578857422, 'CMSY10'),\n",
              " (' “', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('buwei', 10.909099578857422, 'NimbusRomNo9L-ReguItal'),\n",
              " ('”) leads to', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('signiﬁcant erroneous changes in the English trans-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('lation. Both “', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('bupa', 10.909099578857422, 'NimbusRomNo9L-ReguItal'),\n",
              " ('” and “', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('buwei', 10.909099578857422, 'NimbusRomNo9L-ReguItal'),\n",
              " ('” can be translated', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('to the English phrase “', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('be not afraid of', 10.909099578857422, 'NimbusRomNo9L-ReguItal'),\n",
              " ('.”', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('However, studies reveal that very small changes',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('to the input can fool state-of-the-art neural net-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('works with high probability (', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Goodfellow et al.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (',', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('2015', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (';', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' Szegedy et al.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (',', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 2014', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (').', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' Belinkov and Bisk', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('(', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('2018', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (') conﬁrm this ﬁnding by pointing out that',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('NMT models are very brittle and easily falter',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('when presented with noisy input. In NMT, due',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('to the introduction of RNN and attention, each',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('contextual word can inﬂuence the model predic-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('tion in a global context, which is analogous to the',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('“butterﬂy effect.” As shown in Table',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " (' 1', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (', although', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('we only replace a source word with its synonym,',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('the generated translation has been completely dis-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('torted. We investigate severe variations of trans-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('lations caused by small input perturbations by re-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('placing one word in each sentence of a test set with',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('its synonym. We observe that', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 69', 10.909099578857422, 'CMR10'),\n",
              " ('.', 10.909099578857422, 'CMMI10'),\n",
              " ('74', 10.909099578857422, 'CMR10'),\n",
              " ('% of transla-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('tions have changed and the BLEU score is only',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('79', 10.909099578857422, 'CMR10'),\n",
              " ('.', 10.909099578857422, 'CMMI10'),\n",
              " ('01', 10.909099578857422, 'CMR10'),\n",
              " (' between the translations of the original in-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('puts and the translations of the perturbed inputs,',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('suggesting that NMT models are very sensitive to',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('small perturbations in the input. The vulnerabil-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('ity and instability of NMT models limit their ap-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('plicability to a broader range of tasks, which re-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('quire robust performance on noisy inputs. For ex-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('ample, simultaneous translation systems use auto-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('arXiv:1805.06130v1  [cs.CL]  16 May 2018', 20.0, 'Times-Roman'),\n",
              " ('matic speech recognition (ASR) to transcribe in-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('put speech into a sequence of hypothesized words,',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('which are subsequently fed to a translation sys-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('tem. In this pipeline, ASR errors are presented as',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('sentences with noisy perturbations (the same pro-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('nunciation but incorrect words), which is a signif-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('icant challenge for current NMT models. More-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('over, instability makes NMT models sensitive to',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('misspellings and typos in text translation.',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('In this paper, we address this challenge with',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('adversarial stability training',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-ReguItal'),\n",
              " (' for neural machine', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('translation. The basic idea is to improve the ro-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('bustness of two important components in NMT:',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('the encoder and decoder.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('To this end, we pro-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('pose two approaches to constructing noisy inputs',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('with small perturbations to make NMT models re-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('sist them. As important intermediate representa-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('tions encoded by the encoder, they directly deter-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('mine the accuracy of ﬁnal translations. We intro-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('duce adversarial learning to make behaviors of the',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('encoder consistent for both an input and its per-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('turbed counterpart. To improve the stability of the',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('decoder, our method jointly maximizes the likeli-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('hoods of original and perturbed data. Adversarial',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('stability training has the following advantages:',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('1.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' Improving both the robustness and transla-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-ReguItal'),\n",
              " ('tion performance', 10.909099578857422, 'NimbusRomNo9L-ReguItal'),\n",
              " (': Our adversarial stability', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('training is capable of not only improving the',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('robustness of NMT models but also achiev-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('ing better translation performance.',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('2.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' Applicable to arbitrary noisy perturbations',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-ReguItal'),\n",
              " (':', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('In this paper, we propose two approaches to',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('constructing noisy perturbations for inputs.',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('However, our training framework can be eas-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('ily extended to arbitrary noisy perturbations.',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('Especially, we can design task-speciﬁc per-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('turbation methods.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('3.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' Transparent to network architectures',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-ReguItal'),\n",
              " (': Our', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('adversarial stability training does not depend',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('on speciﬁc NMT architectures. It can be ap-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('plied to arbitrary NMT systems.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Experiments', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('on', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Chinese-English,', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('English-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('French and English-German translation tasks',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('show that adversarial stability training achieves',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('signiﬁcant improvements across different lan-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('guages pairs.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Our NMT system outperforms', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('the state-of-the-art RNN-based NMT system',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('(GNMT) (', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Wu et al.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (',', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 2016', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (') and obtains compara-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('ble performance with the CNN-based NMT sys-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('tem (', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Gehring et al.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (',', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 2017', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('). Related experimen-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('tal analyses validate that our training approach can',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('improve the robustness of NMT models.',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('2', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Background', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('NMT is an end-to-end framework which directly',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('optimizes the translation probability of a target',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('sentence', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " (' =', 10.909099578857422, 'CMR10'),\n",
              " (' y', 10.909099578857422, 'CMMI10'),\n",
              " ('1', 7.970099925994873, 'CMR8'),\n",
              " (', ..., y', 10.909099578857422, 'CMMI10'),\n",
              " ('N', 7.970099925994873, 'CMMI8'),\n",
              " (' given its corresponding', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('source sentence', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " (' =', 10.909099578857422, 'CMR10'),\n",
              " (' x', 10.909099578857422, 'CMMI10'),\n",
              " ('1', 7.970099925994873, 'CMR8'),\n",
              " (', ..., x', 10.909099578857422, 'CMMI10'),\n",
              " ('M', 7.970099925994873, 'CMMI8'),\n",
              " (':', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('P', 10.909099578857422, 'CMMI10'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('y', 10.909099578857422, 'CMBX10'),\n",
              " ('|', 10.909099578857422, 'CMSY10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (';', 10.909099578857422, 'CMR10'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " (') =', 10.909099578857422, 'CMR10'),\n",
              " ('N', 7.970099925994873, 'CMMI8'),\n",
              " ('�', 10.909099578857422, 'CMEX10'),\n",
              " ('n', 7.970099925994873, 'CMMI8'),\n",
              " ('=1', 7.970099925994873, 'CMR8'),\n",
              " ('P', 10.909099578857422, 'CMMI10'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('y', 10.909099578857422, 'CMMI10'),\n",
              " ('n', 7.970099925994873, 'CMMI8'),\n",
              " ('|', 10.909099578857422, 'CMSY10'),\n",
              " ('y', 10.909099578857422, 'CMBX10'),\n",
              " ('<n', 7.970099925994873, 'CMMI8'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " (';', 10.909099578857422, 'CMR10'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " ('(1)', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('where', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " (' is a set of model parameters and',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " ('<n', 7.970099925994873, 'CMMI8'),\n",
              " (' is a', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('partial translation.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' P', 10.909099578857422, 'CMMI10'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('y', 10.909099578857422, 'CMBX10'),\n",
              " ('|', 10.909099578857422, 'CMSY10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (';', 10.909099578857422, 'CMR10'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " (' is deﬁned on a holis-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('tic neural network which mainly includes two core',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('components: an', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' encoder', 10.909099578857422, 'NimbusRomNo9L-ReguItal'),\n",
              " (' encodes a source sen-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('tence', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " (' into a sequence of hidden representations',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('H', 10.909099578857422, 'CMBX10'),\n",
              " ('x', 7.970099925994873, 'CMBX8'),\n",
              " (' =', 10.909099578857422, 'CMR10'),\n",
              " (' H', 10.909099578857422, 'CMBX10'),\n",
              " ('1', 7.970099925994873, 'CMR8'),\n",
              " (', ...,', 10.909099578857422, 'CMMI10'),\n",
              " (' H', 10.909099578857422, 'CMBX10'),\n",
              " ('M', 7.970099925994873, 'CMMI8'),\n",
              " (', and a', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' decoder', 10.909099578857422, 'NimbusRomNo9L-ReguItal'),\n",
              " (' generates the', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('n', 10.909099578857422, 'CMMI10'),\n",
              " ('-th target word based on the sequence of hidden',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('representations:', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('P', 10.909099578857422, 'CMMI10'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('y', 10.909099578857422, 'CMMI10'),\n",
              " ('n', 7.970099925994873, 'CMMI8'),\n",
              " ('|', 10.909099578857422, 'CMSY10'),\n",
              " ('y', 10.909099578857422, 'CMBX10'),\n",
              " ('<n', 7.970099925994873, 'CMMI8'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " (';', 10.909099578857422, 'CMR10'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " (' ∝', 10.909099578857422, 'CMSY10'),\n",
              " (' exp', 10.909099578857422, 'CMR10'),\n",
              " ('{', 10.909099578857422, 'CMSY10'),\n",
              " ('g', 10.909099578857422, 'CMMI10'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('y', 10.909099578857422, 'CMMI10'),\n",
              " ('n', 7.970099925994873, 'CMMI8'),\n",
              " ('−', 7.970099925994873, 'CMSY8'),\n",
              " ('1', 7.970099925994873, 'CMR8'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' s', 10.909099578857422, 'CMBX10'),\n",
              " ('n', 7.970099925994873, 'CMMI8'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' H', 10.909099578857422, 'CMBX10'),\n",
              " ('x', 7.970099925994873, 'CMBX8'),\n",
              " (';', 10.909099578857422, 'CMR10'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " ('}', 10.909099578857422, 'CMSY10'),\n",
              " (' (2)', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('where', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' s', 10.909099578857422, 'CMBX10'),\n",
              " ('n', 7.970099925994873, 'CMMI8'),\n",
              " (' is the', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' n', 10.909099578857422, 'CMMI10'),\n",
              " ('-th hidden state on target side.',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('Thus the model parameters of NMT include the',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('parameter sets of the encoder', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " ('enc', 7.970099925994873, 'CMR8'),\n",
              " (' and the decoder', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('θ', 10.909099578857422, 'CMMIB10'),\n",
              " ('dec', 7.970099925994873, 'CMR8'),\n",
              " (':', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " (' =', 10.909099578857422, 'CMR10'),\n",
              " (' {', 10.909099578857422, 'CMSY10'),\n",
              " ('θ', 10.909099578857422, 'CMMIB10'),\n",
              " ('enc', 7.970099925994873, 'CMR8'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " ('dec', 7.970099925994873, 'CMR8'),\n",
              " ('}', 10.909099578857422, 'CMSY10'),\n",
              " ('. The standard training ob-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('jective is to minimize the negative log-likelihood',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('of the training corpus', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' S', 10.909099578857422, 'CMSY10'),\n",
              " (' =', 10.909099578857422, 'CMR10'),\n",
              " (' {⟨', 10.909099578857422, 'CMSY10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " ('(', 7.970099925994873, 'CMR8'),\n",
              " ('s', 7.970099925994873, 'CMMI8'),\n",
              " (')', 7.970099925994873, 'CMR8'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " ('(', 7.970099925994873, 'CMR8'),\n",
              " ('s', 7.970099925994873, 'CMMI8'),\n",
              " (')', 7.970099925994873, 'CMR8'),\n",
              " ('⟩}', 10.909099578857422, 'CMSY10'),\n",
              " ('|S|', 7.970099925994873, 'CMSY8'),\n",
              " ('s', 7.970099925994873, 'CMMI8'),\n",
              " ('=1', 7.970099925994873, 'CMR8'),\n",
              " (':', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('ˆ', 10.909099578857422, 'CMR10'),\n",
              " ('θ', 10.909099578857422, 'CMMIB10'),\n",
              " ('=', 10.909099578857422, 'CMR10'),\n",
              " ('argmin', 10.909099578857422, 'CMR10'),\n",
              " ('θ', 7.970099925994873, 'CMMIB8'),\n",
              " ('L', 10.909099578857422, 'CMSY10'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " (';', 10.909099578857422, 'CMR10'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " ('=', 10.909099578857422, 'CMR10'),\n",
              " ('argmin', 10.909099578857422, 'CMR10'),\n",
              " ('θ', 7.970099925994873, 'CMMIB8'),\n",
              " ('� �', 10.909099578857422, 'CMEX10'),\n",
              " ('⟨', 7.970099925994873, 'CMSY8'),\n",
              " ('x', 7.970099925994873, 'CMBX8'),\n",
              " (',', 7.970099925994873, 'CMMI8'),\n",
              " ('y', 7.970099925994873, 'CMBX8'),\n",
              " ('⟩∈S', 7.970099925994873, 'CMSY8'),\n",
              " ('−', 10.909099578857422, 'CMSY10'),\n",
              " (' log', 10.909099578857422, 'CMR10'),\n",
              " (' P', 10.909099578857422, 'CMMI10'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('y', 10.909099578857422, 'CMBX10'),\n",
              " ('|', 10.909099578857422, 'CMSY10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (';', 10.909099578857422, 'CMR10'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " ('�', 10.909099578857422, 'CMEX10'),\n",
              " ('(3)', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Due to the vulnerability and instability of deep',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('neural networks, NMT models usually suffer from',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('a drawback: small perturbations in the input can',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('dramatically deteriorate its translation results.',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " (' Be-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('linkov and Bisk', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' (', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('2018', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (') point out that character-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('based NMT models are very brittle and easily fal-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('ter when presented with noisy input.',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('We ﬁnd', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('that word-based and subword-based NMT mod-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('els also confront with this shortcoming, as shown',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('in Table', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 1', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('. We argue that the distributed repre-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('sentations should fulﬁll the stability expectation,',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('which is the underlying concept of the proposed',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('approach. Recent work has shown that adversar-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('ially trained models can be made robust to such',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('perturbations (', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Zheng et al.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (',', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 2016', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (';', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' Madry et al.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (',', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('2018', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (').', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Inspired by this, in this work, we im-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('prove the robustness of encoder representations',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('against noisy perturbations with adversarial learn-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('ing (', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Goodfellow et al.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (',', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 2014', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (').', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('x', 10.89900016784668, 'TimesNewRomanPS-BoldMT'),\n",
              " ('’', 10.89900016784668, 'PalatinoLinotype-Bold'),\n",
              " ('x', 10.89900016784668, 'TimesNewRomanPS-BoldMT'),\n",
              " ('+perturbations', 9.687999725341797, 'TimesNewRomanPS-ItalicMT'),\n",
              " ('Encoder', 10.293499946594238, 'TimesNewRomanPS-BoldMT'),\n",
              " ('H', 10.89900016784668, 'TimesNewRomanPS-BoldMT'),\n",
              " ('x', 8.073333740234375, 'PalatinoLinotype-Bold'),\n",
              " ('H', 10.89900016784668, 'TimesNewRomanPS-BoldMT'),\n",
              " ('x’', 8.073333740234375, 'PalatinoLinotype-Bold'),\n",
              " ('Decoder', 10.293499946594238, 'TimesNewRomanPS-BoldMT'),\n",
              " ('Discriminator', 10.293499946594238, 'TimesNewRomanPS-BoldMT'),\n",
              " ('L', 10.89900016784668, 'TimesNewRomanPSMT'),\n",
              " ('inv', 7.265999794006348, 'TimesNewRomanPSMT'),\n",
              " ('(', 10.89900016784668, 'TimesNewRomanPSMT'),\n",
              " ('x', 10.89900016784668, 'TimesNewRomanPS-BoldMT'),\n",
              " (', ', 10.89900016784668, 'TimesNewRomanPSMT'),\n",
              " ('x', 10.89900016784668, 'TimesNewRomanPS-BoldMT'),\n",
              " ('’', 10.89900016784668, 'PalatinoLinotype-Bold'),\n",
              " (')', 10.89900016784668, 'TimesNewRomanPSMT'),\n",
              " ('L', 10.89900016784668, 'PalatinoLinotype-Roman'),\n",
              " ('true', 7.265999794006348, 'PalatinoLinotype-Roman'),\n",
              " ('(', 10.89900016784668, 'PalatinoLinotype-Roman'),\n",
              " ('x', 10.89900016784668, 'TimesNewRomanPS-BoldMT'),\n",
              " (', ', 10.89900016784668, 'TimesNewRomanPSMT'),\n",
              " ('y', 10.89900016784668, 'TimesNewRomanPS-BoldMT'),\n",
              " (')', 10.89900016784668, 'PalatinoLinotype-Roman'),\n",
              " ('L', 10.89900016784668, 'TimesNewRomanPSMT'),\n",
              " ('noisy', 7.265999794006348, 'TimesNewRomanPSMT'),\n",
              " ('(', 10.89900016784668, 'TimesNewRomanPSMT'),\n",
              " ('x', 10.89900016784668, 'TimesNewRomanPS-BoldMT'),\n",
              " ('’', 10.89900016784668, 'PalatinoLinotype-Bold'),\n",
              " (', ', 10.89900016784668, 'TimesNewRomanPSMT'),\n",
              " ('y', 10.89900016784668, 'TimesNewRomanPS-BoldMT'),\n",
              " (')', 10.89900016784668, 'TimesNewRomanPSMT'),\n",
              " ('Figure 1: The architecture of NMT with adversar-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('ial stability training. The dark solid arrow lines',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('represent the forward-pass information ﬂow for',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('the input sentence', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " (', while the', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' red dashed arrow', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('lines', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' for the noisy input sentence', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (', which is', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('transformed from', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " (' by adding small perturbations.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('3', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Approach', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('3.1', 10.909099578857422, 'NimbusRomNo9L-Medi'),\n",
              " ('Overview', 10.909099578857422, 'NimbusRomNo9L-Medi'),\n",
              " ('The goal of this work is to propose a general ap-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('proach to make NMT models learned to be more',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('robust to input perturbations. Our basic idea is',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('to maintain the consistency of behaviors through',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('the NMT model for the source sentence',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " (' and its', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('perturbed counterpart', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " ('. As aforementioned, the', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('NMT model contains two procedures for project-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('ing a source sentence', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " (' to its target sentence', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " (':', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('the encoder is responsible for encoding',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " (' as a se-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('quence of representations', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' H', 10.909099578857422, 'CMBX10'),\n",
              " ('x', 7.970099925994873, 'CMBX8'),\n",
              " (', while the decoder', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('outputs', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " (' with', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' H', 10.909099578857422, 'CMBX10'),\n",
              " ('x', 7.970099925994873, 'CMBX8'),\n",
              " (' as input. We aim at learning', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('the perturbation-invariant encoder and decoder.',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('Figure', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 1', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' illustrates the architecture of our ap-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('proach. Given a source sentence', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " (', we construct a', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('set of perturbed sentences', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' N', 10.909099578857422, 'CMSY10'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " (', in which each', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('sentence', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (' ', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('is constructed by adding small per-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('turbations to', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " ('.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('We require that', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (' ', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('is a subtle', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('variation from', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " (' and they have similar semantics.',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('Given the input pair (', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (',', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " ('), we have two expecta-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('tions: (1) the encoded representation',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " (' H', 10.909099578857422, 'CMBX10'),\n",
              " ('x', 7.970099925994873, 'CMBX8'),\n",
              " ('′', 5.97760009765625, 'CMSY6'),\n",
              " (' should', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('be close to', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' H', 10.909099578857422, 'CMBX10'),\n",
              " ('x', 7.970099925994873, 'CMBX8'),\n",
              " ('; and (2) given', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' H', 10.909099578857422, 'CMBX10'),\n",
              " ('x', 7.970099925994873, 'CMBX8'),\n",
              " ('′', 5.97760009765625, 'CMSY6'),\n",
              " (', the decoder is', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('able to generate the robust output',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " ('. To this end,', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('we introduce two additional objectives to improve',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('the robustness of the encoder and decoder:',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('•', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' L', 10.909099578857422, 'CMSY10'),\n",
              " ('inv', 7.970099925994873, 'CMR8'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " (' to encourage the encoder to out-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('put similar intermediate representations',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " (' H', 10.909099578857422, 'CMBX10'),\n",
              " ('x', 7.970099925994873, 'CMBX8'),\n",
              " ('and', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' H', 10.909099578857422, 'CMBX10'),\n",
              " ('x', 7.970099925994873, 'CMBX8'),\n",
              " ('′', 5.97760009765625, 'CMSY6'),\n",
              " (' for', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " (' and', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (' ', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('to achieve an invariant', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('encoder, which beneﬁts outputting the same',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('translations. We cast this objective in the ad-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('versarial learning framework.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('•', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' L', 10.909099578857422, 'CMSY10'),\n",
              " ('noisy', 7.970099925994873, 'CMR8'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " (' to guide the decoder to generate',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('output', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " (' given the noisy input', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (', which is', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('modeled as', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' −', 10.909099578857422, 'CMSY10'),\n",
              " (' log', 10.909099578857422, 'CMR10'),\n",
              " (' P', 10.909099578857422, 'CMMI10'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('y', 10.909099578857422, 'CMBX10'),\n",
              " ('|', 10.909099578857422, 'CMSY10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " ('. It can also be de-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('ﬁned as KL divergence between', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' P', 10.909099578857422, 'CMMI10'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('y', 10.909099578857422, 'CMBX10'),\n",
              " ('|', 10.909099578857422, 'CMSY10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " (' and', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('P', 10.909099578857422, 'CMMI10'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('y', 10.909099578857422, 'CMBX10'),\n",
              " ('|', 10.909099578857422, 'CMSY10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " (' that indicates using', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' P', 10.909099578857422, 'CMMI10'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('y', 10.909099578857422, 'CMBX10'),\n",
              " ('|', 10.909099578857422, 'CMSY10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " (' to teach', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('P', 10.909099578857422, 'CMMI10'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('y', 10.909099578857422, 'CMBX10'),\n",
              " ('|', 10.909099578857422, 'CMSY10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " ('.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('As seen, the two introduced objectives aim to im-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('prove the robustness of the NMT model which can',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('be free of high variances in target outputs caused',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('by small perturbations in inputs. It is also natural',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('to introduce the original training objective',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " (' L', 10.909099578857422, 'CMSY10'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " ('on', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " (' and', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " (', which can guarantee good transla-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('tion performance while keeping the stability of the',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('NMT model.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Formally, given a training corpus',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " (' S', 10.909099578857422, 'CMSY10'),\n",
              " (', the adver-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('sarial stability training objective is',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('J', 10.909099578857422, 'CMSY10'),\n",
              " (' (', 10.909099578857422, 'CMR10'),\n",
              " ('θ', 10.909099578857422, 'CMMIB10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " ('=', 10.909099578857422, 'CMR10'),\n",
              " ('�', 10.909099578857422, 'CMEX10'),\n",
              " ('⟨', 7.970099925994873, 'CMSY8'),\n",
              " ('x', 7.970099925994873, 'CMBX8'),\n",
              " (',', 7.970099925994873, 'CMMI8'),\n",
              " ('y', 7.970099925994873, 'CMBX8'),\n",
              " ('⟩∈S', 7.970099925994873, 'CMSY8'),\n",
              " ('�', 10.909099578857422, 'CMEX10'),\n",
              " ('L', 10.909099578857422, 'CMSY10'),\n",
              " ('true', 7.970099925994873, 'CMR8'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " (';', 10.909099578857422, 'CMR10'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " ('enc', 7.970099925994873, 'CMR8'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " ('dec', 7.970099925994873, 'CMR8'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " ('+', 10.909099578857422, 'CMR10'),\n",
              " ('α', 10.909099578857422, 'CMMI10'),\n",
              " ('�', 10.909099578857422, 'CMEX10'),\n",
              " ('x', 7.970099925994873, 'CMBX8'),\n",
              " ('′', 5.97760009765625, 'CMSY6'),\n",
              " ('∈N', 7.970099925994873, 'CMSY8'),\n",
              " ('(', 7.970099925994873, 'CMR8'),\n",
              " ('x', 7.970099925994873, 'CMBX8'),\n",
              " (')', 7.970099925994873, 'CMR8'),\n",
              " ('L', 10.909099578857422, 'CMSY10'),\n",
              " ('inv', 7.970099925994873, 'CMR8'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (';', 10.909099578857422, 'CMR10'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " ('enc', 7.970099925994873, 'CMR8'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " ('dis', 7.970099925994873, 'CMR8'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " ('+', 10.909099578857422, 'CMR10'),\n",
              " ('β', 10.909099578857422, 'CMMI10'),\n",
              " ('�', 10.909099578857422, 'CMEX10'),\n",
              " ('x', 7.970099925994873, 'CMBX8'),\n",
              " ('′', 5.97760009765625, 'CMSY6'),\n",
              " ('∈N', 7.970099925994873, 'CMSY8'),\n",
              " ('(', 7.970099925994873, 'CMR8'),\n",
              " ('x', 7.970099925994873, 'CMBX8'),\n",
              " (')', 7.970099925994873, 'CMR8'),\n",
              " ('L', 10.909099578857422, 'CMSY10'),\n",
              " ('noisy', 7.970099925994873, 'CMR8'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " (';', 10.909099578857422, 'CMR10'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " ('enc', 7.970099925994873, 'CMR8'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " ('dec', 7.970099925994873, 'CMR8'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " ('�', 10.909099578857422, 'CMEX10'),\n",
              " ('(4)', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('where', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' L', 10.909099578857422, 'CMSY10'),\n",
              " ('true', 7.970099925994873, 'CMR8'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " (' and', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' L', 10.909099578857422, 'CMSY10'),\n",
              " ('noisy', 7.970099925994873, 'CMR8'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " (' are calculated', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('using Equation', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 3', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (', and', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' L', 10.909099578857422, 'CMSY10'),\n",
              " ('inv', 7.970099925994873, 'CMR8'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " (' is the adversar-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('ial loss to be described in Section',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " (' 3.3', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' α', 10.909099578857422, 'CMMI10'),\n",
              " (' and', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' β', 10.909099578857422, 'CMMI10'),\n",
              " ('control the balance between the original transla-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('tion task and the stability of the NMT model.',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " (' =', 10.909099578857422, 'CMR10'),\n",
              " ('{', 10.909099578857422, 'CMSY10'),\n",
              " ('θ', 10.909099578857422, 'CMMIB10'),\n",
              " ('enc', 7.970099925994873, 'CMR8'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " ('dec', 7.970099925994873, 'CMR8'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " ('dis', 7.970099925994873, 'CMR8'),\n",
              " ('}', 10.909099578857422, 'CMSY10'),\n",
              " (' are trainable parameters of the',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('encoder, decoder, and the newly introduced dis-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('criminator used in adversarial learning. As seen,',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('the parameters of encoder', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " ('enc', 7.970099925994873, 'CMR8'),\n",
              " (' and decoder', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' θ', 10.909099578857422, 'CMMIB10'),\n",
              " ('dec', 7.970099925994873, 'CMR8'),\n",
              " ('are trained to minimize both the translation loss',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('L', 10.909099578857422, 'CMSY10'),\n",
              " ('true', 7.970099925994873, 'CMR8'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " (' and the stability losses (', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('L', 10.909099578857422, 'CMSY10'),\n",
              " ('noisy', 7.970099925994873, 'CMR8'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " ('and', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' L', 10.909099578857422, 'CMSY10'),\n",
              " ('inv', 7.970099925994873, 'CMR8'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " (').', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('Since', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' L', 10.909099578857422, 'CMSY10'),\n",
              " ('noisy', 7.970099925994873, 'CMR8'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " (' evaluates the translation', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('loss on the perturbed neighbour', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " ('′', 7.970099925994873, 'CMSY8'),\n",
              " (' ', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('and its corre-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('sponding target sentence', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' y', 10.909099578857422, 'CMBX10'),\n",
              " (', it means that we aug-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('ment the training data by adding perturbed neigh-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('bours, which can potentially improve the transla-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('tion performance. In this way, our approach not',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('only makes the output of NMT models more ro-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('bust, but also improves the performance on the',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('original translation task.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('In the following sections, we will ﬁrst describe',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('how to construct perturbed inputs with different',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('strategies to fulﬁll different goals (Section',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " (' 3.2', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('),', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('followed by the proposed adversarial learning',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('mechanism for the perturbation-invariant encoder',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('(Section', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 3.3', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('). We conclude this section with the',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('training strategy (Section', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' 3.4', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (').', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('3.2', 10.909099578857422, 'NimbusRomNo9L-Medi'),\n",
              " ('Constructing Perturbed Inputs', 10.909099578857422, 'NimbusRomNo9L-Medi'),\n",
              " ('At each training step, we need to generate a per-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('turbed neighbour set', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' N', 10.909099578857422, 'CMSY10'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (')', 10.909099578857422, 'CMR10'),\n",
              " (' for each source sen-', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('tence', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " (' for adversarial stability training. In this',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('paper, we propose two strategies to construct the',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('perturbed inputs at multiple levels of representa-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('tions.', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('The ﬁrst approach generates perturbed neigh-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('bours at the', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' lexical', 10.909099578857422, 'NimbusRomNo9L-ReguItal'),\n",
              " (' level. Given an input sentence', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " (', we randomly sample some word positions to',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('be modiﬁed. Then we replace words at these posi-',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('tions with other words in the vocabulary according',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('to the following distribution:', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('P', 10.909099578857422, 'CMMI10'),\n",
              " ('(', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMMI10'),\n",
              " ('|', 10.909099578857422, 'CMSY10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " ('i', 7.970099925994873, 'CMMI8'),\n",
              " (') =', 10.909099578857422, 'CMR10'),\n",
              " ('exp', 10.909099578857422, 'CMR10'),\n",
              " (' {', 10.909099578857422, 'CMSY10'),\n",
              " ('cos (', 10.909099578857422, 'CMR10'),\n",
              " ('E', 10.909099578857422, 'CMBX10'),\n",
              " ('[', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " ('i', 7.970099925994873, 'CMMI8'),\n",
              " (']', 10.909099578857422, 'CMR10'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' E', 10.909099578857422, 'CMBX10'),\n",
              " ('[', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMMI10'),\n",
              " ('])', 10.909099578857422, 'CMR10'),\n",
              " ('}', 10.909099578857422, 'CMSY10'),\n",
              " ('�', 10.909099578857422, 'CMEX10'),\n",
              " ('x', 7.970099925994873, 'CMMI8'),\n",
              " ('∈V', 7.970099925994873, 'CMSY8'),\n",
              " ('x', 5.97760009765625, 'CMMI6'),\n",
              " ('\\\\', 7.970099925994873, 'CMSY8'),\n",
              " ('x', 7.970099925994873, 'CMBX8'),\n",
              " ('i', 5.97760009765625, 'CMMI6'),\n",
              " (' ', 10.909099578857422, 'CMR10'),\n",
              " ('exp', 10.909099578857422, 'CMR10'),\n",
              " (' {', 10.909099578857422, 'CMSY10'),\n",
              " ('cos (', 10.909099578857422, 'CMR10'),\n",
              " ('E', 10.909099578857422, 'CMBX10'),\n",
              " ('[', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " ('i', 7.970099925994873, 'CMMI8'),\n",
              " (']', 10.909099578857422, 'CMR10'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " (' E', 10.909099578857422, 'CMBX10'),\n",
              " ('[', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMMI10'),\n",
              " ('])', 10.909099578857422, 'CMR10'),\n",
              " ('}', 10.909099578857422, 'CMSY10'),\n",
              " (' (5)', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('where', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' E', 10.909099578857422, 'CMBX10'),\n",
              " ('[', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " ('i', 7.970099925994873, 'CMMI8'),\n",
              " (']', 10.909099578857422, 'CMR10'),\n",
              " (' is the word embedding for word', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " ('i', 7.970099925994873, 'CMMI8'),\n",
              " (',', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " ('V', 10.909099578857422, 'CMSY10'),\n",
              " ('x', 7.970099925994873, 'CMMI8'),\n",
              " ('\\\\', 10.909099578857422, 'CMSY10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " ('i', 7.970099925994873, 'CMMI8'),\n",
              " (' is the source vocabulary set excluding the',\n",
              "  10.909099578857422,\n",
              "  'NimbusRomNo9L-Regu'),\n",
              " ('word', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' x', 10.909099578857422, 'CMBX10'),\n",
              " ('i', 7.970099925994873, 'CMMI8'),\n",
              " (', and', 10.909099578857422, 'NimbusRomNo9L-Regu'),\n",
              " (' cos (', 10.909099578857422, 'CMR10'),\n",
              " ('E', 10.909099578857422, 'CMBX10'),\n",
              " ('[', 10.909099578857422, 'CMR10'),\n",
              " ('x', 10.909099578857422, 'CMBX10'),\n",
              " ('i', 7.970099925994873, 'CMMI8'),\n",
              " (']', 10.909099578857422, 'CMR10'),\n",
              " (',', 10.909099578857422, 'CMMI10'),\n",
              " ...]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output = scrape(pdf_path)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vki4B4pbC-Wr",
        "outputId": "e5d22c81-a51a-44eb-bcee-7f1646aabbb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Towards Robust Neural Machine Translation Yong Cheng?, Zhaopeng Tu?, Fandong Meng?, Junjie Zhai?and Yang Liuy\n"
          ]
        }
      ],
      "source": [
        "## Validation of correct title extraction\n",
        "if title is None or title == '':\n",
        "      new_title = ''\n",
        "      max_font_size = max(output, key=lambda x: x[1])[1]\n",
        "      elements_with_max_font = [element for element in output if element[1] == max_font_size]\n",
        "\n",
        "      print(\"PDF title is:\\n\")\n",
        "      for element in elements_with_max_font:\n",
        "            new_title += ' ' + element[0]\n",
        "      print(new_title)\n",
        "else:\n",
        "      new_title = title\n",
        "      print(new_title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zR3stimC-Wr",
        "outputId": "cebe1dd0-43e8-47f2-d2a8-469726df55d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# packages required for text pre-processing\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LH8WyKlC-Ws"
      },
      "outputs": [],
      "source": [
        "# Tokenization, lower-case conversion and stop-word removal\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "  sentences = sent_tokenize(text)  # Split into sentences\n",
        "  tokens = [word_tokenize(sentence.lower()) for sentence in sentences]  # Tokenize each sentence\n",
        "  preprocessed_tokens = []\n",
        "  for sentence_tokens in tokens:\n",
        "    filtered_tokens = [token for token in sentence_tokens if token not in stop_words]  # Remove stop words\n",
        "    preprocessed_tokens.extend(filtered_tokens)\n",
        "  return preprocessed_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLNFgXmxC-Ws",
        "outputId": "7618e91a-339a-4d06-f8fb-aefd7a87cd70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['towards', 'robust', 'neural', 'machine', 'translation', 'yong', 'cheng', '?', ',', 'zhaopeng', 'tu', '?', ',', 'fandong', 'meng', '?', ',', 'junjie', 'zhai', '?', 'yang', 'liuy']\n"
          ]
        }
      ],
      "source": [
        "clean_title = preprocess_text(new_title)\n",
        "print(clean_title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRC-sqefC-Ws",
        "outputId": "c67831c8-685f-406f-80d9-75b21a1b4a02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text without punctuations: towards robust neural machine translation yong cheng zhaopeng tu fandong meng junjie zhai yang liuy\n"
          ]
        }
      ],
      "source": [
        "# Removing punctuations from title\n",
        "\n",
        "import string\n",
        "\n",
        "def remove_punctuations(text):\n",
        "\n",
        "  punctuations = string.punctuation + \"/_*\"\n",
        "\n",
        "  no_punct_text = \" \".join([c for c in text if c not in punctuations])\n",
        "\n",
        "  return no_punct_text\n",
        "\n",
        "clean_title = remove_punctuations(clean_title)\n",
        "print(f\"Text without punctuations: {clean_title}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oC8kM2OC-Ws"
      },
      "source": [
        "### Extraction of text from other sections of pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvFZidBGC-Wt"
      },
      "source": [
        "##### Extracting section headers using fontsize and fontname attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4-r7M3LC-Wt",
        "outputId": "f1f65d77-7e88-4bfb-c448-cfcd6173b67f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.9552001953125 NimbusRomNo9L-Medi\n"
          ]
        }
      ],
      "source": [
        "# Determining the font size and font name of 'Abstract' using its index position\n",
        "\n",
        "abstract_index = next(i for i, item in enumerate(output) if item[0] == \"Abstract \" or item[0] == 'ABSTRACT ' or item[0] == \"Abstract\" or item[0] == 'ABSTRACT'  or item[0] == \"Abstract: \")\n",
        "\n",
        "font_size = output[abstract_index][1]\n",
        "font_name = output[abstract_index][2]\n",
        "print(font_size, font_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9vV3EfsC-Wt",
        "outputId": "18143358-83f0-420e-ed81-c07c5a25960a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Yong Cheng', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " (', Zhaopeng Tu', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " (', Fandong Meng', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " (', Junjie Zhai', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " (' ', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('and Yang Liu', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Abstract', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('1', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Introduction', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('2', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Background', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('3', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Approach', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('4', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Experiments', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('5', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Related Work', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('6', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Conclusion', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Acknowledgments', 11.9552001953125, 'NimbusRomNo9L-Medi')]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filtering out only those items which have similar properties as 'Abstract' and considering them as other section headers\n",
        "\n",
        "filtered_items = [item for item in output if item[1] == font_size and item[2] == font_name]\n",
        "filtered_items = filtered_items[:-1] # Excluding references from headers\n",
        "filtered_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP9j6opbC-Wt",
        "outputId": "9b1d8659-9c5e-4a88-d62f-2cc01735e12f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Abstract', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('1', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Introduction', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('2', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Background', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('3', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Approach', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('4', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Experiments', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('5', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Related Work', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('6', 11.9552001953125, 'NimbusRomNo9L-Medi'),\n",
              " ('Conclusion', 11.9552001953125, 'NimbusRomNo9L-Medi')]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Removing unwanted parts of section headers (For eg. Author names, Acknowledgements, References etc.)\n",
        "\n",
        "new_abstract_index = next((i for i, item in enumerate(filtered_items) if item[0] == 'Abstract 'or item[0] == 'ABSTRACT'\n",
        "                           or item[0] == 'Abstract' or item[0] == 'ABSTRACT '), None)\n",
        "\n",
        "new_items = filtered_items[new_abstract_index:] if new_abstract_index is not None else filtered_items\n",
        "\n",
        "new_con_index = next((i for i, element in enumerate(new_items) if element[0] == 'CONCLUSIONS' or element[0] == 'CONCLUSIONS '\n",
        "                      or element[0] == 'Conclusions' or element[0] == 'Conclusions ' or element[0] == 'Conclusion'\n",
        "                      or element[0] == 'Conclusion '), None)\n",
        "\n",
        "new_items = new_items[:new_con_index + 1]\n",
        "\n",
        "new_items\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1esaE2MW2Rjz"
      },
      "source": [
        "##### Formatting the headers to match the actual pdf headers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgJMod05C-Wu",
        "outputId": "c3195921-629b-494c-9c47-a6203e66a702"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Abstract', '1 Introduction', '2 Background', '3 Approach', '4 Experiments', '5 Related Work', '6 Conclusion']\n"
          ]
        }
      ],
      "source": [
        "# Formatting the name of the headers to match the pattern given in original pdfs\n",
        "\n",
        "output = []\n",
        "current_element = ''\n",
        "\n",
        "for i, item in enumerate(new_items):\n",
        "    if i > 0 and item[0].isdigit() and not new_items[i - 1][0].isdigit():\n",
        "\n",
        "        output.append(current_element.strip())\n",
        "        current_element = item[0]\n",
        "    else:\n",
        "        current_element += ' ' + item[0]\n",
        "\n",
        "# Add the last element to the output\n",
        "if current_element:\n",
        "    output.append(current_element.strip())\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP3SnxZAC-Wu",
        "outputId": "80547295-b5ae-4897-9663-836cc037d084"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Abstract',\n",
              " '1 Introduction',\n",
              " '2 Background',\n",
              " '3 Approach',\n",
              " '4 Experiments',\n",
              " '5 Related Work',\n",
              " '6 Conclusion']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Removing other subsections falling under 'Abstract' for less complication\n",
        "\n",
        "new_output = []\n",
        "\n",
        "if(len(output[0].split(' '))>1):\n",
        "    words = output[0].split(' ')\n",
        "    new_output.append(words[0])\n",
        "\n",
        "else:\n",
        "    new_output = output\n",
        "\n",
        "new_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bL2k8JRSC-Wu",
        "outputId": "b5f3777d-e0f2-4dbb-bdfa-84b2783b3990"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Abstract',\n",
              " '1 Introduction',\n",
              " '2 Background',\n",
              " '3 Approach',\n",
              " '4 Experiments',\n",
              " '5 Related Work',\n",
              " '6 Conclusion']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Making a cleaner list of all section headers for individual pdfs\n",
        "\n",
        "for i in range(1,len(output)):\n",
        "  if(output != new_output):\n",
        "    element = output[i].split('.')[0][:-1]\n",
        "    element_new = ''\n",
        "    if(output[i].split('.')[0][-1].isdigit()):\n",
        "        element_new = element\n",
        "    else:\n",
        "        element_new = output[i].split('.')[0]\n",
        "\n",
        "    new_output.append(element_new.rstrip())\n",
        "  else:\n",
        "     pass\n",
        "\n",
        "new_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlF6FvKr8gia"
      },
      "source": [
        "### Extract the entire text of pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFaeQnajC-Wt"
      },
      "outputs": [],
      "source": [
        "# Parse the entire text from individual pdf\n",
        "\n",
        "def extract_text_from_pdf(pdf_file_path):\n",
        "    \"\"\"Extracts text from a PDF file and returns it as a string.\"\"\"\n",
        "\n",
        "    with open(pdf_file_path, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        num_pages = len(pdf_reader.pages)\n",
        "\n",
        "        full_text = \"\"\n",
        "        for page_num in range(num_pages):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            page_text = page.extract_text()\n",
        "            full_text += page_text\n",
        "\n",
        "    return full_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tIgUt8zC-Wt",
        "outputId": "dec49a1b-1080-4cad-b38e-31d8f75b3074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Towards Robust Neural Machine Translation\n",
            "Yong Cheng?, Zhaopeng Tu?, Fandong Meng?, Junjie Zhai?and Yang Liuy\n",
            "?Tencent AI Lab, China\n",
            "yState Key Laboratory of Intelligent Technology and Systems\n",
            "Beijing National Research Center for Information Science and Technology\n",
            "Department of Computer Science and Technology, Tsinghua University, Beijing, China\n",
            "Beijing Advanced Innovation Center for Language Resources\n",
            "chengyong3001@gmail.com\n",
            "fzptu, fandongmeng, jasonzhai g@tencent.com\n",
            "liuyang2011@tsinghua.edu.cn\n",
            "Abstract\n",
            "Small perturbations in the input can\n",
            "severely distort intermediate representa-\n",
            "tions and thus impact translation quality of\n",
            "neural machine translation (NMT) mod-\n",
            "els. In this paper, we propose to improve\n",
            "the robustness of NMT models with adver-\n",
            "sarial stability training. The basic idea is\n",
            "to make both the encoder and decoder in\n",
            "NMT models robust against input pertur-\n",
            "bations by enabling them to behave sim-\n",
            "ilarly for the original input and its per-\n",
            "turbed counterpart. Experimental results\n",
            "on Chinese-English, English-German and\n",
            "English-French translation tasks show that\n",
            "our approaches can not only achieve sig-\n",
            "niﬁcant improvements over strong NMT\n",
            "systems but also improve the robustness of\n",
            "NMT models.\n",
            "1 Introduction\n",
            "Neural machine translation (NMT) models have\n",
            "advanced the state of the art by building a sin-\n",
            "gle neural network that can better learn represen-\n",
            "tations (Cho et al., 2014; Sutskever et al., 2014).\n",
            "The neural network consists of two components:\n",
            "an encoder network that encodes the input sen-\n",
            "tence into a sequence of distributed representa-\n",
            "tions, based on which a decoder network generates\n",
            "the translation with an attention model (Bahdanau\n",
            "et al., 2015; Luong et al., 2015). A variety of NMT\n",
            "models derived from this encoder-decoder frame-\n",
            "work have further improved the performance of\n",
            "machine translation systems (Gehring et al., 2017;\n",
            "Vaswani et al., 2017). NMT is capable of general-\n",
            "izing better to unseen text by exploiting word simi-\n",
            "larities in embeddings and capturing long-distance\n",
            "reordering by conditioning on larger contexts in a\n",
            "continuous way.Input tamen bupa kunnan zuochu weiqi AI.\n",
            "OutputThey are not afraid of difﬁculties to\n",
            "make Go AI.\n",
            "Input tamen buwei kunnan zuochu weiqi AI.\n",
            "Output They are not afraid to make Go AI.\n",
            "Table 1: The non-robustness problem of neural\n",
            "machine translation. Replacing a Chinese word\n",
            "with its synonym (i.e., “ bupa ”!“buwei ”) leads to\n",
            "signiﬁcant erroneous changes in the English trans-\n",
            "lation. Both “ bupa ” and “ buwei ” can be translated\n",
            "to the English phrase “ be not afraid of .”\n",
            "However, studies reveal that very small changes\n",
            "to the input can fool state-of-the-art neural net-\n",
            "works with high probability (Goodfellow et al.,\n",
            "2015; Szegedy et al., 2014). Belinkov and Bisk\n",
            "(2018) conﬁrm this ﬁnding by pointing out that\n",
            "NMT models are very brittle and easily falter\n",
            "when presented with noisy input. In NMT, due\n",
            "to the introduction of RNN and attention, each\n",
            "contextual word can inﬂuence the model predic-\n",
            "tion in a global context, which is analogous to the\n",
            "“butterﬂy effect.” As shown in Table 1, although\n",
            "we only replace a source word with its synonym,\n",
            "the generated translation has been completely dis-\n",
            "torted. We investigate severe variations of trans-\n",
            "lations caused by small input perturbations by re-\n",
            "placing one word in each sentence of a test set with\n",
            "its synonym. We observe that 69:74% of transla-\n",
            "tions have changed and the BLEU score is only\n",
            "79:01between the translations of the original in-\n",
            "puts and the translations of the perturbed inputs,\n",
            "suggesting that NMT models are very sensitive to\n",
            "small perturbations in the input. The vulnerabil-\n",
            "ity and instability of NMT models limit their ap-\n",
            "plicability to a broader range of tasks, which re-\n",
            "quire robust performance on noisy inputs. For ex-\n",
            "ample, simultaneous translation systems use auto-arXiv:1805.06130v1  [cs.CL]  16 May 2018matic speech recognition (ASR) to transcribe in-\n",
            "put speech into a sequence of hypothesized words,\n",
            "which are subsequently fed to a translation sys-\n",
            "tem. In this pipeline, ASR errors are presented as\n",
            "sentences with noisy perturbations (the same pro-\n",
            "nunciation but incorrect words), which is a signif-\n",
            "icant challenge for current NMT models. More-\n",
            "over, instability makes NMT models sensitive to\n",
            "misspellings and typos in text translation.\n",
            "In this paper, we address this challenge with\n",
            "adversarial stability training for neural machine\n",
            "translation. The basic idea is to improve the ro-\n",
            "bustness of two important components in NMT:\n",
            "the encoder and decoder. To this end, we pro-\n",
            "pose two approaches to constructing noisy inputs\n",
            "with small perturbations to make NMT models re-\n",
            "sist them. As important intermediate representa-\n",
            "tions encoded by the encoder, they directly deter-\n",
            "mine the accuracy of ﬁnal translations. We intro-\n",
            "duce adversarial learning to make behaviors of the\n",
            "encoder consistent for both an input and its per-\n",
            "turbed counterpart. To improve the stability of the\n",
            "decoder, our method jointly maximizes the likeli-\n",
            "hoods of original and perturbed data. Adversarial\n",
            "stability training has the following advantages:\n",
            "1.Improving both the robustness and transla-\n",
            "tion performance : Our adversarial stability\n",
            "training is capable of not only improving the\n",
            "robustness of NMT models but also achiev-\n",
            "ing better translation performance.\n",
            "2.Applicable to arbitrary noisy perturbations :\n",
            "In this paper, we propose two approaches to\n",
            "constructing noisy perturbations for inputs.\n",
            "However, our training framework can be eas-\n",
            "ily extended to arbitrary noisy perturbations.\n",
            "Especially, we can design task-speciﬁc per-\n",
            "turbation methods.\n",
            "3.Transparent to network architectures : Our\n",
            "adversarial stability training does not depend\n",
            "on speciﬁc NMT architectures. It can be ap-\n",
            "plied to arbitrary NMT systems.\n",
            "Experiments on Chinese-English, English-\n",
            "French and English-German translation tasks\n",
            "show that adversarial stability training achieves\n",
            "signiﬁcant improvements across different lan-\n",
            "guages pairs. Our NMT system outperforms\n",
            "the state-of-the-art RNN-based NMT system\n",
            "(GNMT) (Wu et al., 2016) and obtains compara-\n",
            "ble performance with the CNN-based NMT sys-tem (Gehring et al., 2017). Related experimen-\n",
            "tal analyses validate that our training approach can\n",
            "improve the robustness of NMT models.\n",
            "2 Background\n",
            "NMT is an end-to-end framework which directly\n",
            "optimizes the translation probability of a target\n",
            "sentence y=y1;:::;y Ngiven its corresponding\n",
            "source sentence x=x1;:::;x M:\n",
            "P(yjx;\u0012) =NY\n",
            "n=1P(ynjy<n;x;\u0012) (1)\n",
            "where \u0012is a set of model parameters and y<nis a\n",
            "partial translation. P(yjx;\u0012)is deﬁned on a holis-\n",
            "tic neural network which mainly includes two core\n",
            "components: an encoder encodes a source sen-\n",
            "tencexinto a sequence of hidden representations\n",
            "Hx=H1;:::;HM, and a decoder generates the\n",
            "n-th target word based on the sequence of hidden\n",
            "representations:\n",
            "P(ynjy<n;x;\u0012)/expfg(yn\u00001;sn;Hx;\u0012)g(2)\n",
            "where snis then-th hidden state on target side.\n",
            "Thus the model parameters of NMT include the\n",
            "parameter sets of the encoder \u0012encand the decoder\n",
            "\u0012dec:\u0012=f\u0012enc;\u0012decg. The standard training ob-\n",
            "jective is to minimize the negative log-likelihood\n",
            "of the training corpus S=fhx(s);y(s)igjSj\n",
            "s=1:\n",
            "^\u0012= argmin\n",
            "\u0012L(x;y;\u0012)\n",
            "= argmin\n",
            "\u0012nX\n",
            "hx;yi2S\u0000logP(yjx;\u0012)o\n",
            "(3)\n",
            "Due to the vulnerability and instability of deep\n",
            "neural networks, NMT models usually suffer from\n",
            "a drawback: small perturbations in the input can\n",
            "dramatically deteriorate its translation results. Be-\n",
            "linkov and Bisk (2018) point out that character-\n",
            "based NMT models are very brittle and easily fal-\n",
            "ter when presented with noisy input. We ﬁnd\n",
            "that word-based and subword-based NMT mod-\n",
            "els also confront with this shortcoming, as shown\n",
            "in Table 1. We argue that the distributed repre-\n",
            "sentations should fulﬁll the stability expectation,\n",
            "which is the underlying concept of the proposed\n",
            "approach. Recent work has shown that adversar-\n",
            "ially trained models can be made robust to such\n",
            "perturbations (Zheng et al., 2016; Madry et al.,\n",
            "2018). Inspired by this, in this work, we im-\n",
            "prove the robustness of encoder representations\n",
            "against noisy perturbations with adversarial learn-\n",
            "ing (Goodfellow et al., 2014).x’x+perturbations\n",
            "EncoderHxHx’\n",
            "Decoder\n",
            "DiscriminatorLinv(x, x’)Ltrue(x, y)Lnoisy(x’, y)Figure 1: The architecture of NMT with adversar-\n",
            "ial stability training. The dark solid arrow lines\n",
            "represent the forward-pass information ﬂow for\n",
            "the input sentence x, while the red dashed arrow\n",
            "lines for the noisy input sentence x0, which is\n",
            "transformed from xby adding small perturbations.\n",
            "3 Approach\n",
            "3.1 Overview\n",
            "The goal of this work is to propose a general ap-\n",
            "proach to make NMT models learned to be more\n",
            "robust to input perturbations. Our basic idea is\n",
            "to maintain the consistency of behaviors through\n",
            "the NMT model for the source sentence xand its\n",
            "perturbed counterpart x0. As aforementioned, the\n",
            "NMT model contains two procedures for project-\n",
            "ing a source sentence xto its target sentence y:\n",
            "the encoder is responsible for encoding xas a se-\n",
            "quence of representations Hx, while the decoder\n",
            "outputs ywithHxas input. We aim at learning\n",
            "the perturbation-invariant encoder and decoder.\n",
            "Figure 1 illustrates the architecture of our ap-\n",
            "proach. Given a source sentence x, we construct a\n",
            "set of perturbed sentences N(x), in which each\n",
            "sentence x0is constructed by adding small per-\n",
            "turbations to x. We require that x0is a subtle\n",
            "variation from xand they have similar semantics.\n",
            "Given the input pair ( x,x0), we have two expecta-\n",
            "tions: (1) the encoded representation Hx0should\n",
            "be close to Hx; and (2) given Hx0, the decoder is\n",
            "able to generate the robust output y. To this end,\n",
            "we introduce two additional objectives to improve\n",
            "the robustness of the encoder and decoder:\n",
            "•Linv(x;x0)to encourage the encoder to out-\n",
            "put similar intermediate representations Hx\n",
            "andHx0forxandx0to achieve an invariantencoder, which beneﬁts outputting the same\n",
            "translations. We cast this objective in the ad-\n",
            "versarial learning framework.\n",
            "•Lnoisy(x0;y)to guide the decoder to generate\n",
            "output ygiven the noisy input x0, which is\n",
            "modeled as\u0000logP(yjx0). It can also be de-\n",
            "ﬁned as KL divergence between P(yjx)and\n",
            "P(yjx0)that indicates using P(yjx)to teach\n",
            "P(yjx0).\n",
            "As seen, the two introduced objectives aim to im-\n",
            "prove the robustness of the NMT model which can\n",
            "be free of high variances in target outputs caused\n",
            "by small perturbations in inputs. It is also natural\n",
            "to introduce the original training objective L(x;y)\n",
            "onxandy, which can guarantee good transla-\n",
            "tion performance while keeping the stability of the\n",
            "NMT model.\n",
            "Formally, given a training corpus S, the adver-\n",
            "sarial stability training objective is\n",
            "J(\u0012)\n",
            "=X\n",
            "hx;yi2S\u0010\n",
            "Ltrue(x;y;\u0012enc;\u0012dec)\n",
            "+\u000bX\n",
            "x02N(x)Linv(x;x0;\u0012enc;\u0012dis)\n",
            "+\fX\n",
            "x02N(x)Lnoisy(x0;y;\u0012enc;\u0012dec)\u0011\n",
            "(4)\n",
            "whereLtrue(x;y)andLnoisy(x0;y)are calculated\n",
            "using Equation 3, and Linv(x;x0)is the adversar-\n",
            "ial loss to be described in Section 3.3. \u000band\f\n",
            "control the balance between the original transla-\n",
            "tion task and the stability of the NMT model. \u0012=\n",
            "f\u0012enc;\u0012dec;\u0012disgare trainable parameters of the\n",
            "encoder, decoder, and the newly introduced dis-\n",
            "criminator used in adversarial learning. As seen,\n",
            "the parameters of encoder \u0012encand decoder \u0012dec\n",
            "are trained to minimize both the translation loss\n",
            "Ltrue(x;y)and the stability losses ( Lnoisy(x0;y)\n",
            "andLinv(x;x0)).\n",
            "SinceLnoisy(x0;y)evaluates the translation\n",
            "loss on the perturbed neighbour x0and its corre-\n",
            "sponding target sentence y, it means that we aug-\n",
            "ment the training data by adding perturbed neigh-\n",
            "bours, which can potentially improve the transla-\n",
            "tion performance. In this way, our approach not\n",
            "only makes the output of NMT models more ro-\n",
            "bust, but also improves the performance on the\n",
            "original translation task.In the following sections, we will ﬁrst describe\n",
            "how to construct perturbed inputs with different\n",
            "strategies to fulﬁll different goals (Section 3.2),\n",
            "followed by the proposed adversarial learning\n",
            "mechanism for the perturbation-invariant encoder\n",
            "(Section 3.3). We conclude this section with the\n",
            "training strategy (Section 3.4).\n",
            "3.2 Constructing Perturbed Inputs\n",
            "At each training step, we need to generate a per-\n",
            "turbed neighbour set N(x)for each source sen-\n",
            "tence xfor adversarial stability training. In this\n",
            "paper, we propose two strategies to construct the\n",
            "perturbed inputs at multiple levels of representa-\n",
            "tions.\n",
            "The ﬁrst approach generates perturbed neigh-\n",
            "bours at the lexical level. Given an input sentence\n",
            "x, we randomly sample some word positions to\n",
            "be modiﬁed. Then we replace words at these posi-\n",
            "tions with other words in the vocabulary according\n",
            "to the following distribution:\n",
            "P(xjxi) =expfcos (E[xi];E[x])gP\n",
            "x2Vxnxiexpfcos (E[xi];E[x])g(5)\n",
            "where E[xi]is the word embedding for word xi,\n",
            "Vxnxiis the source vocabulary set excluding the\n",
            "wordxi, and cos (E[xi];E[x])measures the simi-\n",
            "larity between word xiandx. Thus we can change\n",
            "the word to another word with similar semantics.\n",
            "One potential problem of the above strategy is\n",
            "that it is hard to enumerate all possible positions\n",
            "and possible types to generate perturbed neigh-\n",
            "bours. Therefore, we propose a more general ap-\n",
            "proach to modifying the sentence at the feature\n",
            "level. Given a sentence, we can obtain the word\n",
            "embedding for each word. We add the Gaussian\n",
            "noise to a word embedding to simulate possible\n",
            "types of perturbations. That is\n",
            "E[x0\n",
            "i] =E[xi] +\u000f;\u000f\u0018N(0;\u001b2I) (6)\n",
            "where the vector \u000fis sampled from a Gaussian dis-\n",
            "tribution with variance \u001b2.\u001bis a hyper-parameter.\n",
            "We simply introduce Gaussian noise to all of word\n",
            "embeddings in x.\n",
            "The proposed scheme is a general framework\n",
            "where one can freely deﬁne the strategies to con-\n",
            "struct perturbed inputs. We just present two pos-\n",
            "sible examples here. The ﬁrst strategy is poten-\n",
            "tially useful when the training data contains noisy\n",
            "words, while the latter is a more general strategyto improve the robustness of common NMT mod-\n",
            "els. In practice, one can design speciﬁc strategies\n",
            "for particular tasks. For example, we can replace\n",
            "correct words with their homonyms (same pronun-\n",
            "ciation but different meanings) to improve NMT\n",
            "models for simultaneous translation systems.\n",
            "3.3 Adversarial Learning for the\n",
            "Perturbation-invariant Encoder\n",
            "The goal of the perturbation-invariant encoder is\n",
            "to make the representations produced by the en-\n",
            "coder indistinguishable when fed with a correct\n",
            "sentence xand its perturbed counterpart x0, which\n",
            "is directly beneﬁcial to the output robustness of\n",
            "the decoder. We cast the problem in the adversar-\n",
            "ial learning framework (Goodfellow et al., 2014).\n",
            "The encoder serves as the generator G, which de-\n",
            "ﬁnes the policy that generates a sequence of hid-\n",
            "den representations Hxgiven an input sentence x.\n",
            "We introduce an additional discriminator Dto dis-\n",
            "tinguish the representation of perturbed input Hx0\n",
            "from that of the original input Hx. The goal of\n",
            "the generator G(i.e., encoder) is to produce sim-\n",
            "ilar representations for xandx0which could fool\n",
            "the discriminator, while the discriminator Dtries\n",
            "to correctly distinguish the two representations.\n",
            "Formally, the adversarial learning objective is\n",
            "Linv(x;x0;\u0012enc;\u0012dis)\n",
            "=Ex\u0018S[\u0000logD(G(x))] +\n",
            "Ex0\u0018N(x)\u0002\n",
            "\u0000log(1\u0000D(G(x0)))\u0003\n",
            "(7)\n",
            "The discriminator outputs a classiﬁcation score\n",
            "given an input representation, and tries to max-\n",
            "imizeD(G(x))to 1 and minimize D(G(x0))to\n",
            "0. The objective encourages the encoder to output\n",
            "similar representations for xandx0, so that the\n",
            "discriminator fails to distinguish them.\n",
            "The training procedure can be regarded as a\n",
            "min-max two-player game. The encoder parame-\n",
            "ters\u0012encare trained to maximize the loss function\n",
            "to fool the discriminator. The discriminator pa-\n",
            "rameters \u0012disare optimized to minimize this loss\n",
            "for improving the discriminating ability. For ef-\n",
            "ﬁciency, we update both the encoder and the dis-\n",
            "criminator simultaneously at each iteration, rather\n",
            "than the periodical training strategy that is com-\n",
            "monly used in adversarial learning. Lamb et al.\n",
            "(2016) also propose a similar idea to use Professor\n",
            "Forcing to make the behaviors of RNNs be indis-\n",
            "tinguishable when training and sampling the net-\n",
            "works.3.4 Training\n",
            "As shown in Figure 1, our training objective in-\n",
            "cludes three sets of model parameters for three\n",
            "modules. We use mini-batch stochastic gradient\n",
            "descent to optimize our model. In the forward\n",
            "pass, besides a mini-batch of xandy, we also\n",
            "construct a mini-batch consisting of the perturbed\n",
            "neighbour x0andy. We propagate the informa-\n",
            "tion to calculate these three loss functions accord-\n",
            "ing to arrows. Then, gradients are collected to up-\n",
            "date three sets of model parameters. Except for\n",
            "the gradients ofLinvwith respect to \u0012encare mul-\n",
            "tiplying by\u00001, other gradients are normally back-\n",
            "propagated. Note that we update \u0012invand\u0012encsi-\n",
            "multaneously for training efﬁciency.\n",
            "4 Experiments\n",
            "4.1 Setup\n",
            "We evaluated our adversarial stability training on\n",
            "translation tasks of several language pairs, and re-\n",
            "ported the 4-gram BLEU (Papineni et al., 2002)\n",
            "score as calculated by the multi-bleu.perl script.\n",
            "Chinese-English We used the LDC corpus con-\n",
            "sisting of 1.25M sentence pairs with 27.9M Chi-\n",
            "nese words and 34.5M English words respectively.\n",
            "We selected the best model using the NIST 2006\n",
            "set as the validation set (hyper-parameter opti-\n",
            "mization and model selection). The NIST 2002,\n",
            "2003, 2004, 2005, and 2008 datasets are used as\n",
            "test sets.\n",
            "English-German We used the WMT 14 corpus\n",
            "containing 4.5M sentence pairs with 118M En-\n",
            "glish words and 111M German words. The vali-\n",
            "dation set is newstest2013, and the test set is new-\n",
            "stest2014.\n",
            "English-French We used the IWSLT corpus\n",
            "which contains 0.22M sentence pairs with 4.03M\n",
            "English words and 4.12M French words. The\n",
            "IWLST corpus is very dissimilar from the NIST\n",
            "and WMT corpora. As they are collected from\n",
            "TED talks and inclined to spoken language,\n",
            "we want to verify our approaches on the non-\n",
            "normative text. The IWSLT 14 test set is taken\n",
            "as the validation set and 15 test set is used as the\n",
            "test set.\n",
            "For English-German and English-French, we\n",
            "tokenize both English, German and French words\n",
            "using tokenize.perl script. We follow Sen-\n",
            "nrich et al. (2016b) to split words into sub-\n",
            "word units. The numbers of merge operations\n",
            "in byte pair encoding (BPE) are set to 30K,40K and 30K respectively for Chinese-English,\n",
            "English-German, and English-French. We re-\n",
            "port the case-sensitive tokenized BLEU score for\n",
            "English-German and English-French and the case-\n",
            "insensitive tokenized BLEU score for Chinese-\n",
            "English.\n",
            "Our baseline system is an in-house NMT sys-\n",
            "tem. Following Bahdanau et al. (2015), we im-\n",
            "plement an RNN-based NMT in which both the\n",
            "encoder and decoder are two-layer RNNs with\n",
            "residual connections between layers (He et al.,\n",
            "2016b). The gating mechanism of RNNs is gated\n",
            "recurrent unit (GRUs) (Cho et al., 2014). We\n",
            "apply layer normalization (Ba et al., 2016) and\n",
            "dropout (Hinton et al., 2012) to the hidden states\n",
            "of GRUs. Dropout is also added to the source and\n",
            "target word embeddings. We share the same ma-\n",
            "trix between the target word embeedings and the\n",
            "pre-softmax linear transformation (Vaswani et al.,\n",
            "2017). We update the set of model parameters us-\n",
            "ing Adam SGD (Kingma and Ba, 2015). Its learn-\n",
            "ing rate is initially set to 0:05and varies according\n",
            "to the formula in Vaswani et al. (2017).\n",
            "Our adversarial stability training initializes the\n",
            "model based on the parameters trained by maxi-\n",
            "mum likelihood estimation (MLE). We denote ad-\n",
            "versarial stability training based on lexical-level\n",
            "perturbations and feature-level perturbations re-\n",
            "spectively as AST lexical and AST feature . We only\n",
            "sample one perturbed neighbour x02N (x)for\n",
            "training efﬁciency. For the discriminator used in\n",
            "Linv, we adopt the CNN discriminator proposed\n",
            "by Kim (2014) to address the variable-length prob-\n",
            "lem of the sequence generated by the encoder. In\n",
            "the CNN discriminator, the ﬁlter windows are set\n",
            "to 3, 4, 5 and rectiﬁed linear units are applied af-\n",
            "ter convolution operations. We tune the hyper-\n",
            "parameters on the validation set through a grid\n",
            "search. We ﬁnd that both the optimal values of\n",
            "\u000band\fare set to 1:0. The standard variance in\n",
            "Gaussian noise used in the formula (6) is set to\n",
            "0:01. The number of words that are replaced in\n",
            "the sentence xduring lexical-level perturbations is\n",
            "taken as max(0:2jxj;1)in whichjxjis the length\n",
            "ofx. The default beam size for decoding is 10.\n",
            "4.2 Translation Results\n",
            "4.2.1 NIST Chinese-English Translation\n",
            "Table 2 shows the results on Chinese-English\n",
            "translation. Our strong baseline system signiﬁ-\n",
            "cantly outperforms previously reported results onSystem Training MT06 MT02 MT03 MT04 MT05 MT08\n",
            "Shen et al. (2016) MRT 37.34 40.36 40.93 41.37 38.81 29.23\n",
            "Wang et al. (2017) MLE 37.29 – 39.35 41.15 38.07 –\n",
            "Zhang et al. (2018) MLE 38.38 – 40.02 42.32 38.84 –\n",
            "this workMLE 41.38 43.52 41.50 43.64 41.58 31.60\n",
            "AST lexical 43.57 44.82 42.95 45.05 43.45 34.85\n",
            "AST feature 44.44 46.10 44.07 45.61 44.06 34.94\n",
            "Table 2: Case-insensitive BLEU scores on Chinese-English translation.\n",
            "System Architecture Training BLEU\n",
            "Shen et al. (2016) Gated RNN with 1 layer MRT 20.45\n",
            "Luong et al. (2015) LSTM with 4 layers MLE 20.90\n",
            "Kalchbrenner et al. (2017) ByteNet with 30 layers MLE 23.75\n",
            "Wang et al. (2017) DeepLAU with 4 layers MLE 23.80\n",
            "Wu et al. (2016) LSTM with 8 layers RL 24.60\n",
            "Gehring et al. (2017) CNN with 15 layers MLE 25.16\n",
            "Vaswani et al. (2017) Self-attention with 6 layers MLE 28.40\n",
            "this work Gated RNN with 2 layersMLE 24.06\n",
            "AST lexical 25.17\n",
            "AST feature 25.26\n",
            "Table 3: Case-sensitive BLEU scores on WMT 14 English-German translation.\n",
            "Training tst2014 tst2015\n",
            "MLE 36.92 36.90\n",
            "AST lexical 37.35 37.03\n",
            "AST feature 38.03 37.64\n",
            "Table 4: Case-sensitive BLEU scores on IWSLT\n",
            "English-French translation.\n",
            "Chinese-English NIST datasets trained on RNN-\n",
            "based NMT. Shen et al. (2016) propose minimum\n",
            "risk training (MRT) for NMT, which directly op-\n",
            "timizes model parameters with respect to BLEU\n",
            "scores. Wang et al. (2017) address the issue of\n",
            "severe gradient diffusion with linear associative\n",
            "units (LAU). Their system is deep with an encoder\n",
            "of 4 layers and a decoder of 4 layers. Zhang et al.\n",
            "(2018) propose to exploit both left-to-right and\n",
            "right-to-left decoding strategies for NMT to cap-\n",
            "ture bidirectional dependencies. Compared with\n",
            "them, our NMT system trained by MLE outper-\n",
            "forms their best models by around 3 BLEU points.\n",
            "We hope that the strong baseline systems used in\n",
            "this work make the evaluation convincing.\n",
            "We ﬁnd that introducing adversarial stability\n",
            "training into NMT can bring substantial improve-\n",
            "ments over previous work (up to +3:16BLEUpoints over Shen et al. (2016), up to +3:51\n",
            "BLEU points over Wang et al. (2017) and up to\n",
            "+2:74BLEU points over Zhang et al. (2018))\n",
            "and our system trained with MLE across all the\n",
            "datasets. Compared with our baseline system,\n",
            "AST lexical achieves +1:75BLEU improvement on\n",
            "average. AST feature performs better, which can\n",
            "obtain +2:59BLEU points on average and up to\n",
            "+3:34BLEU points on NIST08.\n",
            "4.2.2 WMT 14 English-German Translation\n",
            "In Table 3, we list existing NMT systems as com-\n",
            "parisons. All these systems use the same WMT 14\n",
            "English-German corpus. Except that Shen et al.\n",
            "(2016) and Wu et al. (2016) respectively adopt\n",
            "MRT and reinforcement learning (RL), other sys-\n",
            "tems all use MLE as training criterion. All the sys-\n",
            "tems except for Shen et al. (2016) are deep NMT\n",
            "models with no less than four layers. Google’s\n",
            "neural machine translation (GNMT) (Wu et al.,\n",
            "2016) represents a strong RNN-based NMT sys-\n",
            "tem. Compared with other RNN-based NMT sys-\n",
            "tems except for GNMT, our baseline system with\n",
            "two layers can achieve better performance than\n",
            "theirs.\n",
            "When training our NMT system with\n",
            "AST leixcal , signiﬁcant improvement ( +1:11Synthetic Type Training 0 Op. 1 Op. 2 Op. 3 Op. 4 Op. 5 Op.\n",
            "SwapMLE 41.38 38.86 37.23 35.97 34.61 32.96\n",
            "AST lexical 43.57 41.18 39.88 37.95 37.02 36.16\n",
            "AST feature 44.44 42.08 40.20 38.67 36.89 35.81\n",
            "ReplacementMLE 41.38 37.21 31.40 27.43 23.94 21.03\n",
            "AST lexical 43.57 40.53 37.59 35.19 32.56 30.42\n",
            "AST feature 44.44 40.04 35.00 30.54 27.42 24.57\n",
            "DeletionMLE 41.38 38.45 36.15 33.28 31.17 28.65\n",
            "AST lexical 43.57 41.89 38.56 36.14 34.09 31.77\n",
            "AST feature 44.44 41.75 39.06 36.16 33.49 30.90\n",
            "Table 5: Translation results of synthetic perturbations on the validation set in Chinese-English translation.\n",
            "“1 Op.” denotes that we conduct one operation (swap, replacement or deletion) on the original sentence.\n",
            "Source zhongguo dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing\n",
            "Reference china’s new management rules for e-banking operations to take effect on march 1\n",
            "MLE china’s electronic bank rules to be implemented on march 1\n",
            "AST lexicalnew rules for business administration of china ’s electronic banking industry\n",
            "will come into effect on march 1 .\n",
            "AST featurenew rules for business management of china ’s electronic banking industry to\n",
            "come into effect on march 1\n",
            "Perturbed Source zhongfang dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing\n",
            "MLE china to implement new regulations on business management\n",
            "AST lexicalthe new regulations for the business administrations of the chinese electronics\n",
            "bank will come into effect on march 1 .\n",
            "AST featurenew rules for business management of china’s electronic banking industry to\n",
            "come into effect on march 1\n",
            "Table 6: Example translations of a source sentence and its perturbed counterpart by replacing a Chinese\n",
            "word “zhongguo” with its synonym “zhongfang.”\n",
            "BLEU points) can be observed. AST feature\n",
            "can obtain slightly better performance. Our\n",
            "NMT system outperforms the state-of-the-art\n",
            "RNN-based NMT system, GNMT, with +0:66\n",
            "BLEU point and performs comparably with\n",
            "Gehring et al. (2017) which is based on CNN\n",
            "with 15 layers. Given that our approach can be\n",
            "applied to any NMT systems, we expect that\n",
            "the adversarial stability training mechanism can\n",
            "further improve performance upon the advanced\n",
            "NMT architectures. We leave this for future work.\n",
            "4.2.3 IWSLT English-French Translation\n",
            "Table 4 shows the results on IWSLT English-\n",
            "French Translation. Compared with our strong\n",
            "baseline system trained by MLE, we observe that\n",
            "our models consistently improve translation per-\n",
            "formance in all datasets. AST feature can achieve\n",
            "signiﬁcant improvements on the tst2015 although\n",
            "AST lexical obtains comparable results. Thesedemonstrate that our approach maintains good per-\n",
            "formance on the non-normative text.\n",
            "4.3 Results on Synthetic Perturbed Data\n",
            "In order to investigate the ability of our training\n",
            "approaches to deal with perturbations, we experi-\n",
            "ment with three types of synthetic perturbations:\n",
            "•Swap : We randomly choose Npositions\n",
            "from a sentence and then swap the chosen\n",
            "words with their right neighbours.\n",
            "•Replacement : We randomly replace sam-\n",
            "pled words in the sentence with other words.\n",
            "•Deletion : We randomly delete Nwords from\n",
            "each sentence in the dataset.\n",
            "As shown in Table 5, we can ﬁnd that our train-\n",
            "ing approaches, AST lexical and AST feature , consis-\n",
            "tently outperform MLE against perturbations on\n",
            "all the numbers of operations. This means that ourLtrueLnoisyLinv BLEUp\u0002 \u0002 41.38p\u0002p41.91\n",
            "\u0002p\u0002 42.20p p\u0002 42.93p p p43.57\n",
            "Table 7: Ablation study of adversarial stabil-\n",
            "ity training AST lexical on Chinese-English trans-\n",
            "lation. “p” means the loss function is included in\n",
            "the training objective while “ \u0002” means it is not.\n",
            "approaches have the capability of resisting pertur-\n",
            "bations. Along with the number of operations in-\n",
            "creasing, the performance on MLE drops quickly.\n",
            "Although the performance of our approaches also\n",
            "drops, we can see that our approaches consistently\n",
            "surpass MLE. In AST lexical , with 0 operation, the\n",
            "difference is +2.19 (43.57 Vs. 41.38) for all syn-\n",
            "thetic types, but the differences are enlarged to\n",
            "+3.20, +9.39, and +3.12 respectively for the three\n",
            "types with 5 operations.\n",
            "In the Swap andDeletion types, AST lexical and\n",
            "AST feature perform comparably after more than\n",
            "four operations. Interestingly, AST lexical per-\n",
            "forms signiﬁcantly better than both of MLE and\n",
            "AST feature after more than one operation in the\n",
            "Replacement type. This is because AST lexical\n",
            "trains the model speciﬁcally on perturbation data\n",
            "that is constructed by replacing words, which\n",
            "agrees with the Replacement Type. Overall,\n",
            "AST lexical performs better than AST feature against\n",
            "perturbations after multiple operations. We spec-\n",
            "ulate that the perturbation method for AST lexical\n",
            "and synthetic type are both discrete and they keep\n",
            "more consistent. Table 6 shows example transla-\n",
            "tions of a Chinese sentence and its perturbed coun-\n",
            "terpart.\n",
            "These ﬁndings indicate that we can construct\n",
            "speciﬁc perturbations for a particular task. For\n",
            "example, in simultaneous translation, an auto-\n",
            "matic speech recognition system usually generates\n",
            "wrong words with the same pronunciation of cor-\n",
            "rect words, which dramatically affects the quality\n",
            "of machine translation system. Therefore, we can\n",
            "design speciﬁc perturbations aiming for this task.\n",
            "4.4 Analysis\n",
            "4.4.1 Ablation Study\n",
            "Our training objective function Eq. (4) contains\n",
            "three loss functions. We perform an ablation\n",
            "Iterations0 20 40 60 80 100 120 140 160 180 200BLEU\n",
            "34363840424446\n",
            "× 103ASTlexical\n",
            "ASTfeatureFigure 2: BLEU scores of AST lexical over itera-\n",
            "tions on Chinese-English validation set.\n",
            "Iterations0 50 100 150 200Cost\n",
            "0.511.522.533.544.55\n",
            "× 103Lnoisy\n",
            "Ltrue\n",
            "Linv\n",
            "Figure 3: Learning curves of three loss functions,\n",
            "Ltrue,LinvandLnoisy over iterations on Chinese-\n",
            "English validation set.\n",
            "study on the Chinese-English translation to under-\n",
            "stand the importance of these loss functions by\n",
            "choosing AST lexical as an example. As Table 7\n",
            "shows, if we remove Ladv, the translation perfor-\n",
            "mance decreases by 0:64BLEU point. However,\n",
            "whenLnoisy is excluded from the training objec-\n",
            "tive function, it results in a signiﬁcant drop of 1:66\n",
            "BLEU point. Surprisingly, only using Lnoisy is\n",
            "able to lead to an increase of 0:88BLEU point.\n",
            "4.4.2 BLEU Scores over Iterations\n",
            "Figure 2 shows the changes of BLEU scores\n",
            "over iterations respectively for AST lexical and\n",
            "AST feature . They behave nearly consistently. Ini-\n",
            "tialized by the model trained by MLE, their per-\n",
            "formance drops rapidly. Then it starts to go up\n",
            "quickly. Compared with the starting point, themaximal dropping points reach up to about 7:0\n",
            "BLEU points. Basically, the curves present the\n",
            "state of oscillation. We think that introducing\n",
            "random perturbations and adversarial learning can\n",
            "make the training not very stable like MLE.\n",
            "4.4.3 Learning Curves of Loss Functions\n",
            "Figure 3 shows the learning curves of three loss\n",
            "functions,Ltrue,LinvandLnoisy. We can ﬁnd that\n",
            "their costs of loss functions decrease not steadily.\n",
            "Similar to the Figure 2, there still exist oscilla-\n",
            "tions in the learning curves although they do not\n",
            "change much sharply. We ﬁnd that Linvconverges\n",
            "to around 0:68after about 100Kiterations, which\n",
            "indicates that discriminator outputs probability 0:5\n",
            "for both positive and negative samples and it can-\n",
            "not distinguish them. Thus the behaviors of the\n",
            "encoder for xand its perturbed neighbour x0per-\n",
            "form nearly consistently.\n",
            "5 Related Work\n",
            "Our work is inspired by two lines of research: (1)\n",
            "adversarial learning and (2) data augmentation.\n",
            "Adversarial Learning Generative Adversarial\n",
            "Network (GAN) (Goodfellow et al., 2014) and\n",
            "its related derivative have been widely applied\n",
            "in computer vision (Radford et al., 2015; Sali-\n",
            "mans et al., 2016) and natural language process-\n",
            "ing (Li et al., 2017; Yang et al., 2018). Previous\n",
            "work has constructed adversarial examples to at-\n",
            "tack trained networks and make networks resist\n",
            "them, which has proved to improve the robust-\n",
            "ness of networks (Goodfellow et al., 2015; Miy-\n",
            "ato et al., 2016; Zheng et al., 2016). Belinkov\n",
            "and Bisk (2018) introduce adversarial examples\n",
            "to training data for character-based NMT models.\n",
            "In contrast to theirs, adversarial stability training\n",
            "aims to stabilize both the encoder and decoder in\n",
            "NMT models. We adopt adversarial learning to\n",
            "learn the perturbation-invariant encoder.\n",
            "Data Augmentation Data augmentation has the\n",
            "capability to improve the robustness of NMT mod-\n",
            "els. In NMT, there is a number of work that aug-\n",
            "ments the training data with monolingual corpora\n",
            "(Sennrich et al., 2016a; Cheng et al., 2016; He\n",
            "et al., 2016a; Zhang and Zong, 2016). They all\n",
            "leverage complex models such as inverse NMT\n",
            "models to generate translation equivalents for\n",
            "monolingual corpora. Then they augment the par-\n",
            "allel corpora with these pseudo corpora to improveNMT models. Some authors have recently en-\n",
            "deavored to achieve zero-shot NMT through trans-\n",
            "ferring knowledge from bilingual corpora of other\n",
            "language pairs (Chen et al., 2017; Zheng et al.,\n",
            "2017; Cheng et al., 2017) or monolingual corpora\n",
            "(Lample et al., 2018; Artetxe et al., 2018). Our\n",
            "work signiﬁcantly differs from these work. We do\n",
            "not resort to any complicated models to generate\n",
            "perturbed data and do not depend on extra mono-\n",
            "lingual or bilingual corpora. The way we exploit\n",
            "is more convenient and easy to implement. We\n",
            "focus more on improving the robustness of NMT\n",
            "models.\n",
            "6 Conclusion\n",
            "We have proposed adversarial stability training to\n",
            "improve the robustness of NMT models. The ba-\n",
            "sic idea is to train both the encoder and decoder\n",
            "robust to input perturbations by enabling them to\n",
            "behave similarly for the original input and its per-\n",
            "turbed counterpart. We propose two approaches\n",
            "to construct perturbed data to adversarially train\n",
            "the encoder and stabilize the decoder. Experi-\n",
            "ments on Chinese-English, English-German and\n",
            "English-French translation tasks show that the pro-\n",
            "posed approach can improve both the robustness\n",
            "and translation performance.\n",
            "As our training framework is not limited to spe-\n",
            "ciﬁc perturbation types, it is interesting to evalu-\n",
            "ate our approach in natural noise existing in prac-\n",
            "tical applications, such as homonym in the simul-\n",
            "taneous translation system. It is also necessary to\n",
            "further validate our approach on more advanced\n",
            "NMT architectures, such as CNN-based NMT\n",
            "(Gehring et al., 2017) and Transformer (Vaswani\n",
            "et al., 2017).\n",
            "Acknowledgments\n",
            "We thank the anonymous reviewers for their in-\n",
            "sightful comments and suggestions. We also thank\n",
            "Xiaoling Li for analyzing experimental results and\n",
            "providing valuable examples. Yang Liu is sup-\n",
            "ported by the National Key R&D Program of\n",
            "China (No. 2017YFB0202204), National Natural\n",
            "Science Foundation of China (No. 61761166008,\n",
            "No. 61522204), Beijing Advanced Innovation\n",
            "Center for Language Resources, and the NExT++\n",
            "project supported by the National Research Foun-\n",
            "dation, Prime Ministers Ofﬁce, Singapore under\n",
            "its IRC@Singapore Funding Initiative.References\n",
            "Mikel Artetxe, Gorka Labaka, Eneko Agirre, and\n",
            "Kyunghyun Cho. 2018. Unsupervised neural ma-\n",
            "chine translation. In Proceedings of ICLR .\n",
            "Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hin-\n",
            "ton. 2016. Layer normalization. arXiv preprint\n",
            "arXiv:1607.06450 .\n",
            "Dzmitry Bahdanau, KyungHyun Cho, and Yoshua\n",
            "Bengio. 2015. Neural machine translation by jointly\n",
            "learning to align and translate. In Proceedings of\n",
            "ICLR .\n",
            "Yonatan Belinkov and Yonatan Bisk. 2018. Synthetic\n",
            "and natural noise both break neural machine transla-\n",
            "tion. In Proceedings of ICLR .\n",
            "Yun Chen, Yang Liu, Yong Cheng, and Victor OK\n",
            "Li. 2017. A teacher-student framework for zero-\n",
            "resource neural machine translation. In Proceedings\n",
            "of ACL .\n",
            "Yong Cheng, Wei Xu, Zhongjun He, Wei He, Hua\n",
            "Wu, Maosong Sun, and Yang Liu. 2016. Semi-\n",
            "supervised learning for neural machine translation.\n",
            "InProceedings of ACL .\n",
            "Yong Cheng, Qian Yang, Yang Liu, Maosong Sun, and\n",
            "Wei Xu. 2017. Joint training for pivot-based neural\n",
            "machine translation. In Proceedings of IJCAI .\n",
            "Kyunghyun Cho, Bart Van Merri ¨enboer, Caglar Gul-\n",
            "cehre, Dzmitry Bahdanau, Fethi Bougares, Holger\n",
            "Schwenk, and Yoshua Bengio. 2014. Learning\n",
            "phrase representations using rnn encoder-decoder\n",
            "for statistical machine translation. In Proceedings\n",
            "of EMNLP .\n",
            "Jonas Gehring, Michael Auli, David Grangier, Denis\n",
            "Yarats, and Yann N Dauphin. 2017. Convolutional\n",
            "sequence to sequence learning. In Proceedings of\n",
            "ICML .\n",
            "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,\n",
            "Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron\n",
            "Courville, and Yoshua Bengio. 2014. Generative ad-\n",
            "versarial nets. In Proceedings of NIPS .\n",
            "Ian Goodfellow, Jonathon Shlens, and Christian\n",
            "Szegedy. 2015. Explaining and harnessing adver-\n",
            "sarial examples. In Proceedings of ICLR .\n",
            "Di He, Yingce Xia, Tao Qin, Liwei Wang, Nenghai Yu,\n",
            "Tie-Yan Liu, and Wei-Ying Ma. 2016a. Dual learn-\n",
            "ing for machine translation. In Proceedings of NIPS .\n",
            "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian\n",
            "Sun. 2016b. Deep residual learning for image recog-\n",
            "nition. In Proceedings of CVPR .\n",
            "Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky,\n",
            "Ilya Sutskever, and Ruslan R Salakhutdinov. 2012.\n",
            "Improving neural networks by preventing co-\n",
            "adaptation of feature detectors. arXiv preprint\n",
            "arXiv:1207.0580 .Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan,\n",
            "Aaron van den Oord, Alex Graves, and Koray\n",
            "Kavukcuoglu. 2017. Neural machine translation in\n",
            "linear time. In Proceedings of ICML .\n",
            "Yoon Kim. 2014. Convolutional neural networks for\n",
            "sentence classiﬁcation. In Proceedings of EMNLP .\n",
            "Diederik P Kingma and Jimmy Ba. 2015. Adam: A\n",
            "method for stochastic optimization. In Proceedings\n",
            "of ICLR .\n",
            "Alex M Lamb, Anirudh Goyal ALIAS PARTH\n",
            "GOYAL, Ying Zhang, Saizheng Zhang, Aaron C\n",
            "Courville, and Yoshua Bengio. 2016. Professor\n",
            "forcing: A new algorithm for training recurrent net-\n",
            "works. In Proceedings of NIPS .\n",
            "Guillaume Lample, Ludovic Denoyer, and\n",
            "Marc’Aurelio Ranzato. 2018. Unsupervised\n",
            "machine translation using monolingual corpora\n",
            "only. In Proceedings of ICLR .\n",
            "Jiwei Li, Will Monroe, Tianlin Shi, S ´ebastien Jean,\n",
            "Alan Ritter, and Dan Jurafsky. 2017. Adversarial\n",
            "learning for neural dialogue generation. In Proceed-\n",
            "ings of EMNLP .\n",
            "Minh-Thang Luong, Hieu Pham, and Christopher D\n",
            "Manning. 2015. Effective approaches to attention-\n",
            "based neural machine translation. In Proceedings of\n",
            "EMNLP .\n",
            "Aleksander Madry, Makelov Aleksandar, Schmidt\n",
            "Ludwig, Dimitris Tsipras, and Adrian Vladu. 2018.\n",
            "Towards deep learning models resistant to adversar-\n",
            "ial attacks. In Proceedings of ICLR .\n",
            "Takeru Miyato, Shin-ichi Maeda, Masanori Koyama,\n",
            "Ken Nakae, and Shin Ishii. 2016. Distributional\n",
            "smoothing with virtual adversarial training. In Pro-\n",
            "ceedings of ICLR .\n",
            "Kishore Papineni, Salim Roukos, Todd Ward, and Wei-\n",
            "Jing Zhu. 2002. BLEU: a methof for automatic eval-\n",
            "uation of machine translation. In Proceedings of\n",
            "ACL.\n",
            "Alec Radford, Luke Metz, and Soumith Chintala.\n",
            "2015. Unsupervised representation learning with\n",
            "deep convolutional generative adversarial networks.\n",
            "arXiv preprint arXiv:1511.06434 .\n",
            "Tim Salimans, Ian Goodfellow, Wojciech Zaremba,\n",
            "Vicki Cheung, Alec Radford, and Xi Chen. 2016.\n",
            "Improved techniques for training gans. In Proceed-\n",
            "ings of NIPS .\n",
            "Rico Sennrich, Barry Haddow, and Alexandra Birch.\n",
            "2016a. Improving nerual machine translation mod-\n",
            "els with monolingual data. In Proceedings of ACL .\n",
            "Rico Sennrich, Barry Haddow, and Alexandra Birch.\n",
            "2016b. Neural machine translation of rare words\n",
            "with subword units. In Proceedings of ACL .Shiqi Shen, Yong Cheng, Zhongjun He, Wei He, Hua\n",
            "Wu, Maosong Sun, and Yang Liu. 2016. Minimum\n",
            "risk training for neural machine translation. In Pro-\n",
            "ceedings of ACL .\n",
            "Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.\n",
            "Sequence to sequence learning with neural net-\n",
            "works. In Proceddings of NIPS .\n",
            "Christian Szegedy, Wojciech Zaremba, Sutskever Ilya,\n",
            "Joan Bruna, Dumitru Erhan, Ian Goodfellow, and\n",
            "Rob Fergus. 2014. Intriguing properties of neural\n",
            "networks. In Proceedings of ICML .\n",
            "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\n",
            "Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz\n",
            "Kaiser, and Illia Polosukhin. 2017. Attention is all\n",
            "you need. In Proceedings of NIPS .\n",
            "Mingxuan Wang, Zhengdong Lu, Jie Zhou, and Qun\n",
            "Liu. 2017. Deep neural machine translation with lin-\n",
            "ear associative unit. In Proceedings of ACL .\n",
            "Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V\n",
            "Le, Mohammad Norouzi, Wolfgang Macherey,\n",
            "Maxim Krikun, et al. 2016. Google’s neural ma-\n",
            "chine translation system: Bridging the gap betweenhuman and machine translation. arXiv preprint\n",
            "arXiv:1609.08144 .\n",
            "Z. Yang, W. Chen, F. Wang, and B. Xu. 2018. Improv-\n",
            "ing Neural Machine Translation with Conditional\n",
            "Sequence Generative Adversarial Nets. In Proceed-\n",
            "ings of NAACL .\n",
            "Jiajun Zhang and Chengqing Zong. 2016. Exploit-\n",
            "ing source-side monolingual data in neural machine\n",
            "translation. In Proceedings of EMNLP .\n",
            "Xiangwen Zhang, Jinsong Su, Yue Qin, Yang Liu, Ron-\n",
            "grong Ji, and Hongji Wang. 2018. Asynchronous\n",
            "Bidirectional Decoding for Neural Machine Trans-\n",
            "lation. In Proeedings of AAAI .\n",
            "Hao Zheng, Yong Cheng, and Yang Liu. 2017.\n",
            "Maximum expected likelihood estimation for zero-\n",
            "resource neural machine translation. In Proceedings\n",
            "of IJCAI .\n",
            "Stephan Zheng, Yang Song, Thomas Leung, and Ian\n",
            "Goodfellow. 2016. Improving the robustness of\n",
            "deep neural networks via stability training. In Pro-\n",
            "ceedings of CVPR .\n"
          ]
        }
      ],
      "source": [
        "extracted_text = extract_text_from_pdf(pdf_path)\n",
        "print(extracted_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iDhiUNI2Rjy"
      },
      "outputs": [],
      "source": [
        "# Omitting 'References' section from extracted text\n",
        "def remove_references(pdf_text):\n",
        "    references_pattern = re.compile(r'References\\s*[\\r\\n]+.*', re.DOTALL | re.IGNORECASE)\n",
        "\n",
        "    text_without_references = re.sub(references_pattern, '', pdf_text)\n",
        "\n",
        "    return text_without_references"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRV4KUpg2Rjz",
        "outputId": "a16c3b28-78f6-4402-ccb9-3d275761252a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Towards Robust Neural Machine Translation\\nYong Cheng?, Zhaopeng Tu?, Fandong Meng?, Junjie Zhai?and Yang Liuy\\n?Tencent AI Lab, China\\nyState Key Laboratory of Intelligent Technology and Systems\\nBeijing National Research Center for Information Science and Technology\\nDepartment of Computer Science and Technology, Tsinghua University, Beijing, China\\nBeijing Advanced Innovation Center for Language Resources\\nchengyong3001@gmail.com\\nfzptu, fandongmeng, jasonzhai g@tencent.com\\nliuyang2011@tsinghua.edu.cn\\nAbstract\\nSmall perturbations in the input can\\nseverely distort intermediate representa-\\ntions and thus impact translation quality of\\nneural machine translation (NMT) mod-\\nels. In this paper, we propose to improve\\nthe robustness of NMT models with adver-\\nsarial stability training. The basic idea is\\nto make both the encoder and decoder in\\nNMT models robust against input pertur-\\nbations by enabling them to behave sim-\\nilarly for the original input and its per-\\nturbed counterpart. Experimental results\\non Chinese-English, English-German and\\nEnglish-French translation tasks show that\\nour approaches can not only achieve sig-\\nniﬁcant improvements over strong NMT\\nsystems but also improve the robustness of\\nNMT models.\\n1 Introduction\\nNeural machine translation (NMT) models have\\nadvanced the state of the art by building a sin-\\ngle neural network that can better learn represen-\\ntations (Cho et al., 2014; Sutskever et al., 2014).\\nThe neural network consists of two components:\\nan encoder network that encodes the input sen-\\ntence into a sequence of distributed representa-\\ntions, based on which a decoder network generates\\nthe translation with an attention model (Bahdanau\\net al., 2015; Luong et al., 2015). A variety of NMT\\nmodels derived from this encoder-decoder frame-\\nwork have further improved the performance of\\nmachine translation systems (Gehring et al., 2017;\\nVaswani et al., 2017). NMT is capable of general-\\nizing better to unseen text by exploiting word simi-\\nlarities in embeddings and capturing long-distance\\nreordering by conditioning on larger contexts in a\\ncontinuous way.Input tamen bupa kunnan zuochu weiqi AI.\\nOutputThey are not afraid of difﬁculties to\\nmake Go AI.\\nInput tamen buwei kunnan zuochu weiqi AI.\\nOutput They are not afraid to make Go AI.\\nTable 1: The non-robustness problem of neural\\nmachine translation. Replacing a Chinese word\\nwith its synonym (i.e., “ bupa ”!“buwei ”) leads to\\nsigniﬁcant erroneous changes in the English trans-\\nlation. Both “ bupa ” and “ buwei ” can be translated\\nto the English phrase “ be not afraid of .”\\nHowever, studies reveal that very small changes\\nto the input can fool state-of-the-art neural net-\\nworks with high probability (Goodfellow et al.,\\n2015; Szegedy et al., 2014). Belinkov and Bisk\\n(2018) conﬁrm this ﬁnding by pointing out that\\nNMT models are very brittle and easily falter\\nwhen presented with noisy input. In NMT, due\\nto the introduction of RNN and attention, each\\ncontextual word can inﬂuence the model predic-\\ntion in a global context, which is analogous to the\\n“butterﬂy effect.” As shown in Table 1, although\\nwe only replace a source word with its synonym,\\nthe generated translation has been completely dis-\\ntorted. We investigate severe variations of trans-\\nlations caused by small input perturbations by re-\\nplacing one word in each sentence of a test set with\\nits synonym. We observe that 69:74% of transla-\\ntions have changed and the BLEU score is only\\n79:01between the translations of the original in-\\nputs and the translations of the perturbed inputs,\\nsuggesting that NMT models are very sensitive to\\nsmall perturbations in the input. The vulnerabil-\\nity and instability of NMT models limit their ap-\\nplicability to a broader range of tasks, which re-\\nquire robust performance on noisy inputs. For ex-\\nample, simultaneous translation systems use auto-arXiv:1805.06130v1  [cs.CL]  16 May 2018matic speech recognition (ASR) to transcribe in-\\nput speech into a sequence of hypothesized words,\\nwhich are subsequently fed to a translation sys-\\ntem. In this pipeline, ASR errors are presented as\\nsentences with noisy perturbations (the same pro-\\nnunciation but incorrect words), which is a signif-\\nicant challenge for current NMT models. More-\\nover, instability makes NMT models sensitive to\\nmisspellings and typos in text translation.\\nIn this paper, we address this challenge with\\nadversarial stability training for neural machine\\ntranslation. The basic idea is to improve the ro-\\nbustness of two important components in NMT:\\nthe encoder and decoder. To this end, we pro-\\npose two approaches to constructing noisy inputs\\nwith small perturbations to make NMT models re-\\nsist them. As important intermediate representa-\\ntions encoded by the encoder, they directly deter-\\nmine the accuracy of ﬁnal translations. We intro-\\nduce adversarial learning to make behaviors of the\\nencoder consistent for both an input and its per-\\nturbed counterpart. To improve the stability of the\\ndecoder, our method jointly maximizes the likeli-\\nhoods of original and perturbed data. Adversarial\\nstability training has the following advantages:\\n1.Improving both the robustness and transla-\\ntion performance : Our adversarial stability\\ntraining is capable of not only improving the\\nrobustness of NMT models but also achiev-\\ning better translation performance.\\n2.Applicable to arbitrary noisy perturbations :\\nIn this paper, we propose two approaches to\\nconstructing noisy perturbations for inputs.\\nHowever, our training framework can be eas-\\nily extended to arbitrary noisy perturbations.\\nEspecially, we can design task-speciﬁc per-\\nturbation methods.\\n3.Transparent to network architectures : Our\\nadversarial stability training does not depend\\non speciﬁc NMT architectures. It can be ap-\\nplied to arbitrary NMT systems.\\nExperiments on Chinese-English, English-\\nFrench and English-German translation tasks\\nshow that adversarial stability training achieves\\nsigniﬁcant improvements across different lan-\\nguages pairs. Our NMT system outperforms\\nthe state-of-the-art RNN-based NMT system\\n(GNMT) (Wu et al., 2016) and obtains compara-\\nble performance with the CNN-based NMT sys-tem (Gehring et al., 2017). Related experimen-\\ntal analyses validate that our training approach can\\nimprove the robustness of NMT models.\\n2 Background\\nNMT is an end-to-end framework which directly\\noptimizes the translation probability of a target\\nsentence y=y1;:::;y Ngiven its corresponding\\nsource sentence x=x1;:::;x M:\\nP(yjx;\\x12) =NY\\nn=1P(ynjy<n;x;\\x12) (1)\\nwhere \\x12is a set of model parameters and y<nis a\\npartial translation. P(yjx;\\x12)is deﬁned on a holis-\\ntic neural network which mainly includes two core\\ncomponents: an encoder encodes a source sen-\\ntencexinto a sequence of hidden representations\\nHx=H1;:::;HM, and a decoder generates the\\nn-th target word based on the sequence of hidden\\nrepresentations:\\nP(ynjy<n;x;\\x12)/expfg(yn\\x001;sn;Hx;\\x12)g(2)\\nwhere snis then-th hidden state on target side.\\nThus the model parameters of NMT include the\\nparameter sets of the encoder \\x12encand the decoder\\n\\x12dec:\\x12=f\\x12enc;\\x12decg. The standard training ob-\\njective is to minimize the negative log-likelihood\\nof the training corpus S=fhx(s);y(s)igjSj\\ns=1:\\n^\\x12= argmin\\n\\x12L(x;y;\\x12)\\n= argmin\\n\\x12nX\\nhx;yi2S\\x00logP(yjx;\\x12)o\\n(3)\\nDue to the vulnerability and instability of deep\\nneural networks, NMT models usually suffer from\\na drawback: small perturbations in the input can\\ndramatically deteriorate its translation results. Be-\\nlinkov and Bisk (2018) point out that character-\\nbased NMT models are very brittle and easily fal-\\nter when presented with noisy input. We ﬁnd\\nthat word-based and subword-based NMT mod-\\nels also confront with this shortcoming, as shown\\nin Table 1. We argue that the distributed repre-\\nsentations should fulﬁll the stability expectation,\\nwhich is the underlying concept of the proposed\\napproach. Recent work has shown that adversar-\\nially trained models can be made robust to such\\nperturbations (Zheng et al., 2016; Madry et al.,\\n2018). Inspired by this, in this work, we im-\\nprove the robustness of encoder representations\\nagainst noisy perturbations with adversarial learn-\\ning (Goodfellow et al., 2014).x’x+perturbations\\nEncoderHxHx’\\nDecoder\\nDiscriminatorLinv(x, x’)Ltrue(x, y)Lnoisy(x’, y)Figure 1: The architecture of NMT with adversar-\\nial stability training. The dark solid arrow lines\\nrepresent the forward-pass information ﬂow for\\nthe input sentence x, while the red dashed arrow\\nlines for the noisy input sentence x0, which is\\ntransformed from xby adding small perturbations.\\n3 Approach\\n3.1 Overview\\nThe goal of this work is to propose a general ap-\\nproach to make NMT models learned to be more\\nrobust to input perturbations. Our basic idea is\\nto maintain the consistency of behaviors through\\nthe NMT model for the source sentence xand its\\nperturbed counterpart x0. As aforementioned, the\\nNMT model contains two procedures for project-\\ning a source sentence xto its target sentence y:\\nthe encoder is responsible for encoding xas a se-\\nquence of representations Hx, while the decoder\\noutputs ywithHxas input. We aim at learning\\nthe perturbation-invariant encoder and decoder.\\nFigure 1 illustrates the architecture of our ap-\\nproach. Given a source sentence x, we construct a\\nset of perturbed sentences N(x), in which each\\nsentence x0is constructed by adding small per-\\nturbations to x. We require that x0is a subtle\\nvariation from xand they have similar semantics.\\nGiven the input pair ( x,x0), we have two expecta-\\ntions: (1) the encoded representation Hx0should\\nbe close to Hx; and (2) given Hx0, the decoder is\\nable to generate the robust output y. To this end,\\nwe introduce two additional objectives to improve\\nthe robustness of the encoder and decoder:\\n•Linv(x;x0)to encourage the encoder to out-\\nput similar intermediate representations Hx\\nandHx0forxandx0to achieve an invariantencoder, which beneﬁts outputting the same\\ntranslations. We cast this objective in the ad-\\nversarial learning framework.\\n•Lnoisy(x0;y)to guide the decoder to generate\\noutput ygiven the noisy input x0, which is\\nmodeled as\\x00logP(yjx0). It can also be de-\\nﬁned as KL divergence between P(yjx)and\\nP(yjx0)that indicates using P(yjx)to teach\\nP(yjx0).\\nAs seen, the two introduced objectives aim to im-\\nprove the robustness of the NMT model which can\\nbe free of high variances in target outputs caused\\nby small perturbations in inputs. It is also natural\\nto introduce the original training objective L(x;y)\\nonxandy, which can guarantee good transla-\\ntion performance while keeping the stability of the\\nNMT model.\\nFormally, given a training corpus S, the adver-\\nsarial stability training objective is\\nJ(\\x12)\\n=X\\nhx;yi2S\\x10\\nLtrue(x;y;\\x12enc;\\x12dec)\\n+\\x0bX\\nx02N(x)Linv(x;x0;\\x12enc;\\x12dis)\\n+\\x0cX\\nx02N(x)Lnoisy(x0;y;\\x12enc;\\x12dec)\\x11\\n(4)\\nwhereLtrue(x;y)andLnoisy(x0;y)are calculated\\nusing Equation 3, and Linv(x;x0)is the adversar-\\nial loss to be described in Section 3.3. \\x0band\\x0c\\ncontrol the balance between the original transla-\\ntion task and the stability of the NMT model. \\x12=\\nf\\x12enc;\\x12dec;\\x12disgare trainable parameters of the\\nencoder, decoder, and the newly introduced dis-\\ncriminator used in adversarial learning. As seen,\\nthe parameters of encoder \\x12encand decoder \\x12dec\\nare trained to minimize both the translation loss\\nLtrue(x;y)and the stability losses ( Lnoisy(x0;y)\\nandLinv(x;x0)).\\nSinceLnoisy(x0;y)evaluates the translation\\nloss on the perturbed neighbour x0and its corre-\\nsponding target sentence y, it means that we aug-\\nment the training data by adding perturbed neigh-\\nbours, which can potentially improve the transla-\\ntion performance. In this way, our approach not\\nonly makes the output of NMT models more ro-\\nbust, but also improves the performance on the\\noriginal translation task.In the following sections, we will ﬁrst describe\\nhow to construct perturbed inputs with different\\nstrategies to fulﬁll different goals (Section 3.2),\\nfollowed by the proposed adversarial learning\\nmechanism for the perturbation-invariant encoder\\n(Section 3.3). We conclude this section with the\\ntraining strategy (Section 3.4).\\n3.2 Constructing Perturbed Inputs\\nAt each training step, we need to generate a per-\\nturbed neighbour set N(x)for each source sen-\\ntence xfor adversarial stability training. In this\\npaper, we propose two strategies to construct the\\nperturbed inputs at multiple levels of representa-\\ntions.\\nThe ﬁrst approach generates perturbed neigh-\\nbours at the lexical level. Given an input sentence\\nx, we randomly sample some word positions to\\nbe modiﬁed. Then we replace words at these posi-\\ntions with other words in the vocabulary according\\nto the following distribution:\\nP(xjxi) =expfcos (E[xi];E[x])gP\\nx2Vxnxiexpfcos (E[xi];E[x])g(5)\\nwhere E[xi]is the word embedding for word xi,\\nVxnxiis the source vocabulary set excluding the\\nwordxi, and cos (E[xi];E[x])measures the simi-\\nlarity between word xiandx. Thus we can change\\nthe word to another word with similar semantics.\\nOne potential problem of the above strategy is\\nthat it is hard to enumerate all possible positions\\nand possible types to generate perturbed neigh-\\nbours. Therefore, we propose a more general ap-\\nproach to modifying the sentence at the feature\\nlevel. Given a sentence, we can obtain the word\\nembedding for each word. We add the Gaussian\\nnoise to a word embedding to simulate possible\\ntypes of perturbations. That is\\nE[x0\\ni] =E[xi] +\\x0f;\\x0f\\x18N(0;\\x1b2I) (6)\\nwhere the vector \\x0fis sampled from a Gaussian dis-\\ntribution with variance \\x1b2.\\x1bis a hyper-parameter.\\nWe simply introduce Gaussian noise to all of word\\nembeddings in x.\\nThe proposed scheme is a general framework\\nwhere one can freely deﬁne the strategies to con-\\nstruct perturbed inputs. We just present two pos-\\nsible examples here. The ﬁrst strategy is poten-\\ntially useful when the training data contains noisy\\nwords, while the latter is a more general strategyto improve the robustness of common NMT mod-\\nels. In practice, one can design speciﬁc strategies\\nfor particular tasks. For example, we can replace\\ncorrect words with their homonyms (same pronun-\\nciation but different meanings) to improve NMT\\nmodels for simultaneous translation systems.\\n3.3 Adversarial Learning for the\\nPerturbation-invariant Encoder\\nThe goal of the perturbation-invariant encoder is\\nto make the representations produced by the en-\\ncoder indistinguishable when fed with a correct\\nsentence xand its perturbed counterpart x0, which\\nis directly beneﬁcial to the output robustness of\\nthe decoder. We cast the problem in the adversar-\\nial learning framework (Goodfellow et al., 2014).\\nThe encoder serves as the generator G, which de-\\nﬁnes the policy that generates a sequence of hid-\\nden representations Hxgiven an input sentence x.\\nWe introduce an additional discriminator Dto dis-\\ntinguish the representation of perturbed input Hx0\\nfrom that of the original input Hx. The goal of\\nthe generator G(i.e., encoder) is to produce sim-\\nilar representations for xandx0which could fool\\nthe discriminator, while the discriminator Dtries\\nto correctly distinguish the two representations.\\nFormally, the adversarial learning objective is\\nLinv(x;x0;\\x12enc;\\x12dis)\\n=Ex\\x18S[\\x00logD(G(x))] +\\nEx0\\x18N(x)\\x02\\n\\x00log(1\\x00D(G(x0)))\\x03\\n(7)\\nThe discriminator outputs a classiﬁcation score\\ngiven an input representation, and tries to max-\\nimizeD(G(x))to 1 and minimize D(G(x0))to\\n0. The objective encourages the encoder to output\\nsimilar representations for xandx0, so that the\\ndiscriminator fails to distinguish them.\\nThe training procedure can be regarded as a\\nmin-max two-player game. The encoder parame-\\nters\\x12encare trained to maximize the loss function\\nto fool the discriminator. The discriminator pa-\\nrameters \\x12disare optimized to minimize this loss\\nfor improving the discriminating ability. For ef-\\nﬁciency, we update both the encoder and the dis-\\ncriminator simultaneously at each iteration, rather\\nthan the periodical training strategy that is com-\\nmonly used in adversarial learning. Lamb et al.\\n(2016) also propose a similar idea to use Professor\\nForcing to make the behaviors of RNNs be indis-\\ntinguishable when training and sampling the net-\\nworks.3.4 Training\\nAs shown in Figure 1, our training objective in-\\ncludes three sets of model parameters for three\\nmodules. We use mini-batch stochastic gradient\\ndescent to optimize our model. In the forward\\npass, besides a mini-batch of xandy, we also\\nconstruct a mini-batch consisting of the perturbed\\nneighbour x0andy. We propagate the informa-\\ntion to calculate these three loss functions accord-\\ning to arrows. Then, gradients are collected to up-\\ndate three sets of model parameters. Except for\\nthe gradients ofLinvwith respect to \\x12encare mul-\\ntiplying by\\x001, other gradients are normally back-\\npropagated. Note that we update \\x12invand\\x12encsi-\\nmultaneously for training efﬁciency.\\n4 Experiments\\n4.1 Setup\\nWe evaluated our adversarial stability training on\\ntranslation tasks of several language pairs, and re-\\nported the 4-gram BLEU (Papineni et al., 2002)\\nscore as calculated by the multi-bleu.perl script.\\nChinese-English We used the LDC corpus con-\\nsisting of 1.25M sentence pairs with 27.9M Chi-\\nnese words and 34.5M English words respectively.\\nWe selected the best model using the NIST 2006\\nset as the validation set (hyper-parameter opti-\\nmization and model selection). The NIST 2002,\\n2003, 2004, 2005, and 2008 datasets are used as\\ntest sets.\\nEnglish-German We used the WMT 14 corpus\\ncontaining 4.5M sentence pairs with 118M En-\\nglish words and 111M German words. The vali-\\ndation set is newstest2013, and the test set is new-\\nstest2014.\\nEnglish-French We used the IWSLT corpus\\nwhich contains 0.22M sentence pairs with 4.03M\\nEnglish words and 4.12M French words. The\\nIWLST corpus is very dissimilar from the NIST\\nand WMT corpora. As they are collected from\\nTED talks and inclined to spoken language,\\nwe want to verify our approaches on the non-\\nnormative text. The IWSLT 14 test set is taken\\nas the validation set and 15 test set is used as the\\ntest set.\\nFor English-German and English-French, we\\ntokenize both English, German and French words\\nusing tokenize.perl script. We follow Sen-\\nnrich et al. (2016b) to split words into sub-\\nword units. The numbers of merge operations\\nin byte pair encoding (BPE) are set to 30K,40K and 30K respectively for Chinese-English,\\nEnglish-German, and English-French. We re-\\nport the case-sensitive tokenized BLEU score for\\nEnglish-German and English-French and the case-\\ninsensitive tokenized BLEU score for Chinese-\\nEnglish.\\nOur baseline system is an in-house NMT sys-\\ntem. Following Bahdanau et al. (2015), we im-\\nplement an RNN-based NMT in which both the\\nencoder and decoder are two-layer RNNs with\\nresidual connections between layers (He et al.,\\n2016b). The gating mechanism of RNNs is gated\\nrecurrent unit (GRUs) (Cho et al., 2014). We\\napply layer normalization (Ba et al., 2016) and\\ndropout (Hinton et al., 2012) to the hidden states\\nof GRUs. Dropout is also added to the source and\\ntarget word embeddings. We share the same ma-\\ntrix between the target word embeedings and the\\npre-softmax linear transformation (Vaswani et al.,\\n2017). We update the set of model parameters us-\\ning Adam SGD (Kingma and Ba, 2015). Its learn-\\ning rate is initially set to 0:05and varies according\\nto the formula in Vaswani et al. (2017).\\nOur adversarial stability training initializes the\\nmodel based on the parameters trained by maxi-\\nmum likelihood estimation (MLE). We denote ad-\\nversarial stability training based on lexical-level\\nperturbations and feature-level perturbations re-\\nspectively as AST lexical and AST feature . We only\\nsample one perturbed neighbour x02N (x)for\\ntraining efﬁciency. For the discriminator used in\\nLinv, we adopt the CNN discriminator proposed\\nby Kim (2014) to address the variable-length prob-\\nlem of the sequence generated by the encoder. In\\nthe CNN discriminator, the ﬁlter windows are set\\nto 3, 4, 5 and rectiﬁed linear units are applied af-\\nter convolution operations. We tune the hyper-\\nparameters on the validation set through a grid\\nsearch. We ﬁnd that both the optimal values of\\n\\x0band\\x0care set to 1:0. The standard variance in\\nGaussian noise used in the formula (6) is set to\\n0:01. The number of words that are replaced in\\nthe sentence xduring lexical-level perturbations is\\ntaken as max(0:2jxj;1)in whichjxjis the length\\nofx. The default beam size for decoding is 10.\\n4.2 Translation Results\\n4.2.1 NIST Chinese-English Translation\\nTable 2 shows the results on Chinese-English\\ntranslation. Our strong baseline system signiﬁ-\\ncantly outperforms previously reported results onSystem Training MT06 MT02 MT03 MT04 MT05 MT08\\nShen et al. (2016) MRT 37.34 40.36 40.93 41.37 38.81 29.23\\nWang et al. (2017) MLE 37.29 – 39.35 41.15 38.07 –\\nZhang et al. (2018) MLE 38.38 – 40.02 42.32 38.84 –\\nthis workMLE 41.38 43.52 41.50 43.64 41.58 31.60\\nAST lexical 43.57 44.82 42.95 45.05 43.45 34.85\\nAST feature 44.44 46.10 44.07 45.61 44.06 34.94\\nTable 2: Case-insensitive BLEU scores on Chinese-English translation.\\nSystem Architecture Training BLEU\\nShen et al. (2016) Gated RNN with 1 layer MRT 20.45\\nLuong et al. (2015) LSTM with 4 layers MLE 20.90\\nKalchbrenner et al. (2017) ByteNet with 30 layers MLE 23.75\\nWang et al. (2017) DeepLAU with 4 layers MLE 23.80\\nWu et al. (2016) LSTM with 8 layers RL 24.60\\nGehring et al. (2017) CNN with 15 layers MLE 25.16\\nVaswani et al. (2017) Self-attention with 6 layers MLE 28.40\\nthis work Gated RNN with 2 layersMLE 24.06\\nAST lexical 25.17\\nAST feature 25.26\\nTable 3: Case-sensitive BLEU scores on WMT 14 English-German translation.\\nTraining tst2014 tst2015\\nMLE 36.92 36.90\\nAST lexical 37.35 37.03\\nAST feature 38.03 37.64\\nTable 4: Case-sensitive BLEU scores on IWSLT\\nEnglish-French translation.\\nChinese-English NIST datasets trained on RNN-\\nbased NMT. Shen et al. (2016) propose minimum\\nrisk training (MRT) for NMT, which directly op-\\ntimizes model parameters with respect to BLEU\\nscores. Wang et al. (2017) address the issue of\\nsevere gradient diffusion with linear associative\\nunits (LAU). Their system is deep with an encoder\\nof 4 layers and a decoder of 4 layers. Zhang et al.\\n(2018) propose to exploit both left-to-right and\\nright-to-left decoding strategies for NMT to cap-\\nture bidirectional dependencies. Compared with\\nthem, our NMT system trained by MLE outper-\\nforms their best models by around 3 BLEU points.\\nWe hope that the strong baseline systems used in\\nthis work make the evaluation convincing.\\nWe ﬁnd that introducing adversarial stability\\ntraining into NMT can bring substantial improve-\\nments over previous work (up to +3:16BLEUpoints over Shen et al. (2016), up to +3:51\\nBLEU points over Wang et al. (2017) and up to\\n+2:74BLEU points over Zhang et al. (2018))\\nand our system trained with MLE across all the\\ndatasets. Compared with our baseline system,\\nAST lexical achieves +1:75BLEU improvement on\\naverage. AST feature performs better, which can\\nobtain +2:59BLEU points on average and up to\\n+3:34BLEU points on NIST08.\\n4.2.2 WMT 14 English-German Translation\\nIn Table 3, we list existing NMT systems as com-\\nparisons. All these systems use the same WMT 14\\nEnglish-German corpus. Except that Shen et al.\\n(2016) and Wu et al. (2016) respectively adopt\\nMRT and reinforcement learning (RL), other sys-\\ntems all use MLE as training criterion. All the sys-\\ntems except for Shen et al. (2016) are deep NMT\\nmodels with no less than four layers. Google’s\\nneural machine translation (GNMT) (Wu et al.,\\n2016) represents a strong RNN-based NMT sys-\\ntem. Compared with other RNN-based NMT sys-\\ntems except for GNMT, our baseline system with\\ntwo layers can achieve better performance than\\ntheirs.\\nWhen training our NMT system with\\nAST leixcal , signiﬁcant improvement ( +1:11Synthetic Type Training 0 Op. 1 Op. 2 Op. 3 Op. 4 Op. 5 Op.\\nSwapMLE 41.38 38.86 37.23 35.97 34.61 32.96\\nAST lexical 43.57 41.18 39.88 37.95 37.02 36.16\\nAST feature 44.44 42.08 40.20 38.67 36.89 35.81\\nReplacementMLE 41.38 37.21 31.40 27.43 23.94 21.03\\nAST lexical 43.57 40.53 37.59 35.19 32.56 30.42\\nAST feature 44.44 40.04 35.00 30.54 27.42 24.57\\nDeletionMLE 41.38 38.45 36.15 33.28 31.17 28.65\\nAST lexical 43.57 41.89 38.56 36.14 34.09 31.77\\nAST feature 44.44 41.75 39.06 36.16 33.49 30.90\\nTable 5: Translation results of synthetic perturbations on the validation set in Chinese-English translation.\\n“1 Op.” denotes that we conduct one operation (swap, replacement or deletion) on the original sentence.\\nSource zhongguo dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing\\nReference china’s new management rules for e-banking operations to take effect on march 1\\nMLE china’s electronic bank rules to be implemented on march 1\\nAST lexicalnew rules for business administration of china ’s electronic banking industry\\nwill come into effect on march 1 .\\nAST featurenew rules for business management of china ’s electronic banking industry to\\ncome into effect on march 1\\nPerturbed Source zhongfang dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing\\nMLE china to implement new regulations on business management\\nAST lexicalthe new regulations for the business administrations of the chinese electronics\\nbank will come into effect on march 1 .\\nAST featurenew rules for business management of china’s electronic banking industry to\\ncome into effect on march 1\\nTable 6: Example translations of a source sentence and its perturbed counterpart by replacing a Chinese\\nword “zhongguo” with its synonym “zhongfang.”\\nBLEU points) can be observed. AST feature\\ncan obtain slightly better performance. Our\\nNMT system outperforms the state-of-the-art\\nRNN-based NMT system, GNMT, with +0:66\\nBLEU point and performs comparably with\\nGehring et al. (2017) which is based on CNN\\nwith 15 layers. Given that our approach can be\\napplied to any NMT systems, we expect that\\nthe adversarial stability training mechanism can\\nfurther improve performance upon the advanced\\nNMT architectures. We leave this for future work.\\n4.2.3 IWSLT English-French Translation\\nTable 4 shows the results on IWSLT English-\\nFrench Translation. Compared with our strong\\nbaseline system trained by MLE, we observe that\\nour models consistently improve translation per-\\nformance in all datasets. AST feature can achieve\\nsigniﬁcant improvements on the tst2015 although\\nAST lexical obtains comparable results. Thesedemonstrate that our approach maintains good per-\\nformance on the non-normative text.\\n4.3 Results on Synthetic Perturbed Data\\nIn order to investigate the ability of our training\\napproaches to deal with perturbations, we experi-\\nment with three types of synthetic perturbations:\\n•Swap : We randomly choose Npositions\\nfrom a sentence and then swap the chosen\\nwords with their right neighbours.\\n•Replacement : We randomly replace sam-\\npled words in the sentence with other words.\\n•Deletion : We randomly delete Nwords from\\neach sentence in the dataset.\\nAs shown in Table 5, we can ﬁnd that our train-\\ning approaches, AST lexical and AST feature , consis-\\ntently outperform MLE against perturbations on\\nall the numbers of operations. This means that ourLtrueLnoisyLinv BLEUp\\x02 \\x02 41.38p\\x02p41.91\\n\\x02p\\x02 42.20p p\\x02 42.93p p p43.57\\nTable 7: Ablation study of adversarial stabil-\\nity training AST lexical on Chinese-English trans-\\nlation. “p” means the loss function is included in\\nthe training objective while “ \\x02” means it is not.\\napproaches have the capability of resisting pertur-\\nbations. Along with the number of operations in-\\ncreasing, the performance on MLE drops quickly.\\nAlthough the performance of our approaches also\\ndrops, we can see that our approaches consistently\\nsurpass MLE. In AST lexical , with 0 operation, the\\ndifference is +2.19 (43.57 Vs. 41.38) for all syn-\\nthetic types, but the differences are enlarged to\\n+3.20, +9.39, and +3.12 respectively for the three\\ntypes with 5 operations.\\nIn the Swap andDeletion types, AST lexical and\\nAST feature perform comparably after more than\\nfour operations. Interestingly, AST lexical per-\\nforms signiﬁcantly better than both of MLE and\\nAST feature after more than one operation in the\\nReplacement type. This is because AST lexical\\ntrains the model speciﬁcally on perturbation data\\nthat is constructed by replacing words, which\\nagrees with the Replacement Type. Overall,\\nAST lexical performs better than AST feature against\\nperturbations after multiple operations. We spec-\\nulate that the perturbation method for AST lexical\\nand synthetic type are both discrete and they keep\\nmore consistent. Table 6 shows example transla-\\ntions of a Chinese sentence and its perturbed coun-\\nterpart.\\nThese ﬁndings indicate that we can construct\\nspeciﬁc perturbations for a particular task. For\\nexample, in simultaneous translation, an auto-\\nmatic speech recognition system usually generates\\nwrong words with the same pronunciation of cor-\\nrect words, which dramatically affects the quality\\nof machine translation system. Therefore, we can\\ndesign speciﬁc perturbations aiming for this task.\\n4.4 Analysis\\n4.4.1 Ablation Study\\nOur training objective function Eq. (4) contains\\nthree loss functions. We perform an ablation\\nIterations0 20 40 60 80 100 120 140 160 180 200BLEU\\n34363840424446\\n× 103ASTlexical\\nASTfeatureFigure 2: BLEU scores of AST lexical over itera-\\ntions on Chinese-English validation set.\\nIterations0 50 100 150 200Cost\\n0.511.522.533.544.55\\n× 103Lnoisy\\nLtrue\\nLinv\\nFigure 3: Learning curves of three loss functions,\\nLtrue,LinvandLnoisy over iterations on Chinese-\\nEnglish validation set.\\nstudy on the Chinese-English translation to under-\\nstand the importance of these loss functions by\\nchoosing AST lexical as an example. As Table 7\\nshows, if we remove Ladv, the translation perfor-\\nmance decreases by 0:64BLEU point. However,\\nwhenLnoisy is excluded from the training objec-\\ntive function, it results in a signiﬁcant drop of 1:66\\nBLEU point. Surprisingly, only using Lnoisy is\\nable to lead to an increase of 0:88BLEU point.\\n4.4.2 BLEU Scores over Iterations\\nFigure 2 shows the changes of BLEU scores\\nover iterations respectively for AST lexical and\\nAST feature . They behave nearly consistently. Ini-\\ntialized by the model trained by MLE, their per-\\nformance drops rapidly. Then it starts to go up\\nquickly. Compared with the starting point, themaximal dropping points reach up to about 7:0\\nBLEU points. Basically, the curves present the\\nstate of oscillation. We think that introducing\\nrandom perturbations and adversarial learning can\\nmake the training not very stable like MLE.\\n4.4.3 Learning Curves of Loss Functions\\nFigure 3 shows the learning curves of three loss\\nfunctions,Ltrue,LinvandLnoisy. We can ﬁnd that\\ntheir costs of loss functions decrease not steadily.\\nSimilar to the Figure 2, there still exist oscilla-\\ntions in the learning curves although they do not\\nchange much sharply. We ﬁnd that Linvconverges\\nto around 0:68after about 100Kiterations, which\\nindicates that discriminator outputs probability 0:5\\nfor both positive and negative samples and it can-\\nnot distinguish them. Thus the behaviors of the\\nencoder for xand its perturbed neighbour x0per-\\nform nearly consistently.\\n5 Related Work\\nOur work is inspired by two lines of research: (1)\\nadversarial learning and (2) data augmentation.\\nAdversarial Learning Generative Adversarial\\nNetwork (GAN) (Goodfellow et al., 2014) and\\nits related derivative have been widely applied\\nin computer vision (Radford et al., 2015; Sali-\\nmans et al., 2016) and natural language process-\\ning (Li et al., 2017; Yang et al., 2018). Previous\\nwork has constructed adversarial examples to at-\\ntack trained networks and make networks resist\\nthem, which has proved to improve the robust-\\nness of networks (Goodfellow et al., 2015; Miy-\\nato et al., 2016; Zheng et al., 2016). Belinkov\\nand Bisk (2018) introduce adversarial examples\\nto training data for character-based NMT models.\\nIn contrast to theirs, adversarial stability training\\naims to stabilize both the encoder and decoder in\\nNMT models. We adopt adversarial learning to\\nlearn the perturbation-invariant encoder.\\nData Augmentation Data augmentation has the\\ncapability to improve the robustness of NMT mod-\\nels. In NMT, there is a number of work that aug-\\nments the training data with monolingual corpora\\n(Sennrich et al., 2016a; Cheng et al., 2016; He\\net al., 2016a; Zhang and Zong, 2016). They all\\nleverage complex models such as inverse NMT\\nmodels to generate translation equivalents for\\nmonolingual corpora. Then they augment the par-\\nallel corpora with these pseudo corpora to improveNMT models. Some authors have recently en-\\ndeavored to achieve zero-shot NMT through trans-\\nferring knowledge from bilingual corpora of other\\nlanguage pairs (Chen et al., 2017; Zheng et al.,\\n2017; Cheng et al., 2017) or monolingual corpora\\n(Lample et al., 2018; Artetxe et al., 2018). Our\\nwork signiﬁcantly differs from these work. We do\\nnot resort to any complicated models to generate\\nperturbed data and do not depend on extra mono-\\nlingual or bilingual corpora. The way we exploit\\nis more convenient and easy to implement. We\\nfocus more on improving the robustness of NMT\\nmodels.\\n6 Conclusion\\nWe have proposed adversarial stability training to\\nimprove the robustness of NMT models. The ba-\\nsic idea is to train both the encoder and decoder\\nrobust to input perturbations by enabling them to\\nbehave similarly for the original input and its per-\\nturbed counterpart. We propose two approaches\\nto construct perturbed data to adversarially train\\nthe encoder and stabilize the decoder. Experi-\\nments on Chinese-English, English-German and\\nEnglish-French translation tasks show that the pro-\\nposed approach can improve both the robustness\\nand translation performance.\\nAs our training framework is not limited to spe-\\nciﬁc perturbation types, it is interesting to evalu-\\nate our approach in natural noise existing in prac-\\ntical applications, such as homonym in the simul-\\ntaneous translation system. It is also necessary to\\nfurther validate our approach on more advanced\\nNMT architectures, such as CNN-based NMT\\n(Gehring et al., 2017) and Transformer (Vaswani\\net al., 2017).\\nAcknowledgments\\nWe thank the anonymous reviewers for their in-\\nsightful comments and suggestions. We also thank\\nXiaoling Li for analyzing experimental results and\\nproviding valuable examples. Yang Liu is sup-\\nported by the National Key R&D Program of\\nChina (No. 2017YFB0202204), National Natural\\nScience Foundation of China (No. 61761166008,\\nNo. 61522204), Beijing Advanced Innovation\\nCenter for Language Resources, and the NExT++\\nproject supported by the National Research Foun-\\ndation, Prime Ministers Ofﬁce, Singapore under\\nits IRC@Singapore Funding Initiative.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extracted_text = remove_references(extracted_text)\n",
        "extracted_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw7T0x_h2Rjz",
        "outputId": "d7f9e419-8ac2-4b23-9977-ef3fbcbaad15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Towards Robust Neural Machine Translation\n",
            "Yong Cheng?, Zhaopeng Tu?, Fandong Meng?, Junjie Zhai?and Yang Liuy\n",
            "?Tencent AI Lab, China\n",
            "yState Key Laboratory of Intelligent Technology and Systems\n",
            "Beijing National Research Center for Information Science and Technology\n",
            "Department of Computer Science and Technology, Tsinghua University, Beijing, China\n",
            "Beijing Advanced Innovation Center for Language Resources\n",
            "chengyong3001@gmail.com\n",
            "fzptu, fandongmeng, jasonzhai g@tencent.com\n",
            "liuyang2011@tsinghua.edu.cn\n",
            "Abstract\n",
            "Small perturbations in the input can\n",
            "severely distort intermediate representa-\n",
            "tions and thus impact translation quality of\n",
            "neural machine translation (NMT) mod-\n",
            "els. In this paper, we propose to improve\n",
            "the robustness of NMT models with adver-\n",
            "sarial stability training. The basic idea is\n",
            "to make both the encoder and decoder in\n",
            "NMT models robust against input pertur-\n",
            "bations by enabling them to behave sim-\n",
            "ilarly for the original input and its per-\n",
            "turbed counterpart. Experimental results\n",
            "on Chinese-English, English-German and\n",
            "English-French translation tasks show that\n",
            "our approaches can not only achieve sig-\n",
            "nicant improvements over strong NMT\n",
            "systems but also improve the robustness of\n",
            "NMT models.\n",
            "1 Introduction\n",
            "Neural machine translation (NMT) models have\n",
            "advanced the state of the art by building a sin-\n",
            "gle neural network that can better learn represen-\n",
            "tations (Cho et al., 2014; Sutskever et al., 2014).\n",
            "The neural network consists of two components:\n",
            "an encoder network that encodes the input sen-\n",
            "tence into a sequence of distributed representa-\n",
            "tions, based on which a decoder network generates\n",
            "the translation with an attention model (Bahdanau\n",
            "et al., 2015; Luong et al., 2015). A variety of NMT\n",
            "models derived from this encoder-decoder frame-\n",
            "work have further improved the performance of\n",
            "machine translation systems (Gehring et al., 2017;\n",
            "Vaswani et al., 2017). NMT is capable of general-\n",
            "izing better to unseen text by exploiting word simi-\n",
            "larities in embeddings and capturing long-distance\n",
            "reordering by conditioning on larger contexts in a\n",
            "continuous way.Input tamen bupa kunnan zuochu weiqi AI.\n",
            "OutputThey are not afraid of difculties to\n",
            "make Go AI.\n",
            "Input tamen buwei kunnan zuochu weiqi AI.\n",
            "Output They are not afraid to make Go AI.\n",
            "Table 1: The non-robustness problem of neural\n",
            "machine translation. Replacing a Chinese word\n",
            "with its synonym (i.e.,  bupa !buwei ) leads to\n",
            "signicant erroneous changes in the English trans-\n",
            "lation. Both  bupa  and  buwei  can be translated\n",
            "to the English phrase  be not afraid of .\n",
            "However, studies reveal that very small changes\n",
            "to the input can fool state-of-the-art neural net-\n",
            "works with high probability (Goodfellow et al.,\n",
            "2015; Szegedy et al., 2014). Belinkov and Bisk\n",
            "(2018) conrm this nding by pointing out that\n",
            "NMT models are very brittle and easily falter\n",
            "when presented with noisy input. In NMT, due\n",
            "to the introduction of RNN and attention, each\n",
            "contextual word can inuence the model predic-\n",
            "tion in a global context, which is analogous to the\n",
            "buttery effect. As shown in Table 1, although\n",
            "we only replace a source word with its synonym,\n",
            "the generated translation has been completely dis-\n",
            "torted. We investigate severe variations of trans-\n",
            "lations caused by small input perturbations by re-\n",
            "placing one word in each sentence of a test set with\n",
            "its synonym. We observe that 69:74% of transla-\n",
            "tions have changed and the BLEU score is only\n",
            "79:01between the translations of the original in-\n",
            "puts and the translations of the perturbed inputs,\n",
            "suggesting that NMT models are very sensitive to\n",
            "small perturbations in the input. The vulnerabil-\n",
            "ity and instability of NMT models limit their ap-\n",
            "plicability to a broader range of tasks, which re-\n",
            "quire robust performance on noisy inputs. For ex-\n",
            "ample, simultaneous translation systems use auto-arXiv:1805.06130v1  [cs.CL]  16 May 2018matic speech recognition (ASR) to transcribe in-\n",
            "put speech into a sequence of hypothesized words,\n",
            "which are subsequently fed to a translation sys-\n",
            "tem. In this pipeline, ASR errors are presented as\n",
            "sentences with noisy perturbations (the same pro-\n",
            "nunciation but incorrect words), which is a signif-\n",
            "icant challenge for current NMT models. More-\n",
            "over, instability makes NMT models sensitive to\n",
            "misspellings and typos in text translation.\n",
            "In this paper, we address this challenge with\n",
            "adversarial stability training for neural machine\n",
            "translation. The basic idea is to improve the ro-\n",
            "bustness of two important components in NMT:\n",
            "the encoder and decoder. To this end, we pro-\n",
            "pose two approaches to constructing noisy inputs\n",
            "with small perturbations to make NMT models re-\n",
            "sist them. As important intermediate representa-\n",
            "tions encoded by the encoder, they directly deter-\n",
            "mine the accuracy of nal translations. We intro-\n",
            "duce adversarial learning to make behaviors of the\n",
            "encoder consistent for both an input and its per-\n",
            "turbed counterpart. To improve the stability of the\n",
            "decoder, our method jointly maximizes the likeli-\n",
            "hoods of original and perturbed data. Adversarial\n",
            "stability training has the following advantages:\n",
            "1.Improving both the robustness and transla-\n",
            "tion performance : Our adversarial stability\n",
            "training is capable of not only improving the\n",
            "robustness of NMT models but also achiev-\n",
            "ing better translation performance.\n",
            "2.Applicable to arbitrary noisy perturbations :\n",
            "In this paper, we propose two approaches to\n",
            "constructing noisy perturbations for inputs.\n",
            "However, our training framework can be eas-\n",
            "ily extended to arbitrary noisy perturbations.\n",
            "Especially, we can design task-specic per-\n",
            "turbation methods.\n",
            "3.Transparent to network architectures : Our\n",
            "adversarial stability training does not depend\n",
            "on specic NMT architectures. It can be ap-\n",
            "plied to arbitrary NMT systems.\n",
            "Experiments on Chinese-English, English-\n",
            "French and English-German translation tasks\n",
            "show that adversarial stability training achieves\n",
            "signicant improvements across different lan-\n",
            "guages pairs. Our NMT system outperforms\n",
            "the state-of-the-art RNN-based NMT system\n",
            "(GNMT) (Wu et al., 2016) and obtains compara-\n",
            "ble performance with the CNN-based NMT sys-tem (Gehring et al., 2017). Related experimen-\n",
            "tal analyses validate that our training approach can\n",
            "improve the robustness of NMT models.\n",
            "2 Background\n",
            "NMT is an end-to-end framework which directly\n",
            "optimizes the translation probability of a target\n",
            "sentence y=y1;:::;y Ngiven its corresponding\n",
            "source sentence x=x1;:::;x M:\n",
            "P(yjx;\u0012) =NY\n",
            "n=1P(ynjy<n;x;\u0012) (1)\n",
            "where \u0012is a set of model parameters and y<nis a\n",
            "partial translation. P(yjx;\u0012)is dened on a holis-\n",
            "tic neural network which mainly includes two core\n",
            "components: an encoder encodes a source sen-\n",
            "tencexinto a sequence of hidden representations\n",
            "Hx=H1;:::;HM, and a decoder generates the\n",
            "n-th target word based on the sequence of hidden\n",
            "representations:\n",
            "P(ynjy<n;x;\u0012)/expfg(yn\u00001;sn;Hx;\u0012)g(2)\n",
            "where snis then-th hidden state on target side.\n",
            "Thus the model parameters of NMT include the\n",
            "parameter sets of the encoder \u0012encand the decoder\n",
            "\u0012dec:\u0012=f\u0012enc;\u0012decg. The standard training ob-\n",
            "jective is to minimize the negative log-likelihood\n",
            "of the training corpus S=fhx(s);y(s)igjSj\n",
            "s=1:\n",
            "^\u0012= argmin\n",
            "\u0012L(x;y;\u0012)\n",
            "= argmin\n",
            "\u0012nX\n",
            "hx;yi2S\u0000logP(yjx;\u0012)o\n",
            "(3)\n",
            "Due to the vulnerability and instability of deep\n",
            "neural networks, NMT models usually suffer from\n",
            "a drawback: small perturbations in the input can\n",
            "dramatically deteriorate its translation results. Be-\n",
            "linkov and Bisk (2018) point out that character-\n",
            "based NMT models are very brittle and easily fal-\n",
            "ter when presented with noisy input. We nd\n",
            "that word-based and subword-based NMT mod-\n",
            "els also confront with this shortcoming, as shown\n",
            "in Table 1. We argue that the distributed repre-\n",
            "sentations should fulll the stability expectation,\n",
            "which is the underlying concept of the proposed\n",
            "approach. Recent work has shown that adversar-\n",
            "ially trained models can be made robust to such\n",
            "perturbations (Zheng et al., 2016; Madry et al.,\n",
            "2018). Inspired by this, in this work, we im-\n",
            "prove the robustness of encoder representations\n",
            "against noisy perturbations with adversarial learn-\n",
            "ing (Goodfellow et al., 2014).xx+perturbations\n",
            "EncoderHxHx\n",
            "Decoder\n",
            "DiscriminatorLinv(x, x)Ltrue(x, y)Lnoisy(x, y)Figure 1: The architecture of NMT with adversar-\n",
            "ial stability training. The dark solid arrow lines\n",
            "represent the forward-pass information ow for\n",
            "the input sentence x, while the red dashed arrow\n",
            "lines for the noisy input sentence x0, which is\n",
            "transformed from xby adding small perturbations.\n",
            "3 Approach\n",
            "3.1 Overview\n",
            "The goal of this work is to propose a general ap-\n",
            "proach to make NMT models learned to be more\n",
            "robust to input perturbations. Our basic idea is\n",
            "to maintain the consistency of behaviors through\n",
            "the NMT model for the source sentence xand its\n",
            "perturbed counterpart x0. As aforementioned, the\n",
            "NMT model contains two procedures for project-\n",
            "ing a source sentence xto its target sentence y:\n",
            "the encoder is responsible for encoding xas a se-\n",
            "quence of representations Hx, while the decoder\n",
            "outputs ywithHxas input. We aim at learning\n",
            "the perturbation-invariant encoder and decoder.\n",
            "Figure 1 illustrates the architecture of our ap-\n",
            "proach. Given a source sentence x, we construct a\n",
            "set of perturbed sentences N(x), in which each\n",
            "sentence x0is constructed by adding small per-\n",
            "turbations to x. We require that x0is a subtle\n",
            "variation from xand they have similar semantics.\n",
            "Given the input pair ( x,x0), we have two expecta-\n",
            "tions: (1) the encoded representation Hx0should\n",
            "be close to Hx; and (2) given Hx0, the decoder is\n",
            "able to generate the robust output y. To this end,\n",
            "we introduce two additional objectives to improve\n",
            "the robustness of the encoder and decoder:\n",
            "Linv(x;x0)to encourage the encoder to out-\n",
            "put similar intermediate representations Hx\n",
            "andHx0forxandx0to achieve an invariantencoder, which benets outputting the same\n",
            "translations. We cast this objective in the ad-\n",
            "versarial learning framework.\n",
            "Lnoisy(x0;y)to guide the decoder to generate\n",
            "output ygiven the noisy input x0, which is\n",
            "modeled as\u0000logP(yjx0). It can also be de-\n",
            "ned as KL divergence between P(yjx)and\n",
            "P(yjx0)that indicates using P(yjx)to teach\n",
            "P(yjx0).\n",
            "As seen, the two introduced objectives aim to im-\n",
            "prove the robustness of the NMT model which can\n",
            "be free of high variances in target outputs caused\n",
            "by small perturbations in inputs. It is also natural\n",
            "to introduce the original training objective L(x;y)\n",
            "onxandy, which can guarantee good transla-\n",
            "tion performance while keeping the stability of the\n",
            "NMT model.\n",
            "Formally, given a training corpus S, the adver-\n",
            "sarial stability training objective is\n",
            "J(\u0012)\n",
            "=X\n",
            "hx;yi2S\u0010\n",
            "Ltrue(x;y;\u0012enc;\u0012dec)\n",
            "+\u000bX\n",
            "x02N(x)Linv(x;x0;\u0012enc;\u0012dis)\n",
            "+\fX\n",
            "x02N(x)Lnoisy(x0;y;\u0012enc;\u0012dec)\u0011\n",
            "(4)\n",
            "whereLtrue(x;y)andLnoisy(x0;y)are calculated\n",
            "using Equation 3, and Linv(x;x0)is the adversar-\n",
            "ial loss to be described in Section 3.3. \u000band\f\n",
            "control the balance between the original transla-\n",
            "tion task and the stability of the NMT model. \u0012=\n",
            "f\u0012enc;\u0012dec;\u0012disgare trainable parameters of the\n",
            "encoder, decoder, and the newly introduced dis-\n",
            "criminator used in adversarial learning. As seen,\n",
            "the parameters of encoder \u0012encand decoder \u0012dec\n",
            "are trained to minimize both the translation loss\n",
            "Ltrue(x;y)and the stability losses ( Lnoisy(x0;y)\n",
            "andLinv(x;x0)).\n",
            "SinceLnoisy(x0;y)evaluates the translation\n",
            "loss on the perturbed neighbour x0and its corre-\n",
            "sponding target sentence y, it means that we aug-\n",
            "ment the training data by adding perturbed neigh-\n",
            "bours, which can potentially improve the transla-\n",
            "tion performance. In this way, our approach not\n",
            "only makes the output of NMT models more ro-\n",
            "bust, but also improves the performance on the\n",
            "original translation task.In the following sections, we will rst describe\n",
            "how to construct perturbed inputs with different\n",
            "strategies to fulll different goals (Section 3.2),\n",
            "followed by the proposed adversarial learning\n",
            "mechanism for the perturbation-invariant encoder\n",
            "(Section 3.3). We conclude this section with the\n",
            "training strategy (Section 3.4).\n",
            "3.2 Constructing Perturbed Inputs\n",
            "At each training step, we need to generate a per-\n",
            "turbed neighbour set N(x)for each source sen-\n",
            "tence xfor adversarial stability training. In this\n",
            "paper, we propose two strategies to construct the\n",
            "perturbed inputs at multiple levels of representa-\n",
            "tions.\n",
            "The rst approach generates perturbed neigh-\n",
            "bours at the lexical level. Given an input sentence\n",
            "x, we randomly sample some word positions to\n",
            "be modied. Then we replace words at these posi-\n",
            "tions with other words in the vocabulary according\n",
            "to the following distribution:\n",
            "P(xjxi) =expfcos (E[xi];E[x])gP\n",
            "x2Vxnxiexpfcos (E[xi];E[x])g(5)\n",
            "where E[xi]is the word embedding for word xi,\n",
            "Vxnxiis the source vocabulary set excluding the\n",
            "wordxi, and cos (E[xi];E[x])measures the simi-\n",
            "larity between word xiandx. Thus we can change\n",
            "the word to another word with similar semantics.\n",
            "One potential problem of the above strategy is\n",
            "that it is hard to enumerate all possible positions\n",
            "and possible types to generate perturbed neigh-\n",
            "bours. Therefore, we propose a more general ap-\n",
            "proach to modifying the sentence at the feature\n",
            "level. Given a sentence, we can obtain the word\n",
            "embedding for each word. We add the Gaussian\n",
            "noise to a word embedding to simulate possible\n",
            "types of perturbations. That is\n",
            "E[x0\n",
            "i] =E[xi] +\u000f;\u000f\u0018N(0;\u001b2I) (6)\n",
            "where the vector \u000fis sampled from a Gaussian dis-\n",
            "tribution with variance \u001b2.\u001bis a hyper-parameter.\n",
            "We simply introduce Gaussian noise to all of word\n",
            "embeddings in x.\n",
            "The proposed scheme is a general framework\n",
            "where one can freely dene the strategies to con-\n",
            "struct perturbed inputs. We just present two pos-\n",
            "sible examples here. The rst strategy is poten-\n",
            "tially useful when the training data contains noisy\n",
            "words, while the latter is a more general strategyto improve the robustness of common NMT mod-\n",
            "els. In practice, one can design specic strategies\n",
            "for particular tasks. For example, we can replace\n",
            "correct words with their homonyms (same pronun-\n",
            "ciation but different meanings) to improve NMT\n",
            "models for simultaneous translation systems.\n",
            "3.3 Adversarial Learning for the\n",
            "Perturbation-invariant Encoder\n",
            "The goal of the perturbation-invariant encoder is\n",
            "to make the representations produced by the en-\n",
            "coder indistinguishable when fed with a correct\n",
            "sentence xand its perturbed counterpart x0, which\n",
            "is directly benecial to the output robustness of\n",
            "the decoder. We cast the problem in the adversar-\n",
            "ial learning framework (Goodfellow et al., 2014).\n",
            "The encoder serves as the generator G, which de-\n",
            "nes the policy that generates a sequence of hid-\n",
            "den representations Hxgiven an input sentence x.\n",
            "We introduce an additional discriminator Dto dis-\n",
            "tinguish the representation of perturbed input Hx0\n",
            "from that of the original input Hx. The goal of\n",
            "the generator G(i.e., encoder) is to produce sim-\n",
            "ilar representations for xandx0which could fool\n",
            "the discriminator, while the discriminator Dtries\n",
            "to correctly distinguish the two representations.\n",
            "Formally, the adversarial learning objective is\n",
            "Linv(x;x0;\u0012enc;\u0012dis)\n",
            "=Ex\u0018S[\u0000logD(G(x))] +\n",
            "Ex0\u0018N(x)\u0002\n",
            "\u0000log(1\u0000D(G(x0)))\u0003\n",
            "(7)\n",
            "The discriminator outputs a classication score\n",
            "given an input representation, and tries to max-\n",
            "imizeD(G(x))to 1 and minimize D(G(x0))to\n",
            "0. The objective encourages the encoder to output\n",
            "similar representations for xandx0, so that the\n",
            "discriminator fails to distinguish them.\n",
            "The training procedure can be regarded as a\n",
            "min-max two-player game. The encoder parame-\n",
            "ters\u0012encare trained to maximize the loss function\n",
            "to fool the discriminator. The discriminator pa-\n",
            "rameters \u0012disare optimized to minimize this loss\n",
            "for improving the discriminating ability. For ef-\n",
            "ciency, we update both the encoder and the dis-\n",
            "criminator simultaneously at each iteration, rather\n",
            "than the periodical training strategy that is com-\n",
            "monly used in adversarial learning. Lamb et al.\n",
            "(2016) also propose a similar idea to use Professor\n",
            "Forcing to make the behaviors of RNNs be indis-\n",
            "tinguishable when training and sampling the net-\n",
            "works.3.4 Training\n",
            "As shown in Figure 1, our training objective in-\n",
            "cludes three sets of model parameters for three\n",
            "modules. We use mini-batch stochastic gradient\n",
            "descent to optimize our model. In the forward\n",
            "pass, besides a mini-batch of xandy, we also\n",
            "construct a mini-batch consisting of the perturbed\n",
            "neighbour x0andy. We propagate the informa-\n",
            "tion to calculate these three loss functions accord-\n",
            "ing to arrows. Then, gradients are collected to up-\n",
            "date three sets of model parameters. Except for\n",
            "the gradients ofLinvwith respect to \u0012encare mul-\n",
            "tiplying by\u00001, other gradients are normally back-\n",
            "propagated. Note that we update \u0012invand\u0012encsi-\n",
            "multaneously for training efciency.\n",
            "4 Experiments\n",
            "4.1 Setup\n",
            "We evaluated our adversarial stability training on\n",
            "translation tasks of several language pairs, and re-\n",
            "ported the 4-gram BLEU (Papineni et al., 2002)\n",
            "score as calculated by the multi-bleu.perl script.\n",
            "Chinese-English We used the LDC corpus con-\n",
            "sisting of 1.25M sentence pairs with 27.9M Chi-\n",
            "nese words and 34.5M English words respectively.\n",
            "We selected the best model using the NIST 2006\n",
            "set as the validation set (hyper-parameter opti-\n",
            "mization and model selection). The NIST 2002,\n",
            "2003, 2004, 2005, and 2008 datasets are used as\n",
            "test sets.\n",
            "English-German We used the WMT 14 corpus\n",
            "containing 4.5M sentence pairs with 118M En-\n",
            "glish words and 111M German words. The vali-\n",
            "dation set is newstest2013, and the test set is new-\n",
            "stest2014.\n",
            "English-French We used the IWSLT corpus\n",
            "which contains 0.22M sentence pairs with 4.03M\n",
            "English words and 4.12M French words. The\n",
            "IWLST corpus is very dissimilar from the NIST\n",
            "and WMT corpora. As they are collected from\n",
            "TED talks and inclined to spoken language,\n",
            "we want to verify our approaches on the non-\n",
            "normative text. The IWSLT 14 test set is taken\n",
            "as the validation set and 15 test set is used as the\n",
            "test set.\n",
            "For English-German and English-French, we\n",
            "tokenize both English, German and French words\n",
            "using tokenize.perl script. We follow Sen-\n",
            "nrich et al. (2016b) to split words into sub-\n",
            "word units. The numbers of merge operations\n",
            "in byte pair encoding (BPE) are set to 30K,40K and 30K respectively for Chinese-English,\n",
            "English-German, and English-French. We re-\n",
            "port the case-sensitive tokenized BLEU score for\n",
            "English-German and English-French and the case-\n",
            "insensitive tokenized BLEU score for Chinese-\n",
            "English.\n",
            "Our baseline system is an in-house NMT sys-\n",
            "tem. Following Bahdanau et al. (2015), we im-\n",
            "plement an RNN-based NMT in which both the\n",
            "encoder and decoder are two-layer RNNs with\n",
            "residual connections between layers (He et al.,\n",
            "2016b). The gating mechanism of RNNs is gated\n",
            "recurrent unit (GRUs) (Cho et al., 2014). We\n",
            "apply layer normalization (Ba et al., 2016) and\n",
            "dropout (Hinton et al., 2012) to the hidden states\n",
            "of GRUs. Dropout is also added to the source and\n",
            "target word embeddings. We share the same ma-\n",
            "trix between the target word embeedings and the\n",
            "pre-softmax linear transformation (Vaswani et al.,\n",
            "2017). We update the set of model parameters us-\n",
            "ing Adam SGD (Kingma and Ba, 2015). Its learn-\n",
            "ing rate is initially set to 0:05and varies according\n",
            "to the formula in Vaswani et al. (2017).\n",
            "Our adversarial stability training initializes the\n",
            "model based on the parameters trained by maxi-\n",
            "mum likelihood estimation (MLE). We denote ad-\n",
            "versarial stability training based on lexical-level\n",
            "perturbations and feature-level perturbations re-\n",
            "spectively as AST lexical and AST feature . We only\n",
            "sample one perturbed neighbour x02N (x)for\n",
            "training efciency. For the discriminator used in\n",
            "Linv, we adopt the CNN discriminator proposed\n",
            "by Kim (2014) to address the variable-length prob-\n",
            "lem of the sequence generated by the encoder. In\n",
            "the CNN discriminator, the lter windows are set\n",
            "to 3, 4, 5 and rectied linear units are applied af-\n",
            "ter convolution operations. We tune the hyper-\n",
            "parameters on the validation set through a grid\n",
            "search. We nd that both the optimal values of\n",
            "\u000band\fare set to 1:0. The standard variance in\n",
            "Gaussian noise used in the formula (6) is set to\n",
            "0:01. The number of words that are replaced in\n",
            "the sentence xduring lexical-level perturbations is\n",
            "taken as max(0:2jxj;1)in whichjxjis the length\n",
            "ofx. The default beam size for decoding is 10.\n",
            "4.2 Translation Results\n",
            "4.2.1 NIST Chinese-English Translation\n",
            "Table 2 shows the results on Chinese-English\n",
            "translation. Our strong baseline system signi-\n",
            "cantly outperforms previously reported results onSystem Training MT06 MT02 MT03 MT04 MT05 MT08\n",
            "Shen et al. (2016) MRT 37.34 40.36 40.93 41.37 38.81 29.23\n",
            "Wang et al. (2017) MLE 37.29  39.35 41.15 38.07 \n",
            "Zhang et al. (2018) MLE 38.38  40.02 42.32 38.84 \n",
            "this workMLE 41.38 43.52 41.50 43.64 41.58 31.60\n",
            "AST lexical 43.57 44.82 42.95 45.05 43.45 34.85\n",
            "AST feature 44.44 46.10 44.07 45.61 44.06 34.94\n",
            "Table 2: Case-insensitive BLEU scores on Chinese-English translation.\n",
            "System Architecture Training BLEU\n",
            "Shen et al. (2016) Gated RNN with 1 layer MRT 20.45\n",
            "Luong et al. (2015) LSTM with 4 layers MLE 20.90\n",
            "Kalchbrenner et al. (2017) ByteNet with 30 layers MLE 23.75\n",
            "Wang et al. (2017) DeepLAU with 4 layers MLE 23.80\n",
            "Wu et al. (2016) LSTM with 8 layers RL 24.60\n",
            "Gehring et al. (2017) CNN with 15 layers MLE 25.16\n",
            "Vaswani et al. (2017) Self-attention with 6 layers MLE 28.40\n",
            "this work Gated RNN with 2 layersMLE 24.06\n",
            "AST lexical 25.17\n",
            "AST feature 25.26\n",
            "Table 3: Case-sensitive BLEU scores on WMT 14 English-German translation.\n",
            "Training tst2014 tst2015\n",
            "MLE 36.92 36.90\n",
            "AST lexical 37.35 37.03\n",
            "AST feature 38.03 37.64\n",
            "Table 4: Case-sensitive BLEU scores on IWSLT\n",
            "English-French translation.\n",
            "Chinese-English NIST datasets trained on RNN-\n",
            "based NMT. Shen et al. (2016) propose minimum\n",
            "risk training (MRT) for NMT, which directly op-\n",
            "timizes model parameters with respect to BLEU\n",
            "scores. Wang et al. (2017) address the issue of\n",
            "severe gradient diffusion with linear associative\n",
            "units (LAU). Their system is deep with an encoder\n",
            "of 4 layers and a decoder of 4 layers. Zhang et al.\n",
            "(2018) propose to exploit both left-to-right and\n",
            "right-to-left decoding strategies for NMT to cap-\n",
            "ture bidirectional dependencies. Compared with\n",
            "them, our NMT system trained by MLE outper-\n",
            "forms their best models by around 3 BLEU points.\n",
            "We hope that the strong baseline systems used in\n",
            "this work make the evaluation convincing.\n",
            "We nd that introducing adversarial stability\n",
            "training into NMT can bring substantial improve-\n",
            "ments over previous work (up to +3:16BLEUpoints over Shen et al. (2016), up to +3:51\n",
            "BLEU points over Wang et al. (2017) and up to\n",
            "+2:74BLEU points over Zhang et al. (2018))\n",
            "and our system trained with MLE across all the\n",
            "datasets. Compared with our baseline system,\n",
            "AST lexical achieves +1:75BLEU improvement on\n",
            "average. AST feature performs better, which can\n",
            "obtain +2:59BLEU points on average and up to\n",
            "+3:34BLEU points on NIST08.\n",
            "4.2.2 WMT 14 English-German Translation\n",
            "In Table 3, we list existing NMT systems as com-\n",
            "parisons. All these systems use the same WMT 14\n",
            "English-German corpus. Except that Shen et al.\n",
            "(2016) and Wu et al. (2016) respectively adopt\n",
            "MRT and reinforcement learning (RL), other sys-\n",
            "tems all use MLE as training criterion. All the sys-\n",
            "tems except for Shen et al. (2016) are deep NMT\n",
            "models with no less than four layers. Googles\n",
            "neural machine translation (GNMT) (Wu et al.,\n",
            "2016) represents a strong RNN-based NMT sys-\n",
            "tem. Compared with other RNN-based NMT sys-\n",
            "tems except for GNMT, our baseline system with\n",
            "two layers can achieve better performance than\n",
            "theirs.\n",
            "When training our NMT system with\n",
            "AST leixcal , signicant improvement ( +1:11Synthetic Type Training 0 Op. 1 Op. 2 Op. 3 Op. 4 Op. 5 Op.\n",
            "SwapMLE 41.38 38.86 37.23 35.97 34.61 32.96\n",
            "AST lexical 43.57 41.18 39.88 37.95 37.02 36.16\n",
            "AST feature 44.44 42.08 40.20 38.67 36.89 35.81\n",
            "ReplacementMLE 41.38 37.21 31.40 27.43 23.94 21.03\n",
            "AST lexical 43.57 40.53 37.59 35.19 32.56 30.42\n",
            "AST feature 44.44 40.04 35.00 30.54 27.42 24.57\n",
            "DeletionMLE 41.38 38.45 36.15 33.28 31.17 28.65\n",
            "AST lexical 43.57 41.89 38.56 36.14 34.09 31.77\n",
            "AST feature 44.44 41.75 39.06 36.16 33.49 30.90\n",
            "Table 5: Translation results of synthetic perturbations on the validation set in Chinese-English translation.\n",
            "1 Op. denotes that we conduct one operation (swap, replacement or deletion) on the original sentence.\n",
            "Source zhongguo dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing\n",
            "Reference chinas new management rules for e-banking operations to take effect on march 1\n",
            "MLE chinas electronic bank rules to be implemented on march 1\n",
            "AST lexicalnew rules for business administration of china s electronic banking industry\n",
            "will come into effect on march 1 .\n",
            "AST featurenew rules for business management of china s electronic banking industry to\n",
            "come into effect on march 1\n",
            "Perturbed Source zhongfang dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing\n",
            "MLE china to implement new regulations on business management\n",
            "AST lexicalthe new regulations for the business administrations of the chinese electronics\n",
            "bank will come into effect on march 1 .\n",
            "AST featurenew rules for business management of chinas electronic banking industry to\n",
            "come into effect on march 1\n",
            "Table 6: Example translations of a source sentence and its perturbed counterpart by replacing a Chinese\n",
            "word zhongguo with its synonym zhongfang.\n",
            "BLEU points) can be observed. AST feature\n",
            "can obtain slightly better performance. Our\n",
            "NMT system outperforms the state-of-the-art\n",
            "RNN-based NMT system, GNMT, with +0:66\n",
            "BLEU point and performs comparably with\n",
            "Gehring et al. (2017) which is based on CNN\n",
            "with 15 layers. Given that our approach can be\n",
            "applied to any NMT systems, we expect that\n",
            "the adversarial stability training mechanism can\n",
            "further improve performance upon the advanced\n",
            "NMT architectures. We leave this for future work.\n",
            "4.2.3 IWSLT English-French Translation\n",
            "Table 4 shows the results on IWSLT English-\n",
            "French Translation. Compared with our strong\n",
            "baseline system trained by MLE, we observe that\n",
            "our models consistently improve translation per-\n",
            "formance in all datasets. AST feature can achieve\n",
            "signicant improvements on the tst2015 although\n",
            "AST lexical obtains comparable results. Thesedemonstrate that our approach maintains good per-\n",
            "formance on the non-normative text.\n",
            "4.3 Results on Synthetic Perturbed Data\n",
            "In order to investigate the ability of our training\n",
            "approaches to deal with perturbations, we experi-\n",
            "ment with three types of synthetic perturbations:\n",
            "Swap : We randomly choose Npositions\n",
            "from a sentence and then swap the chosen\n",
            "words with their right neighbours.\n",
            "Replacement : We randomly replace sam-\n",
            "pled words in the sentence with other words.\n",
            "Deletion : We randomly delete Nwords from\n",
            "each sentence in the dataset.\n",
            "As shown in Table 5, we can nd that our train-\n",
            "ing approaches, AST lexical and AST feature , consis-\n",
            "tently outperform MLE against perturbations on\n",
            "all the numbers of operations. This means that ourLtrueLnoisyLinv BLEUp\u0002 \u0002 41.38p\u0002p41.91\n",
            "\u0002p\u0002 42.20p p\u0002 42.93p p p43.57\n",
            "Table 7: Ablation study of adversarial stabil-\n",
            "ity training AST lexical on Chinese-English trans-\n",
            "lation. p means the loss function is included in\n",
            "the training objective while  \u0002 means it is not.\n",
            "approaches have the capability of resisting pertur-\n",
            "bations. Along with the number of operations in-\n",
            "creasing, the performance on MLE drops quickly.\n",
            "Although the performance of our approaches also\n",
            "drops, we can see that our approaches consistently\n",
            "surpass MLE. In AST lexical , with 0 operation, the\n",
            "difference is +2.19 (43.57 Vs. 41.38) for all syn-\n",
            "thetic types, but the differences are enlarged to\n",
            "+3.20, +9.39, and +3.12 respectively for the three\n",
            "types with 5 operations.\n",
            "In the Swap andDeletion types, AST lexical and\n",
            "AST feature perform comparably after more than\n",
            "four operations. Interestingly, AST lexical per-\n",
            "forms signicantly better than both of MLE and\n",
            "AST feature after more than one operation in the\n",
            "Replacement type. This is because AST lexical\n",
            "trains the model specically on perturbation data\n",
            "that is constructed by replacing words, which\n",
            "agrees with the Replacement Type. Overall,\n",
            "AST lexical performs better than AST feature against\n",
            "perturbations after multiple operations. We spec-\n",
            "ulate that the perturbation method for AST lexical\n",
            "and synthetic type are both discrete and they keep\n",
            "more consistent. Table 6 shows example transla-\n",
            "tions of a Chinese sentence and its perturbed coun-\n",
            "terpart.\n",
            "These ndings indicate that we can construct\n",
            "specic perturbations for a particular task. For\n",
            "example, in simultaneous translation, an auto-\n",
            "matic speech recognition system usually generates\n",
            "wrong words with the same pronunciation of cor-\n",
            "rect words, which dramatically affects the quality\n",
            "of machine translation system. Therefore, we can\n",
            "design specic perturbations aiming for this task.\n",
            "4.4 Analysis\n",
            "4.4.1 Ablation Study\n",
            "Our training objective function Eq. (4) contains\n",
            "three loss functions. We perform an ablation\n",
            "Iterations0 20 40 60 80 100 120 140 160 180 200BLEU\n",
            "34363840424446\n",
            " 103ASTlexical\n",
            "ASTfeatureFigure 2: BLEU scores of AST lexical over itera-\n",
            "tions on Chinese-English validation set.\n",
            "Iterations0 50 100 150 200Cost\n",
            "0.511.522.533.544.55\n",
            " 103Lnoisy\n",
            "Ltrue\n",
            "Linv\n",
            "Figure 3: Learning curves of three loss functions,\n",
            "Ltrue,LinvandLnoisy over iterations on Chinese-\n",
            "English validation set.\n",
            "study on the Chinese-English translation to under-\n",
            "stand the importance of these loss functions by\n",
            "choosing AST lexical as an example. As Table 7\n",
            "shows, if we remove Ladv, the translation perfor-\n",
            "mance decreases by 0:64BLEU point. However,\n",
            "whenLnoisy is excluded from the training objec-\n",
            "tive function, it results in a signicant drop of 1:66\n",
            "BLEU point. Surprisingly, only using Lnoisy is\n",
            "able to lead to an increase of 0:88BLEU point.\n",
            "4.4.2 BLEU Scores over Iterations\n",
            "Figure 2 shows the changes of BLEU scores\n",
            "over iterations respectively for AST lexical and\n",
            "AST feature . They behave nearly consistently. Ini-\n",
            "tialized by the model trained by MLE, their per-\n",
            "formance drops rapidly. Then it starts to go up\n",
            "quickly. Compared with the starting point, themaximal dropping points reach up to about 7:0\n",
            "BLEU points. Basically, the curves present the\n",
            "state of oscillation. We think that introducing\n",
            "random perturbations and adversarial learning can\n",
            "make the training not very stable like MLE.\n",
            "4.4.3 Learning Curves of Loss Functions\n",
            "Figure 3 shows the learning curves of three loss\n",
            "functions,Ltrue,LinvandLnoisy. We can nd that\n",
            "their costs of loss functions decrease not steadily.\n",
            "Similar to the Figure 2, there still exist oscilla-\n",
            "tions in the learning curves although they do not\n",
            "change much sharply. We nd that Linvconverges\n",
            "to around 0:68after about 100Kiterations, which\n",
            "indicates that discriminator outputs probability 0:5\n",
            "for both positive and negative samples and it can-\n",
            "not distinguish them. Thus the behaviors of the\n",
            "encoder for xand its perturbed neighbour x0per-\n",
            "form nearly consistently.\n",
            "5 Related Work\n",
            "Our work is inspired by two lines of research: (1)\n",
            "adversarial learning and (2) data augmentation.\n",
            "Adversarial Learning Generative Adversarial\n",
            "Network (GAN) (Goodfellow et al., 2014) and\n",
            "its related derivative have been widely applied\n",
            "in computer vision (Radford et al., 2015; Sali-\n",
            "mans et al., 2016) and natural language process-\n",
            "ing (Li et al., 2017; Yang et al., 2018). Previous\n",
            "work has constructed adversarial examples to at-\n",
            "tack trained networks and make networks resist\n",
            "them, which has proved to improve the robust-\n",
            "ness of networks (Goodfellow et al., 2015; Miy-\n",
            "ato et al., 2016; Zheng et al., 2016). Belinkov\n",
            "and Bisk (2018) introduce adversarial examples\n",
            "to training data for character-based NMT models.\n",
            "In contrast to theirs, adversarial stability training\n",
            "aims to stabilize both the encoder and decoder in\n",
            "NMT models. We adopt adversarial learning to\n",
            "learn the perturbation-invariant encoder.\n",
            "Data Augmentation Data augmentation has the\n",
            "capability to improve the robustness of NMT mod-\n",
            "els. In NMT, there is a number of work that aug-\n",
            "ments the training data with monolingual corpora\n",
            "(Sennrich et al., 2016a; Cheng et al., 2016; He\n",
            "et al., 2016a; Zhang and Zong, 2016). They all\n",
            "leverage complex models such as inverse NMT\n",
            "models to generate translation equivalents for\n",
            "monolingual corpora. Then they augment the par-\n",
            "allel corpora with these pseudo corpora to improveNMT models. Some authors have recently en-\n",
            "deavored to achieve zero-shot NMT through trans-\n",
            "ferring knowledge from bilingual corpora of other\n",
            "language pairs (Chen et al., 2017; Zheng et al.,\n",
            "2017; Cheng et al., 2017) or monolingual corpora\n",
            "(Lample et al., 2018; Artetxe et al., 2018). Our\n",
            "work signicantly differs from these work. We do\n",
            "not resort to any complicated models to generate\n",
            "perturbed data and do not depend on extra mono-\n",
            "lingual or bilingual corpora. The way we exploit\n",
            "is more convenient and easy to implement. We\n",
            "focus more on improving the robustness of NMT\n",
            "models.\n",
            "6 Conclusion\n",
            "We have proposed adversarial stability training to\n",
            "improve the robustness of NMT models. The ba-\n",
            "sic idea is to train both the encoder and decoder\n",
            "robust to input perturbations by enabling them to\n",
            "behave similarly for the original input and its per-\n",
            "turbed counterpart. We propose two approaches\n",
            "to construct perturbed data to adversarially train\n",
            "the encoder and stabilize the decoder. Experi-\n",
            "ments on Chinese-English, English-German and\n",
            "English-French translation tasks show that the pro-\n",
            "posed approach can improve both the robustness\n",
            "and translation performance.\n",
            "As our training framework is not limited to spe-\n",
            "cic perturbation types, it is interesting to evalu-\n",
            "ate our approach in natural noise existing in prac-\n",
            "tical applications, such as homonym in the simul-\n",
            "taneous translation system. It is also necessary to\n",
            "further validate our approach on more advanced\n",
            "NMT architectures, such as CNN-based NMT\n",
            "(Gehring et al., 2017) and Transformer (Vaswani\n",
            "et al., 2017).\n",
            "Acknowledgments\n",
            "We thank the anonymous reviewers for their in-\n",
            "sightful comments and suggestions. We also thank\n",
            "Xiaoling Li for analyzing experimental results and\n",
            "providing valuable examples. Yang Liu is sup-\n",
            "ported by the National Key R&D Program of\n",
            "China (No. 2017YFB0202204), National Natural\n",
            "Science Foundation of China (No. 61761166008,\n",
            "No. 61522204), Beijing Advanced Innovation\n",
            "Center for Language Resources, and the NExT++\n",
            "project supported by the National Research Foun-\n",
            "dation, Prime Ministers Ofce, Singapore under\n",
            "its IRC@Singapore Funding Initiative.\n"
          ]
        }
      ],
      "source": [
        "# Removing non-ascii characters, urls from extracted text\n",
        "\n",
        "text_without_non_ascii = re.sub(r\"[^\\x00-\\x7F]\", \"\", extracted_text)\n",
        "text_without_non_ascii = re.sub(r\",.-/:\",\"\",text_without_non_ascii)\n",
        "cleaned_text = re.sub(r\"h/t_tps?://[^\\s]+\",\"\",text_without_non_ascii)\n",
        "\n",
        "print(cleaned_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RomL4FpaC-Wu",
        "outputId": "2bcd4247-2ead-4713-949e-a6b6942d6010"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Copying the header names within a new variable\n",
        "\n",
        "sections = new_output\n",
        "len(sections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvDA0BdZC-Wu",
        "outputId": "ef2b7482-4f26-43d0-b378-f7c0c49266df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Markers found in the text. Abstract\n",
            "Markers found in the text. 1 Introduction\n",
            "Markers found in the text. 2 Background\n",
            "Markers found in the text. 3 Approach\n",
            "Markers found in the text. 4 Experiments\n",
            "Markers found in the text. 5 Related Work\n",
            "Markers found in the text. 6 Conclusion\n"
          ]
        }
      ],
      "source": [
        "# Extraction of text under individual sections of pdfs using the header names\n",
        "\n",
        "section_extraction = []\n",
        "\n",
        "for i in range(len(sections)-1):\n",
        "    start_index = cleaned_text.find(sections[i])\n",
        "    end_index = cleaned_text.find(sections[i+1])\n",
        "\n",
        "    if start_index != -1 and end_index != -1:\n",
        "        extraction = cleaned_text[start_index:end_index].strip()\n",
        "        print(\"Markers found in the text.\",sections[i])\n",
        "        section_extraction.append(extraction)\n",
        "    else:\n",
        "        print(\"Markers not found in the text.\",sections[i])\n",
        "\n",
        "# Extract the last section separately\n",
        "last_start_index = cleaned_text.find(sections[-1])\n",
        "if last_start_index != -1:\n",
        "    last_extraction = cleaned_text[last_start_index:].strip()\n",
        "    print(\"Markers found in the text.\", sections[-1])\n",
        "    section_extraction.append(last_extraction)\n",
        "else:\n",
        "    print(\"Markers not found in the text.\", sections[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOM4NXbZC-Wu",
        "outputId": "2c514c1f-683b-440e-fbc2-ad12adac6dc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Abstract\\nSmall perturbations in the input can\\nseverely distort intermediate representa-\\ntions and thus impact translation quality of\\nneural machine translation (NMT) mod-\\nels. In this paper, we propose to improve\\nthe robustness of NMT models with adver-\\nsarial stability training. The basic idea is\\nto make both the encoder and decoder in\\nNMT models robust against input pertur-\\nbations by enabling them to behave sim-\\nilarly for the original input and its per-\\nturbed counterpart. Experimental results\\non Chinese-English, English-German and\\nEnglish-French translation tasks show that\\nour approaches can not only achieve sig-\\nnicant improvements over strong NMT\\nsystems but also improve the robustness of\\nNMT models.',\n",
              " '1 Introduction\\nNeural machine translation (NMT) models have\\nadvanced the state of the art by building a sin-\\ngle neural network that can better learn represen-\\ntations (Cho et al., 2014; Sutskever et al., 2014).\\nThe neural network consists of two components:\\nan encoder network that encodes the input sen-\\ntence into a sequence of distributed representa-\\ntions, based on which a decoder network generates\\nthe translation with an attention model (Bahdanau\\net al., 2015; Luong et al., 2015). A variety of NMT\\nmodels derived from this encoder-decoder frame-\\nwork have further improved the performance of\\nmachine translation systems (Gehring et al., 2017;\\nVaswani et al., 2017). NMT is capable of general-\\nizing better to unseen text by exploiting word simi-\\nlarities in embeddings and capturing long-distance\\nreordering by conditioning on larger contexts in a\\ncontinuous way.Input tamen bupa kunnan zuochu weiqi AI.\\nOutputThey are not afraid of difculties to\\nmake Go AI.\\nInput tamen buwei kunnan zuochu weiqi AI.\\nOutput They are not afraid to make Go AI.\\nTable 1: The non-robustness problem of neural\\nmachine translation. Replacing a Chinese word\\nwith its synonym (i.e.,  bupa !buwei ) leads to\\nsignicant erroneous changes in the English trans-\\nlation. Both  bupa  and  buwei  can be translated\\nto the English phrase  be not afraid of .\\nHowever, studies reveal that very small changes\\nto the input can fool state-of-the-art neural net-\\nworks with high probability (Goodfellow et al.,\\n2015; Szegedy et al., 2014). Belinkov and Bisk\\n(2018) conrm this nding by pointing out that\\nNMT models are very brittle and easily falter\\nwhen presented with noisy input. In NMT, due\\nto the introduction of RNN and attention, each\\ncontextual word can inuence the model predic-\\ntion in a global context, which is analogous to the\\nbuttery effect. As shown in Table 1, although\\nwe only replace a source word with its synonym,\\nthe generated translation has been completely dis-\\ntorted. We investigate severe variations of trans-\\nlations caused by small input perturbations by re-\\nplacing one word in each sentence of a test set with\\nits synonym. We observe that 69:74% of transla-\\ntions have changed and the BLEU score is only\\n79:01between the translations of the original in-\\nputs and the translations of the perturbed inputs,\\nsuggesting that NMT models are very sensitive to\\nsmall perturbations in the input. The vulnerabil-\\nity and instability of NMT models limit their ap-\\nplicability to a broader range of tasks, which re-\\nquire robust performance on noisy inputs. For ex-\\nample, simultaneous translation systems use auto-arXiv:1805.06130v1  [cs.CL]  16 May 2018matic speech recognition (ASR) to transcribe in-\\nput speech into a sequence of hypothesized words,\\nwhich are subsequently fed to a translation sys-\\ntem. In this pipeline, ASR errors are presented as\\nsentences with noisy perturbations (the same pro-\\nnunciation but incorrect words), which is a signif-\\nicant challenge for current NMT models. More-\\nover, instability makes NMT models sensitive to\\nmisspellings and typos in text translation.\\nIn this paper, we address this challenge with\\nadversarial stability training for neural machine\\ntranslation. The basic idea is to improve the ro-\\nbustness of two important components in NMT:\\nthe encoder and decoder. To this end, we pro-\\npose two approaches to constructing noisy inputs\\nwith small perturbations to make NMT models re-\\nsist them. As important intermediate representa-\\ntions encoded by the encoder, they directly deter-\\nmine the accuracy of nal translations. We intro-\\nduce adversarial learning to make behaviors of the\\nencoder consistent for both an input and its per-\\nturbed counterpart. To improve the stability of the\\ndecoder, our method jointly maximizes the likeli-\\nhoods of original and perturbed data. Adversarial\\nstability training has the following advantages:\\n1.Improving both the robustness and transla-\\ntion performance : Our adversarial stability\\ntraining is capable of not only improving the\\nrobustness of NMT models but also achiev-\\ning better translation performance.\\n2.Applicable to arbitrary noisy perturbations :\\nIn this paper, we propose two approaches to\\nconstructing noisy perturbations for inputs.\\nHowever, our training framework can be eas-\\nily extended to arbitrary noisy perturbations.\\nEspecially, we can design task-specic per-\\nturbation methods.\\n3.Transparent to network architectures : Our\\nadversarial stability training does not depend\\non specic NMT architectures. It can be ap-\\nplied to arbitrary NMT systems.\\nExperiments on Chinese-English, English-\\nFrench and English-German translation tasks\\nshow that adversarial stability training achieves\\nsignicant improvements across different lan-\\nguages pairs. Our NMT system outperforms\\nthe state-of-the-art RNN-based NMT system\\n(GNMT) (Wu et al., 2016) and obtains compara-\\nble performance with the CNN-based NMT sys-tem (Gehring et al., 2017). Related experimen-\\ntal analyses validate that our training approach can\\nimprove the robustness of NMT models.',\n",
              " '2 Background\\nNMT is an end-to-end framework which directly\\noptimizes the translation probability of a target\\nsentence y=y1;:::;y Ngiven its corresponding\\nsource sentence x=x1;:::;x M:\\nP(yjx;\\x12) =NY\\nn=1P(ynjy<n;x;\\x12) (1)\\nwhere \\x12is a set of model parameters and y<nis a\\npartial translation. P(yjx;\\x12)is dened on a holis-\\ntic neural network which mainly includes two core\\ncomponents: an encoder encodes a source sen-\\ntencexinto a sequence of hidden representations\\nHx=H1;:::;HM, and a decoder generates the\\nn-th target word based on the sequence of hidden\\nrepresentations:\\nP(ynjy<n;x;\\x12)/expfg(yn\\x001;sn;Hx;\\x12)g(2)\\nwhere snis then-th hidden state on target side.\\nThus the model parameters of NMT include the\\nparameter sets of the encoder \\x12encand the decoder\\n\\x12dec:\\x12=f\\x12enc;\\x12decg. The standard training ob-\\njective is to minimize the negative log-likelihood\\nof the training corpus S=fhx(s);y(s)igjSj\\ns=1:\\n^\\x12= argmin\\n\\x12L(x;y;\\x12)\\n= argmin\\n\\x12nX\\nhx;yi2S\\x00logP(yjx;\\x12)o\\n(3)\\nDue to the vulnerability and instability of deep\\nneural networks, NMT models usually suffer from\\na drawback: small perturbations in the input can\\ndramatically deteriorate its translation results. Be-\\nlinkov and Bisk (2018) point out that character-\\nbased NMT models are very brittle and easily fal-\\nter when presented with noisy input. We nd\\nthat word-based and subword-based NMT mod-\\nels also confront with this shortcoming, as shown\\nin Table 1. We argue that the distributed repre-\\nsentations should fulll the stability expectation,\\nwhich is the underlying concept of the proposed\\napproach. Recent work has shown that adversar-\\nially trained models can be made robust to such\\nperturbations (Zheng et al., 2016; Madry et al.,\\n2018). Inspired by this, in this work, we im-\\nprove the robustness of encoder representations\\nagainst noisy perturbations with adversarial learn-\\ning (Goodfellow et al., 2014).xx+perturbations\\nEncoderHxHx\\nDecoder\\nDiscriminatorLinv(x, x)Ltrue(x, y)Lnoisy(x, y)Figure 1: The architecture of NMT with adversar-\\nial stability training. The dark solid arrow lines\\nrepresent the forward-pass information ow for\\nthe input sentence x, while the red dashed arrow\\nlines for the noisy input sentence x0, which is\\ntransformed from xby adding small perturbations.',\n",
              " '3 Approach\\n3.1 Overview\\nThe goal of this work is to propose a general ap-\\nproach to make NMT models learned to be more\\nrobust to input perturbations. Our basic idea is\\nto maintain the consistency of behaviors through\\nthe NMT model for the source sentence xand its\\nperturbed counterpart x0. As aforementioned, the\\nNMT model contains two procedures for project-\\ning a source sentence xto its target sentence y:\\nthe encoder is responsible for encoding xas a se-\\nquence of representations Hx, while the decoder\\noutputs ywithHxas input. We aim at learning\\nthe perturbation-invariant encoder and decoder.\\nFigure 1 illustrates the architecture of our ap-\\nproach. Given a source sentence x, we construct a\\nset of perturbed sentences N(x), in which each\\nsentence x0is constructed by adding small per-\\nturbations to x. We require that x0is a subtle\\nvariation from xand they have similar semantics.\\nGiven the input pair ( x,x0), we have two expecta-\\ntions: (1) the encoded representation Hx0should\\nbe close to Hx; and (2) given Hx0, the decoder is\\nable to generate the robust output y. To this end,\\nwe introduce two additional objectives to improve\\nthe robustness of the encoder and decoder:\\nLinv(x;x0)to encourage the encoder to out-\\nput similar intermediate representations Hx\\nandHx0forxandx0to achieve an invariantencoder, which benets outputting the same\\ntranslations. We cast this objective in the ad-\\nversarial learning framework.\\nLnoisy(x0;y)to guide the decoder to generate\\noutput ygiven the noisy input x0, which is\\nmodeled as\\x00logP(yjx0). It can also be de-\\nned as KL divergence between P(yjx)and\\nP(yjx0)that indicates using P(yjx)to teach\\nP(yjx0).\\nAs seen, the two introduced objectives aim to im-\\nprove the robustness of the NMT model which can\\nbe free of high variances in target outputs caused\\nby small perturbations in inputs. It is also natural\\nto introduce the original training objective L(x;y)\\nonxandy, which can guarantee good transla-\\ntion performance while keeping the stability of the\\nNMT model.\\nFormally, given a training corpus S, the adver-\\nsarial stability training objective is\\nJ(\\x12)\\n=X\\nhx;yi2S\\x10\\nLtrue(x;y;\\x12enc;\\x12dec)\\n+\\x0bX\\nx02N(x)Linv(x;x0;\\x12enc;\\x12dis)\\n+\\x0cX\\nx02N(x)Lnoisy(x0;y;\\x12enc;\\x12dec)\\x11\\n(4)\\nwhereLtrue(x;y)andLnoisy(x0;y)are calculated\\nusing Equation 3, and Linv(x;x0)is the adversar-\\nial loss to be described in Section 3.3. \\x0band\\x0c\\ncontrol the balance between the original transla-\\ntion task and the stability of the NMT model. \\x12=\\nf\\x12enc;\\x12dec;\\x12disgare trainable parameters of the\\nencoder, decoder, and the newly introduced dis-\\ncriminator used in adversarial learning. As seen,\\nthe parameters of encoder \\x12encand decoder \\x12dec\\nare trained to minimize both the translation loss\\nLtrue(x;y)and the stability losses ( Lnoisy(x0;y)\\nandLinv(x;x0)).\\nSinceLnoisy(x0;y)evaluates the translation\\nloss on the perturbed neighbour x0and its corre-\\nsponding target sentence y, it means that we aug-\\nment the training data by adding perturbed neigh-\\nbours, which can potentially improve the transla-\\ntion performance. In this way, our approach not\\nonly makes the output of NMT models more ro-\\nbust, but also improves the performance on the\\noriginal translation task.In the following sections, we will rst describe\\nhow to construct perturbed inputs with different\\nstrategies to fulll different goals (Section 3.2),\\nfollowed by the proposed adversarial learning\\nmechanism for the perturbation-invariant encoder\\n(Section 3.3). We conclude this section with the\\ntraining strategy (Section 3.4).\\n3.2 Constructing Perturbed Inputs\\nAt each training step, we need to generate a per-\\nturbed neighbour set N(x)for each source sen-\\ntence xfor adversarial stability training. In this\\npaper, we propose two strategies to construct the\\nperturbed inputs at multiple levels of representa-\\ntions.\\nThe rst approach generates perturbed neigh-\\nbours at the lexical level. Given an input sentence\\nx, we randomly sample some word positions to\\nbe modied. Then we replace words at these posi-\\ntions with other words in the vocabulary according\\nto the following distribution:\\nP(xjxi) =expfcos (E[xi];E[x])gP\\nx2Vxnxiexpfcos (E[xi];E[x])g(5)\\nwhere E[xi]is the word embedding for word xi,\\nVxnxiis the source vocabulary set excluding the\\nwordxi, and cos (E[xi];E[x])measures the simi-\\nlarity between word xiandx. Thus we can change\\nthe word to another word with similar semantics.\\nOne potential problem of the above strategy is\\nthat it is hard to enumerate all possible positions\\nand possible types to generate perturbed neigh-\\nbours. Therefore, we propose a more general ap-\\nproach to modifying the sentence at the feature\\nlevel. Given a sentence, we can obtain the word\\nembedding for each word. We add the Gaussian\\nnoise to a word embedding to simulate possible\\ntypes of perturbations. That is\\nE[x0\\ni] =E[xi] +\\x0f;\\x0f\\x18N(0;\\x1b2I) (6)\\nwhere the vector \\x0fis sampled from a Gaussian dis-\\ntribution with variance \\x1b2.\\x1bis a hyper-parameter.\\nWe simply introduce Gaussian noise to all of word\\nembeddings in x.\\nThe proposed scheme is a general framework\\nwhere one can freely dene the strategies to con-\\nstruct perturbed inputs. We just present two pos-\\nsible examples here. The rst strategy is poten-\\ntially useful when the training data contains noisy\\nwords, while the latter is a more general strategyto improve the robustness of common NMT mod-\\nels. In practice, one can design specic strategies\\nfor particular tasks. For example, we can replace\\ncorrect words with their homonyms (same pronun-\\nciation but different meanings) to improve NMT\\nmodels for simultaneous translation systems.\\n3.3 Adversarial Learning for the\\nPerturbation-invariant Encoder\\nThe goal of the perturbation-invariant encoder is\\nto make the representations produced by the en-\\ncoder indistinguishable when fed with a correct\\nsentence xand its perturbed counterpart x0, which\\nis directly benecial to the output robustness of\\nthe decoder. We cast the problem in the adversar-\\nial learning framework (Goodfellow et al., 2014).\\nThe encoder serves as the generator G, which de-\\nnes the policy that generates a sequence of hid-\\nden representations Hxgiven an input sentence x.\\nWe introduce an additional discriminator Dto dis-\\ntinguish the representation of perturbed input Hx0\\nfrom that of the original input Hx. The goal of\\nthe generator G(i.e., encoder) is to produce sim-\\nilar representations for xandx0which could fool\\nthe discriminator, while the discriminator Dtries\\nto correctly distinguish the two representations.\\nFormally, the adversarial learning objective is\\nLinv(x;x0;\\x12enc;\\x12dis)\\n=Ex\\x18S[\\x00logD(G(x))] +\\nEx0\\x18N(x)\\x02\\n\\x00log(1\\x00D(G(x0)))\\x03\\n(7)\\nThe discriminator outputs a classication score\\ngiven an input representation, and tries to max-\\nimizeD(G(x))to 1 and minimize D(G(x0))to\\n0. The objective encourages the encoder to output\\nsimilar representations for xandx0, so that the\\ndiscriminator fails to distinguish them.\\nThe training procedure can be regarded as a\\nmin-max two-player game. The encoder parame-\\nters\\x12encare trained to maximize the loss function\\nto fool the discriminator. The discriminator pa-\\nrameters \\x12disare optimized to minimize this loss\\nfor improving the discriminating ability. For ef-\\nciency, we update both the encoder and the dis-\\ncriminator simultaneously at each iteration, rather\\nthan the periodical training strategy that is com-\\nmonly used in adversarial learning. Lamb et al.\\n(2016) also propose a similar idea to use Professor\\nForcing to make the behaviors of RNNs be indis-\\ntinguishable when training and sampling the net-\\nworks.3.4 Training\\nAs shown in Figure 1, our training objective in-\\ncludes three sets of model parameters for three\\nmodules. We use mini-batch stochastic gradient\\ndescent to optimize our model. In the forward\\npass, besides a mini-batch of xandy, we also\\nconstruct a mini-batch consisting of the perturbed\\nneighbour x0andy. We propagate the informa-\\ntion to calculate these three loss functions accord-\\ning to arrows. Then, gradients are collected to up-\\ndate three sets of model parameters. Except for\\nthe gradients ofLinvwith respect to \\x12encare mul-\\ntiplying by\\x001, other gradients are normally back-\\npropagated. Note that we update \\x12invand\\x12encsi-\\nmultaneously for training efciency.',\n",
              " '4 Experiments\\n4.1 Setup\\nWe evaluated our adversarial stability training on\\ntranslation tasks of several language pairs, and re-\\nported the 4-gram BLEU (Papineni et al., 2002)\\nscore as calculated by the multi-bleu.perl script.\\nChinese-English We used the LDC corpus con-\\nsisting of 1.25M sentence pairs with 27.9M Chi-\\nnese words and 34.5M English words respectively.\\nWe selected the best model using the NIST 2006\\nset as the validation set (hyper-parameter opti-\\nmization and model selection). The NIST 2002,\\n2003, 2004, 2005, and 2008 datasets are used as\\ntest sets.\\nEnglish-German We used the WMT 14 corpus\\ncontaining 4.5M sentence pairs with 118M En-\\nglish words and 111M German words. The vali-\\ndation set is newstest2013, and the test set is new-\\nstest2014.\\nEnglish-French We used the IWSLT corpus\\nwhich contains 0.22M sentence pairs with 4.03M\\nEnglish words and 4.12M French words. The\\nIWLST corpus is very dissimilar from the NIST\\nand WMT corpora. As they are collected from\\nTED talks and inclined to spoken language,\\nwe want to verify our approaches on the non-\\nnormative text. The IWSLT 14 test set is taken\\nas the validation set and 15 test set is used as the\\ntest set.\\nFor English-German and English-French, we\\ntokenize both English, German and French words\\nusing tokenize.perl script. We follow Sen-\\nnrich et al. (2016b) to split words into sub-\\nword units. The numbers of merge operations\\nin byte pair encoding (BPE) are set to 30K,40K and 30K respectively for Chinese-English,\\nEnglish-German, and English-French. We re-\\nport the case-sensitive tokenized BLEU score for\\nEnglish-German and English-French and the case-\\ninsensitive tokenized BLEU score for Chinese-\\nEnglish.\\nOur baseline system is an in-house NMT sys-\\ntem. Following Bahdanau et al. (2015), we im-\\nplement an RNN-based NMT in which both the\\nencoder and decoder are two-layer RNNs with\\nresidual connections between layers (He et al.,\\n2016b). The gating mechanism of RNNs is gated\\nrecurrent unit (GRUs) (Cho et al., 2014). We\\napply layer normalization (Ba et al., 2016) and\\ndropout (Hinton et al., 2012) to the hidden states\\nof GRUs. Dropout is also added to the source and\\ntarget word embeddings. We share the same ma-\\ntrix between the target word embeedings and the\\npre-softmax linear transformation (Vaswani et al.,\\n2017). We update the set of model parameters us-\\ning Adam SGD (Kingma and Ba, 2015). Its learn-\\ning rate is initially set to 0:05and varies according\\nto the formula in Vaswani et al. (2017).\\nOur adversarial stability training initializes the\\nmodel based on the parameters trained by maxi-\\nmum likelihood estimation (MLE). We denote ad-\\nversarial stability training based on lexical-level\\nperturbations and feature-level perturbations re-\\nspectively as AST lexical and AST feature . We only\\nsample one perturbed neighbour x02N (x)for\\ntraining efciency. For the discriminator used in\\nLinv, we adopt the CNN discriminator proposed\\nby Kim (2014) to address the variable-length prob-\\nlem of the sequence generated by the encoder. In\\nthe CNN discriminator, the lter windows are set\\nto 3, 4, 5 and rectied linear units are applied af-\\nter convolution operations. We tune the hyper-\\nparameters on the validation set through a grid\\nsearch. We nd that both the optimal values of\\n\\x0band\\x0care set to 1:0. The standard variance in\\nGaussian noise used in the formula (6) is set to\\n0:01. The number of words that are replaced in\\nthe sentence xduring lexical-level perturbations is\\ntaken as max(0:2jxj;1)in whichjxjis the length\\nofx. The default beam size for decoding is 10.\\n4.2 Translation Results\\n4.2.1 NIST Chinese-English Translation\\nTable 2 shows the results on Chinese-English\\ntranslation. Our strong baseline system signi-\\ncantly outperforms previously reported results onSystem Training MT06 MT02 MT03 MT04 MT05 MT08\\nShen et al. (2016) MRT 37.34 40.36 40.93 41.37 38.81 29.23\\nWang et al. (2017) MLE 37.29  39.35 41.15 38.07 \\nZhang et al. (2018) MLE 38.38  40.02 42.32 38.84 \\nthis workMLE 41.38 43.52 41.50 43.64 41.58 31.60\\nAST lexical 43.57 44.82 42.95 45.05 43.45 34.85\\nAST feature 44.44 46.10 44.07 45.61 44.06 34.94\\nTable 2: Case-insensitive BLEU scores on Chinese-English translation.\\nSystem Architecture Training BLEU\\nShen et al. (2016) Gated RNN with 1 layer MRT 20.45\\nLuong et al. (2015) LSTM with 4 layers MLE 20.90\\nKalchbrenner et al. (2017) ByteNet with 30 layers MLE 23.75\\nWang et al. (2017) DeepLAU with 4 layers MLE 23.80\\nWu et al. (2016) LSTM with 8 layers RL 24.60\\nGehring et al. (2017) CNN with 15 layers MLE 25.16\\nVaswani et al. (2017) Self-attention with 6 layers MLE 28.40\\nthis work Gated RNN with 2 layersMLE 24.06\\nAST lexical 25.17\\nAST feature 25.26\\nTable 3: Case-sensitive BLEU scores on WMT 14 English-German translation.\\nTraining tst2014 tst2015\\nMLE 36.92 36.90\\nAST lexical 37.35 37.03\\nAST feature 38.03 37.64\\nTable 4: Case-sensitive BLEU scores on IWSLT\\nEnglish-French translation.\\nChinese-English NIST datasets trained on RNN-\\nbased NMT. Shen et al. (2016) propose minimum\\nrisk training (MRT) for NMT, which directly op-\\ntimizes model parameters with respect to BLEU\\nscores. Wang et al. (2017) address the issue of\\nsevere gradient diffusion with linear associative\\nunits (LAU). Their system is deep with an encoder\\nof 4 layers and a decoder of 4 layers. Zhang et al.\\n(2018) propose to exploit both left-to-right and\\nright-to-left decoding strategies for NMT to cap-\\nture bidirectional dependencies. Compared with\\nthem, our NMT system trained by MLE outper-\\nforms their best models by around 3 BLEU points.\\nWe hope that the strong baseline systems used in\\nthis work make the evaluation convincing.\\nWe nd that introducing adversarial stability\\ntraining into NMT can bring substantial improve-\\nments over previous work (up to +3:16BLEUpoints over Shen et al. (2016), up to +3:51\\nBLEU points over Wang et al. (2017) and up to\\n+2:74BLEU points over Zhang et al. (2018))\\nand our system trained with MLE across all the\\ndatasets. Compared with our baseline system,\\nAST lexical achieves +1:75BLEU improvement on\\naverage. AST feature performs better, which can\\nobtain +2:59BLEU points on average and up to\\n+3:34BLEU points on NIST08.\\n4.2.2 WMT 14 English-German Translation\\nIn Table 3, we list existing NMT systems as com-\\nparisons. All these systems use the same WMT 14\\nEnglish-German corpus. Except that Shen et al.\\n(2016) and Wu et al. (2016) respectively adopt\\nMRT and reinforcement learning (RL), other sys-\\ntems all use MLE as training criterion. All the sys-\\ntems except for Shen et al. (2016) are deep NMT\\nmodels with no less than four layers. Googles\\nneural machine translation (GNMT) (Wu et al.,\\n2016) represents a strong RNN-based NMT sys-\\ntem. Compared with other RNN-based NMT sys-\\ntems except for GNMT, our baseline system with\\ntwo layers can achieve better performance than\\ntheirs.\\nWhen training our NMT system with\\nAST leixcal , signicant improvement ( +1:11Synthetic Type Training 0 Op. 1 Op. 2 Op. 3 Op. 4 Op. 5 Op.\\nSwapMLE 41.38 38.86 37.23 35.97 34.61 32.96\\nAST lexical 43.57 41.18 39.88 37.95 37.02 36.16\\nAST feature 44.44 42.08 40.20 38.67 36.89 35.81\\nReplacementMLE 41.38 37.21 31.40 27.43 23.94 21.03\\nAST lexical 43.57 40.53 37.59 35.19 32.56 30.42\\nAST feature 44.44 40.04 35.00 30.54 27.42 24.57\\nDeletionMLE 41.38 38.45 36.15 33.28 31.17 28.65\\nAST lexical 43.57 41.89 38.56 36.14 34.09 31.77\\nAST feature 44.44 41.75 39.06 36.16 33.49 30.90\\nTable 5: Translation results of synthetic perturbations on the validation set in Chinese-English translation.\\n1 Op. denotes that we conduct one operation (swap, replacement or deletion) on the original sentence.\\nSource zhongguo dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing\\nReference chinas new management rules for e-banking operations to take effect on march 1\\nMLE chinas electronic bank rules to be implemented on march 1\\nAST lexicalnew rules for business administration of china s electronic banking industry\\nwill come into effect on march 1 .\\nAST featurenew rules for business management of china s electronic banking industry to\\ncome into effect on march 1\\nPerturbed Source zhongfang dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing\\nMLE china to implement new regulations on business management\\nAST lexicalthe new regulations for the business administrations of the chinese electronics\\nbank will come into effect on march 1 .\\nAST featurenew rules for business management of chinas electronic banking industry to\\ncome into effect on march 1\\nTable 6: Example translations of a source sentence and its perturbed counterpart by replacing a Chinese\\nword zhongguo with its synonym zhongfang.\\nBLEU points) can be observed. AST feature\\ncan obtain slightly better performance. Our\\nNMT system outperforms the state-of-the-art\\nRNN-based NMT system, GNMT, with +0:66\\nBLEU point and performs comparably with\\nGehring et al. (2017) which is based on CNN\\nwith 15 layers. Given that our approach can be\\napplied to any NMT systems, we expect that\\nthe adversarial stability training mechanism can\\nfurther improve performance upon the advanced\\nNMT architectures. We leave this for future work.\\n4.2.3 IWSLT English-French Translation\\nTable 4 shows the results on IWSLT English-\\nFrench Translation. Compared with our strong\\nbaseline system trained by MLE, we observe that\\nour models consistently improve translation per-\\nformance in all datasets. AST feature can achieve\\nsignicant improvements on the tst2015 although\\nAST lexical obtains comparable results. Thesedemonstrate that our approach maintains good per-\\nformance on the non-normative text.\\n4.3 Results on Synthetic Perturbed Data\\nIn order to investigate the ability of our training\\napproaches to deal with perturbations, we experi-\\nment with three types of synthetic perturbations:\\nSwap : We randomly choose Npositions\\nfrom a sentence and then swap the chosen\\nwords with their right neighbours.\\nReplacement : We randomly replace sam-\\npled words in the sentence with other words.\\nDeletion : We randomly delete Nwords from\\neach sentence in the dataset.\\nAs shown in Table 5, we can nd that our train-\\ning approaches, AST lexical and AST feature , consis-\\ntently outperform MLE against perturbations on\\nall the numbers of operations. This means that ourLtrueLnoisyLinv BLEUp\\x02 \\x02 41.38p\\x02p41.91\\n\\x02p\\x02 42.20p p\\x02 42.93p p p43.57\\nTable 7: Ablation study of adversarial stabil-\\nity training AST lexical on Chinese-English trans-\\nlation. p means the loss function is included in\\nthe training objective while  \\x02 means it is not.\\napproaches have the capability of resisting pertur-\\nbations. Along with the number of operations in-\\ncreasing, the performance on MLE drops quickly.\\nAlthough the performance of our approaches also\\ndrops, we can see that our approaches consistently\\nsurpass MLE. In AST lexical , with 0 operation, the\\ndifference is +2.19 (43.57 Vs. 41.38) for all syn-\\nthetic types, but the differences are enlarged to\\n+3.20, +9.39, and +3.12 respectively for the three\\ntypes with 5 operations.\\nIn the Swap andDeletion types, AST lexical and\\nAST feature perform comparably after more than\\nfour operations. Interestingly, AST lexical per-\\nforms signicantly better than both of MLE and\\nAST feature after more than one operation in the\\nReplacement type. This is because AST lexical\\ntrains the model specically on perturbation data\\nthat is constructed by replacing words, which\\nagrees with the Replacement Type. Overall,\\nAST lexical performs better than AST feature against\\nperturbations after multiple operations. We spec-\\nulate that the perturbation method for AST lexical\\nand synthetic type are both discrete and they keep\\nmore consistent. Table 6 shows example transla-\\ntions of a Chinese sentence and its perturbed coun-\\nterpart.\\nThese ndings indicate that we can construct\\nspecic perturbations for a particular task. For\\nexample, in simultaneous translation, an auto-\\nmatic speech recognition system usually generates\\nwrong words with the same pronunciation of cor-\\nrect words, which dramatically affects the quality\\nof machine translation system. Therefore, we can\\ndesign specic perturbations aiming for this task.\\n4.4 Analysis\\n4.4.1 Ablation Study\\nOur training objective function Eq. (4) contains\\nthree loss functions. We perform an ablation\\nIterations0 20 40 60 80 100 120 140 160 180 200BLEU\\n34363840424446\\n 103ASTlexical\\nASTfeatureFigure 2: BLEU scores of AST lexical over itera-\\ntions on Chinese-English validation set.\\nIterations0 50 100 150 200Cost\\n0.511.522.533.544.55\\n 103Lnoisy\\nLtrue\\nLinv\\nFigure 3: Learning curves of three loss functions,\\nLtrue,LinvandLnoisy over iterations on Chinese-\\nEnglish validation set.\\nstudy on the Chinese-English translation to under-\\nstand the importance of these loss functions by\\nchoosing AST lexical as an example. As Table 7\\nshows, if we remove Ladv, the translation perfor-\\nmance decreases by 0:64BLEU point. However,\\nwhenLnoisy is excluded from the training objec-\\ntive function, it results in a signicant drop of 1:66\\nBLEU point. Surprisingly, only using Lnoisy is\\nable to lead to an increase of 0:88BLEU point.\\n4.4.2 BLEU Scores over Iterations\\nFigure 2 shows the changes of BLEU scores\\nover iterations respectively for AST lexical and\\nAST feature . They behave nearly consistently. Ini-\\ntialized by the model trained by MLE, their per-\\nformance drops rapidly. Then it starts to go up\\nquickly. Compared with the starting point, themaximal dropping points reach up to about 7:0\\nBLEU points. Basically, the curves present the\\nstate of oscillation. We think that introducing\\nrandom perturbations and adversarial learning can\\nmake the training not very stable like MLE.\\n4.4.3 Learning Curves of Loss Functions\\nFigure 3 shows the learning curves of three loss\\nfunctions,Ltrue,LinvandLnoisy. We can nd that\\ntheir costs of loss functions decrease not steadily.\\nSimilar to the Figure 2, there still exist oscilla-\\ntions in the learning curves although they do not\\nchange much sharply. We nd that Linvconverges\\nto around 0:68after about 100Kiterations, which\\nindicates that discriminator outputs probability 0:5\\nfor both positive and negative samples and it can-\\nnot distinguish them. Thus the behaviors of the\\nencoder for xand its perturbed neighbour x0per-\\nform nearly consistently.',\n",
              " '5 Related Work\\nOur work is inspired by two lines of research: (1)\\nadversarial learning and (2) data augmentation.\\nAdversarial Learning Generative Adversarial\\nNetwork (GAN) (Goodfellow et al., 2014) and\\nits related derivative have been widely applied\\nin computer vision (Radford et al., 2015; Sali-\\nmans et al., 2016) and natural language process-\\ning (Li et al., 2017; Yang et al., 2018). Previous\\nwork has constructed adversarial examples to at-\\ntack trained networks and make networks resist\\nthem, which has proved to improve the robust-\\nness of networks (Goodfellow et al., 2015; Miy-\\nato et al., 2016; Zheng et al., 2016). Belinkov\\nand Bisk (2018) introduce adversarial examples\\nto training data for character-based NMT models.\\nIn contrast to theirs, adversarial stability training\\naims to stabilize both the encoder and decoder in\\nNMT models. We adopt adversarial learning to\\nlearn the perturbation-invariant encoder.\\nData Augmentation Data augmentation has the\\ncapability to improve the robustness of NMT mod-\\nels. In NMT, there is a number of work that aug-\\nments the training data with monolingual corpora\\n(Sennrich et al., 2016a; Cheng et al., 2016; He\\net al., 2016a; Zhang and Zong, 2016). They all\\nleverage complex models such as inverse NMT\\nmodels to generate translation equivalents for\\nmonolingual corpora. Then they augment the par-\\nallel corpora with these pseudo corpora to improveNMT models. Some authors have recently en-\\ndeavored to achieve zero-shot NMT through trans-\\nferring knowledge from bilingual corpora of other\\nlanguage pairs (Chen et al., 2017; Zheng et al.,\\n2017; Cheng et al., 2017) or monolingual corpora\\n(Lample et al., 2018; Artetxe et al., 2018). Our\\nwork signicantly differs from these work. We do\\nnot resort to any complicated models to generate\\nperturbed data and do not depend on extra mono-\\nlingual or bilingual corpora. The way we exploit\\nis more convenient and easy to implement. We\\nfocus more on improving the robustness of NMT\\nmodels.',\n",
              " '6 Conclusion\\nWe have proposed adversarial stability training to\\nimprove the robustness of NMT models. The ba-\\nsic idea is to train both the encoder and decoder\\nrobust to input perturbations by enabling them to\\nbehave similarly for the original input and its per-\\nturbed counterpart. We propose two approaches\\nto construct perturbed data to adversarially train\\nthe encoder and stabilize the decoder. Experi-\\nments on Chinese-English, English-German and\\nEnglish-French translation tasks show that the pro-\\nposed approach can improve both the robustness\\nand translation performance.\\nAs our training framework is not limited to spe-\\ncic perturbation types, it is interesting to evalu-\\nate our approach in natural noise existing in prac-\\ntical applications, such as homonym in the simul-\\ntaneous translation system. It is also necessary to\\nfurther validate our approach on more advanced\\nNMT architectures, such as CNN-based NMT\\n(Gehring et al., 2017) and Transformer (Vaswani\\net al., 2017).\\nAcknowledgments\\nWe thank the anonymous reviewers for their in-\\nsightful comments and suggestions. We also thank\\nXiaoling Li for analyzing experimental results and\\nproviding valuable examples. Yang Liu is sup-\\nported by the National Key R&D Program of\\nChina (No. 2017YFB0202204), National Natural\\nScience Foundation of China (No. 61761166008,\\nNo. 61522204), Beijing Advanced Innovation\\nCenter for Language Resources, and the NExT++\\nproject supported by the National Research Foun-\\ndation, Prime Ministers Ofce, Singapore under\\nits IRC@Singapore Funding Initiative.']"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "section_extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9mOZsMy2Rj2",
        "outputId": "5612ed21-f0da-44ea-a195-0ccbca26e91f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Abstract Small perturbations input severely distort intermediate representa- tions thus impact translation quality neural machine translation ( NMT ) mod- els . paper , propose improve robustness NMT models adver- sarial stability training . basic idea make encoder decoder NMT models robust input pertur- bations enabling behave sim- ilarly original input per- turbed counterpart . Experimental results Chinese-English , English-German English-French translation tasks show approaches achieve sig- nicant improvements strong NMT systems also improve robustness NMT models .',\n",
              " '1 Introduction Neural machine translation ( NMT ) models advanced state art building sin- gle neural network better learn represen- tations ( Cho et al. , 2014 ; Sutskever et al. , 2014 ) . neural network consists two components : encoder network encodes input sen- tence sequence distributed representa- tions , based decoder network generates translation attention model ( Bahdanau et al. , 2015 ; Luong et al. , 2015 ) . variety NMT models derived encoder-decoder frame- work improved performance machine translation systems ( Gehring et al. , 2017 ; Vaswani et al. , 2017 ) . NMT capable general- izing better unseen text exploiting word simi- larities embeddings capturing long-distance reordering conditioning larger contexts continuous way.Input tamen bupa kunnan zuochu weiqi AI . OutputThey afraid difculties make Go AI . Input tamen buwei kunnan zuochu weiqi AI . Output afraid make Go AI . Table 1 : non-robustness problem neural machine translation . Replacing Chinese word synonym ( i.e. , bupa ! buwei ) leads signicant erroneous changes English trans- lation . bupa buwei translated English phrase afraid . However , studies reveal small changes input fool state-of-the-art neural net- works high probability ( Goodfellow et al. , 2015 ; Szegedy et al. , 2014 ) . Belinkov Bisk ( 2018 ) conrm nding pointing NMT models brittle easily falter presented noisy input . NMT , due introduction RNN attention , contextual word inuence model predic- tion global context , analogous buttery effect . shown Table 1 , although replace source word synonym , generated translation completely dis- torted . investigate severe variations trans- lations caused small input perturbations re- placing one word sentence test set synonym . observe 69:74 % transla- tions changed BLEU score 79:01between translations original in- puts translations perturbed inputs , suggesting NMT models sensitive small perturbations input . vulnerabil- ity instability NMT models limit ap- plicability broader range tasks , re- quire robust performance noisy inputs . ex- ample , simultaneous translation systems use auto-arXiv:1805.06130v1 [ cs.CL ] 16 May 2018matic speech recognition ( ASR ) transcribe in- put speech sequence hypothesized words , subsequently fed translation sys- tem . pipeline , ASR errors presented sentences noisy perturbations ( pro- nunciation incorrect words ) , signif- icant challenge current NMT models . More- , instability makes NMT models sensitive misspellings typos text translation . paper , address challenge adversarial stability training neural machine translation . basic idea improve ro- bustness two important components NMT : encoder decoder . end , pro- pose two approaches constructing noisy inputs small perturbations make NMT models re- sist . important intermediate representa- tions encoded encoder , directly deter- mine accuracy nal translations . intro- duce adversarial learning make behaviors encoder consistent input per- turbed counterpart . improve stability decoder , method jointly maximizes likeli- hoods original perturbed data . Adversarial stability training following advantages : 1.Improving robustness transla- tion performance : adversarial stability training capable improving robustness NMT models also achiev- ing better translation performance . 2.Applicable arbitrary noisy perturbations : paper , propose two approaches constructing noisy perturbations inputs . However , training framework eas- ily extended arbitrary noisy perturbations . Especially , design task-specic per- turbation methods . 3.Transparent network architectures : adversarial stability training depend specic NMT architectures . ap- plied arbitrary NMT systems . Experiments Chinese-English , English- French English-German translation tasks show adversarial stability training achieves signicant improvements across different lan- guages pairs . NMT system outperforms state-of-the-art RNN-based NMT system ( GNMT ) ( Wu et al. , 2016 ) obtains compara- ble performance CNN-based NMT sys-tem ( Gehring et al. , 2017 ) . Related experimen- tal analyses validate training approach improve robustness NMT models .',\n",
              " '2 Background NMT end-to-end framework directly optimizes translation probability target sentence y=y1 ; : : : ; Ngiven corresponding source sentence x=x1 ; : : : ; x : P ( yjx ; \\x12 ) =NY n=1P ( ynjy < n ; x ; \\x12 ) ( 1 ) \\x12is set model parameters < nis partial translation . P ( yjx ; \\x12 ) dened holis- tic neural network mainly includes two core components : encoder encodes source sen- tencexinto sequence hidden representations Hx=H1 ; : : : ; HM , decoder generates n-th target word based sequence hidden representations : P ( ynjy < n ; x ; \\x12 ) /expfg ( yn\\x001 ; sn ; Hx ; \\x12 ) g ( 2 ) snis then-th hidden state target side . Thus model parameters NMT include parameter sets encoder \\x12encand decoder \\x12dec : \\x12=f\\x12enc ; \\x12decg . standard training ob- jective minimize negative log-likelihood training corpus S=fhx ( ) ; ( ) igjSj s=1 : ^\\x12= argmin \\x12L ( x ; ; \\x12 ) = argmin \\x12nX hx ; yi2S\\x00logP ( yjx ; \\x12 ) ( 3 ) Due vulnerability instability deep neural networks , NMT models usually suffer drawback : small perturbations input dramatically deteriorate translation results . Be- linkov Bisk ( 2018 ) point character- based NMT models brittle easily fal- ter presented noisy input . nd word-based subword-based NMT mod- els also confront shortcoming , shown Table 1 . argue distributed repre- sentations fulll stability expectation , underlying concept proposed approach . Recent work shown adversar- ially trained models made robust perturbations ( Zheng et al. , 2016 ; Madry et al. , 2018 ) . Inspired , work , im- prove robustness encoder representations noisy perturbations adversarial learn- ing ( Goodfellow et al. , 2014 ) .xx+perturbations EncoderHxHx Decoder DiscriminatorLinv ( x , x ) Ltrue ( x , ) Lnoisy ( x , ) Figure 1 : architecture NMT adversar- ial stability training . dark solid arrow lines represent forward-pass information ow input sentence x , red dashed arrow lines noisy input sentence x0 , transformed xby adding small perturbations .',\n",
              " '3 Approach 3.1 Overview goal work propose general ap- proach make NMT models learned robust input perturbations . basic idea maintain consistency behaviors NMT model source sentence xand perturbed counterpart x0 . aforementioned , NMT model contains two procedures project- ing source sentence xto target sentence : encoder responsible encoding xas se- quence representations Hx , decoder outputs ywithHxas input . aim learning perturbation-invariant encoder decoder . Figure 1 illustrates architecture ap- proach . Given source sentence x , construct set perturbed sentences N ( x ) , sentence x0is constructed adding small per- turbations x . require x0is subtle variation xand similar semantics . Given input pair ( x , x0 ) , two expecta- tions : ( 1 ) encoded representation Hx0should close Hx ; ( 2 ) given Hx0 , decoder able generate robust output . end , introduce two additional objectives improve robustness encoder decoder : Linv ( x ; x0 ) encourage encoder out- put similar intermediate representations Hx andHx0forxandx0to achieve invariantencoder , benets outputting translations . cast objective ad- versarial learning framework . Lnoisy ( x0 ; ) guide decoder generate output ygiven noisy input x0 , modeled as\\x00logP ( yjx0 ) . also de- ned KL divergence P ( yjx ) P ( yjx0 ) indicates using P ( yjx ) teach P ( yjx0 ) . seen , two introduced objectives aim im- prove robustness NMT model free high variances target outputs caused small perturbations inputs . also natural introduce original training objective L ( x ; ) onxandy , guarantee good transla- tion performance keeping stability NMT model . Formally , given training corpus , adver- sarial stability training objective J ( \\x12 ) =X hx ; yi2S\\x10 Ltrue ( x ; ; \\x12enc ; \\x12dec ) + X x02N ( x ) Linv ( x ; x0 ; \\x12enc ; \\x12dis ) + X x02N ( x ) Lnoisy ( x0 ; ; \\x12enc ; \\x12dec ) \\x11 ( 4 ) whereLtrue ( x ; ) andLnoisy ( x0 ; ) calculated using Equation 3 , Linv ( x ; x0 ) adversar- ial loss described Section 3.3. control balance original transla- tion task stability NMT model . \\x12= f\\x12enc ; \\x12dec ; \\x12disgare trainable parameters encoder , decoder , newly introduced dis- criminator used adversarial learning . seen , parameters encoder \\x12encand decoder \\x12dec trained minimize translation loss Ltrue ( x ; ) stability losses ( Lnoisy ( x0 ; ) andLinv ( x ; x0 ) ) . SinceLnoisy ( x0 ; ) evaluates translation loss perturbed neighbour x0and corre- sponding target sentence , means aug- ment training data adding perturbed neigh- bours , potentially improve transla- tion performance . way , approach makes output NMT models ro- bust , also improves performance original translation task.In following sections , rst describe construct perturbed inputs different strategies fulll different goals ( Section 3.2 ) , followed proposed adversarial learning mechanism perturbation-invariant encoder ( Section 3.3 ) . conclude section training strategy ( Section 3.4 ) . 3.2 Constructing Perturbed Inputs training step , need generate per- turbed neighbour set N ( x ) source sen- tence xfor adversarial stability training . paper , propose two strategies construct perturbed inputs multiple levels representa- tions . rst approach generates perturbed neigh- bours lexical level . Given input sentence x , randomly sample word positions modied . replace words posi- tions words vocabulary according following distribution : P ( xjxi ) =expfcos ( E [ xi ] ; E [ x ] ) gP x2Vxnxiexpfcos ( E [ xi ] ; E [ x ] ) g ( 5 ) E [ xi ] word embedding word xi , Vxnxiis source vocabulary set excluding wordxi , cos ( E [ xi ] ; E [ x ] ) measures simi- larity word xiandx . Thus change word another word similar semantics . One potential problem strategy hard enumerate possible positions possible types generate perturbed neigh- bours . Therefore , propose general ap- proach modifying sentence feature level . Given sentence , obtain word embedding word . add Gaussian noise word embedding simulate possible types perturbations . E [ x0 ] =E [ xi ] +\\x0f ; \\x0f\\x18N ( 0 ; \\x1b2I ) ( 6 ) vector \\x0fis sampled Gaussian dis- tribution variance \\x1b2.\\x1bis hyper-parameter . simply introduce Gaussian noise word embeddings x . proposed scheme general framework one freely dene strategies con- struct perturbed inputs . present two pos- sible examples . rst strategy poten- tially useful training data contains noisy words , latter general strategyto improve robustness common NMT mod- els . practice , one design specic strategies particular tasks . example , replace correct words homonyms ( pronun- ciation different meanings ) improve NMT models simultaneous translation systems . 3.3 Adversarial Learning Perturbation-invariant Encoder goal perturbation-invariant encoder make representations produced en- coder indistinguishable fed correct sentence xand perturbed counterpart x0 , directly benecial output robustness decoder . cast problem adversar- ial learning framework ( Goodfellow et al. , 2014 ) . encoder serves generator G , de- nes policy generates sequence hid- den representations Hxgiven input sentence x . introduce additional discriminator Dto dis- tinguish representation perturbed input Hx0 original input Hx . goal generator G ( i.e. , encoder ) produce sim- ilar representations xandx0which could fool discriminator , discriminator Dtries correctly distinguish two representations . Formally , adversarial learning objective Linv ( x ; x0 ; \\x12enc ; \\x12dis ) =Ex\\x18S [ \\x00logD ( G ( x ) ) ] + Ex0\\x18N ( x ) \\x02 \\x00log ( 1\\x00D ( G ( x0 ) ) ) \\x03 ( 7 ) discriminator outputs classication score given input representation , tries max- imizeD ( G ( x ) ) 1 minimize ( G ( x0 ) ) 0 . objective encourages encoder output similar representations xandx0 , discriminator fails distinguish . training procedure regarded min-max two-player game . encoder parame- ters\\x12encare trained maximize loss function fool discriminator . discriminator pa- rameters \\x12disare optimized minimize loss improving discriminating ability . ef- ciency , update encoder dis- criminator simultaneously iteration , rather periodical training strategy com- monly used adversarial learning . Lamb et al . ( 2016 ) also propose similar idea use Professor Forcing make behaviors RNNs indis- tinguishable training sampling net- works.3.4 Training shown Figure 1 , training objective in- cludes three sets model parameters three modules . use mini-batch stochastic gradient descent optimize model . forward pass , besides mini-batch xandy , also construct mini-batch consisting perturbed neighbour x0andy . propagate informa- tion calculate three loss functions accord- ing arrows . , gradients collected up- date three sets model parameters . Except gradients ofLinvwith respect \\x12encare mul- tiplying by\\x001 , gradients normally back- propagated . Note update \\x12invand\\x12encsi- multaneously training efciency .',\n",
              " '4 Experiments 4.1 Setup evaluated adversarial stability training translation tasks several language pairs , re- ported 4-gram BLEU ( Papineni et al. , 2002 ) score calculated multi-bleu.perl script . Chinese-English used LDC corpus con- sisting 1.25M sentence pairs 27.9M Chi- nese words 34.5M English words respectively . selected best model using NIST 2006 set validation set ( hyper-parameter opti- mization model selection ) . NIST 2002 , 2003 , 2004 , 2005 , 2008 datasets used test sets . English-German used WMT 14 corpus containing 4.5M sentence pairs 118M En- glish words 111M German words . vali- dation set newstest2013 , test set new- stest2014 . English-French used IWSLT corpus contains 0.22M sentence pairs 4.03M English words 4.12M French words . IWLST corpus dissimilar NIST WMT corpora . collected TED talks inclined spoken language , want verify approaches non- normative text . IWSLT 14 test set taken validation set 15 test set used test set . English-German English-French , tokenize English , German French words using tokenize.perl script . follow Sen- nrich et al . ( 2016b ) split words sub- word units . numbers merge operations byte pair encoding ( BPE ) set 30K,40K 30K respectively Chinese-English , English-German , English-French . re- port case-sensitive tokenized BLEU score English-German English-French case- insensitive tokenized BLEU score Chinese- English . baseline system in-house NMT sys- tem . Following Bahdanau et al . ( 2015 ) , im- plement RNN-based NMT encoder decoder two-layer RNNs residual connections layers ( et al. , 2016b ) . gating mechanism RNNs gated recurrent unit ( GRUs ) ( Cho et al. , 2014 ) . apply layer normalization ( Ba et al. , 2016 ) dropout ( Hinton et al. , 2012 ) hidden states GRUs . Dropout also added source target word embeddings . share ma- trix target word embeedings pre-softmax linear transformation ( Vaswani et al. , 2017 ) . update set model parameters us- ing Adam SGD ( Kingma Ba , 2015 ) . learn- ing rate initially set 0:05and varies according formula Vaswani et al . ( 2017 ) . adversarial stability training initializes model based parameters trained maxi- mum likelihood estimation ( MLE ) . denote ad- versarial stability training based lexical-level perturbations feature-level perturbations re- spectively AST lexical AST feature . sample one perturbed neighbour x02N ( x ) training efciency . discriminator used Linv , adopt CNN discriminator proposed Kim ( 2014 ) address variable-length prob- lem sequence generated encoder . CNN discriminator , lter windows set 3 , 4 , 5 rectied linear units applied af- ter convolution operations . tune hyper- parameters validation set grid search . nd optimal values set 1:0 . standard variance Gaussian noise used formula ( 6 ) set 0:01 . number words replaced sentence xduring lexical-level perturbations taken max ( 0:2jxj ; 1 ) whichjxjis length ofx . default beam size decoding 10 . 4.2 Translation Results 4.2.1 NIST Chinese-English Translation Table 2 shows results Chinese-English translation . strong baseline system signi- cantly outperforms previously reported results onSystem Training MT06 MT02 MT03 MT04 MT05 MT08 Shen et al . ( 2016 ) MRT 37.34 40.36 40.93 41.37 38.81 29.23 Wang et al . ( 2017 ) MLE 37.29 39.35 41.15 38.07 Zhang et al . ( 2018 ) MLE 38.38 40.02 42.32 38.84 workMLE 41.38 43.52 41.50 43.64 41.58 31.60 AST lexical 43.57 44.82 42.95 45.05 43.45 34.85 AST feature 44.44 46.10 44.07 45.61 44.06 34.94 Table 2 : Case-insensitive BLEU scores Chinese-English translation . System Architecture Training BLEU Shen et al . ( 2016 ) Gated RNN 1 layer MRT 20.45 Luong et al . ( 2015 ) LSTM 4 layers MLE 20.90 Kalchbrenner et al . ( 2017 ) ByteNet 30 layers MLE 23.75 Wang et al . ( 2017 ) DeepLAU 4 layers MLE 23.80 Wu et al . ( 2016 ) LSTM 8 layers RL 24.60 Gehring et al . ( 2017 ) CNN 15 layers MLE 25.16 Vaswani et al . ( 2017 ) Self-attention 6 layers MLE 28.40 work Gated RNN 2 layersMLE 24.06 AST lexical 25.17 AST feature 25.26 Table 3 : Case-sensitive BLEU scores WMT 14 English-German translation . Training tst2014 tst2015 MLE 36.92 36.90 AST lexical 37.35 37.03 AST feature 38.03 37.64 Table 4 : Case-sensitive BLEU scores IWSLT English-French translation . Chinese-English NIST datasets trained RNN- based NMT . Shen et al . ( 2016 ) propose minimum risk training ( MRT ) NMT , directly op- timizes model parameters respect BLEU scores . Wang et al . ( 2017 ) address issue severe gradient diffusion linear associative units ( LAU ) . system deep encoder 4 layers decoder 4 layers . Zhang et al . ( 2018 ) propose exploit left-to-right right-to-left decoding strategies NMT cap- ture bidirectional dependencies . Compared , NMT system trained MLE outper- forms best models around 3 BLEU points . hope strong baseline systems used work make evaluation convincing . nd introducing adversarial stability training NMT bring substantial improve- ments previous work ( +3:16BLEUpoints Shen et al . ( 2016 ) , +3:51 BLEU points Wang et al . ( 2017 ) +2:74BLEU points Zhang et al . ( 2018 ) ) system trained MLE across datasets . Compared baseline system , AST lexical achieves +1:75BLEU improvement average . AST feature performs better , obtain +2:59BLEU points average +3:34BLEU points NIST08 . 4.2.2 WMT 14 English-German Translation Table 3 , list existing NMT systems com- parisons . systems use WMT 14 English-German corpus . Except Shen et al . ( 2016 ) Wu et al . ( 2016 ) respectively adopt MRT reinforcement learning ( RL ) , sys- tems use MLE training criterion . sys- tems except Shen et al . ( 2016 ) deep NMT models less four layers . Googles neural machine translation ( GNMT ) ( Wu et al. , 2016 ) represents strong RNN-based NMT sys- tem . Compared RNN-based NMT sys- tems except GNMT , baseline system two layers achieve better performance . training NMT system AST leixcal , signicant improvement ( +1:11Synthetic Type Training 0 Op . 1 Op . 2 Op . 3 Op . 4 Op . 5 Op . SwapMLE 41.38 38.86 37.23 35.97 34.61 32.96 AST lexical 43.57 41.18 39.88 37.95 37.02 36.16 AST feature 44.44 42.08 40.20 38.67 36.89 35.81 ReplacementMLE 41.38 37.21 31.40 27.43 23.94 21.03 AST lexical 43.57 40.53 37.59 35.19 32.56 30.42 AST feature 44.44 40.04 35.00 30.54 27.42 24.57 DeletionMLE 41.38 38.45 36.15 33.28 31.17 28.65 AST lexical 43.57 41.89 38.56 36.14 34.09 31.77 AST feature 44.44 41.75 39.06 36.16 33.49 30.90 Table 5 : Translation results synthetic perturbations validation set Chinese-English translation . 1 Op . denotes conduct one operation ( swap , replacement deletion ) original sentence . Source zhongguo dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing Reference chinas new management rules e-banking operations take effect march 1 MLE chinas electronic bank rules implemented march 1 AST lexicalnew rules business administration china electronic banking industry come effect march 1 . AST featurenew rules business management china electronic banking industry come effect march 1 Perturbed Source zhongfang dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing MLE china implement new regulations business management AST lexicalthe new regulations business administrations chinese electronics bank come effect march 1 . AST featurenew rules business management chinas electronic banking industry come effect march 1 Table 6 : Example translations source sentence perturbed counterpart replacing Chinese word zhongguo synonym zhongfang . BLEU points ) observed . AST feature obtain slightly better performance . NMT system outperforms state-of-the-art RNN-based NMT system , GNMT , +0:66 BLEU point performs comparably Gehring et al . ( 2017 ) based CNN 15 layers . Given approach applied NMT systems , expect adversarial stability training mechanism improve performance upon advanced NMT architectures . leave future work . 4.2.3 IWSLT English-French Translation Table 4 shows results IWSLT English- French Translation . Compared strong baseline system trained MLE , observe models consistently improve translation per- formance datasets . AST feature achieve signicant improvements tst2015 although AST lexical obtains comparable results . Thesedemonstrate approach maintains good per- formance non-normative text . 4.3 Results Synthetic Perturbed Data order investigate ability training approaches deal perturbations , experi- ment three types synthetic perturbations : Swap : randomly choose Npositions sentence swap chosen words right neighbours . Replacement : randomly replace sam- pled words sentence words . Deletion : randomly delete Nwords sentence dataset . shown Table 5 , nd train- ing approaches , AST lexical AST feature , consis- tently outperform MLE perturbations numbers operations . means ourLtrueLnoisyLinv BLEUp\\x02 \\x02 41.38p\\x02p41.91 \\x02p\\x02 42.20p p\\x02 42.93p p p43.57 Table 7 : Ablation study adversarial stabil- ity training AST lexical Chinese-English trans- lation . p means loss function included training objective \\x02 means . approaches capability resisting pertur- bations . Along number operations in- creasing , performance MLE drops quickly . Although performance approaches also drops , see approaches consistently surpass MLE . AST lexical , 0 operation , difference +2.19 ( 43.57 Vs. 41.38 ) syn- thetic types , differences enlarged +3.20 , +9.39 , +3.12 respectively three types 5 operations . Swap andDeletion types , AST lexical AST feature perform comparably four operations . Interestingly , AST lexical per- forms signicantly better MLE AST feature one operation Replacement type . AST lexical trains model specically perturbation data constructed replacing words , agrees Replacement Type . Overall , AST lexical performs better AST feature perturbations multiple operations . spec- ulate perturbation method AST lexical synthetic type discrete keep consistent . Table 6 shows example transla- tions Chinese sentence perturbed coun- terpart . ndings indicate construct specic perturbations particular task . example , simultaneous translation , auto- matic speech recognition system usually generates wrong words pronunciation cor- rect words , dramatically affects quality machine translation system . Therefore , design specic perturbations aiming task . 4.4 Analysis 4.4.1 Ablation Study training objective function Eq . ( 4 ) contains three loss functions . perform ablation Iterations0 20 40 60 80 100 120 140 160 180 200BLEU 34363840424446 103ASTlexical ASTfeatureFigure 2 : BLEU scores AST lexical itera- tions Chinese-English validation set . Iterations0 50 100 150 200Cost 0.511.522.533.544.55 103Lnoisy Ltrue Linv Figure 3 : Learning curves three loss functions , Ltrue , LinvandLnoisy iterations Chinese- English validation set . study Chinese-English translation under- stand importance loss functions choosing AST lexical example . Table 7 shows , remove Ladv , translation perfor- mance decreases 0:64BLEU point . However , whenLnoisy excluded training objec- tive function , results signicant drop 1:66 BLEU point . Surprisingly , using Lnoisy able lead increase 0:88BLEU point . 4.4.2 BLEU Scores Iterations Figure 2 shows changes BLEU scores iterations respectively AST lexical AST feature . behave nearly consistently . Ini- tialized model trained MLE , per- formance drops rapidly . starts go quickly . Compared starting point , themaximal dropping points reach 7:0 BLEU points . Basically , curves present state oscillation . think introducing random perturbations adversarial learning make training stable like MLE . 4.4.3 Learning Curves Loss Functions Figure 3 shows learning curves three loss functions , Ltrue , LinvandLnoisy . nd costs loss functions decrease steadily . Similar Figure 2 , still exist oscilla- tions learning curves although change much sharply . nd Linvconverges around 0:68after 100Kiterations , indicates discriminator outputs probability 0:5 positive negative samples can- distinguish . Thus behaviors encoder xand perturbed neighbour x0per- form nearly consistently .',\n",
              " '5 Related Work work inspired two lines research : ( 1 ) adversarial learning ( 2 ) data augmentation . Adversarial Learning Generative Adversarial Network ( GAN ) ( Goodfellow et al. , 2014 ) related derivative widely applied computer vision ( Radford et al. , 2015 ; Sali- mans et al. , 2016 ) natural language process- ing ( Li et al. , 2017 ; Yang et al. , 2018 ) . Previous work constructed adversarial examples at- tack trained networks make networks resist , proved improve robust- ness networks ( Goodfellow et al. , 2015 ; Miy- ato et al. , 2016 ; Zheng et al. , 2016 ) . Belinkov Bisk ( 2018 ) introduce adversarial examples training data character-based NMT models . contrast , adversarial stability training aims stabilize encoder decoder NMT models . adopt adversarial learning learn perturbation-invariant encoder . Data Augmentation Data augmentation capability improve robustness NMT mod- els . NMT , number work aug- ments training data monolingual corpora ( Sennrich et al. , 2016a ; Cheng et al. , 2016 ; et al. , 2016a ; Zhang Zong , 2016 ) . leverage complex models inverse NMT models generate translation equivalents monolingual corpora . augment par- allel corpora pseudo corpora improveNMT models . authors recently en- deavored achieve zero-shot NMT trans- ferring knowledge bilingual corpora language pairs ( Chen et al. , 2017 ; Zheng et al. , 2017 ; Cheng et al. , 2017 ) monolingual corpora ( Lample et al. , 2018 ; Artetxe et al. , 2018 ) . work signicantly differs work . resort complicated models generate perturbed data depend extra mono- lingual bilingual corpora . way exploit convenient easy implement . focus improving robustness NMT models .',\n",
              " '6 Conclusion proposed adversarial stability training improve robustness NMT models . ba- sic idea train encoder decoder robust input perturbations enabling behave similarly original input per- turbed counterpart . propose two approaches construct perturbed data adversarially train encoder stabilize decoder . Experi- ments Chinese-English , English-German English-French translation tasks show pro- posed approach improve robustness translation performance . training framework limited spe- cic perturbation types , interesting evalu- ate approach natural noise existing prac- tical applications , homonym simul- taneous translation system . also necessary validate approach advanced NMT architectures , CNN-based NMT ( Gehring et al. , 2017 ) Transformer ( Vaswani et al. , 2017 ) . Acknowledgments thank anonymous reviewers in- sightful comments suggestions . also thank Xiaoling Li analyzing experimental results providing valuable examples . Yang Liu sup- ported National Key R & Program China ( . 2017YFB0202204 ) , National Natural Science Foundation China ( . 61761166008 , . 61522204 ) , Beijing Advanced Innovation Center Language Resources , NExT++ project supported National Research Foun- dation , Prime Ministers Ofce , Singapore IRC @ Singapore Funding Initiative .']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tokenization, Stop word removal from extracted pdf text\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_text)\n",
        "\n",
        "# Process each elements in section_extraction\n",
        "\n",
        "processed_text_final = [remove_stopwords(section) for section in section_extraction]\n",
        "processed_text_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_HRuUDoC-Wv"
      },
      "source": [
        "### Applying LSA for summarizing the section extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ktz-IQiC-Wv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcyZXjwTC-Wv"
      },
      "outputs": [],
      "source": [
        "# Vectorizing the extracted sentences\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "tfidf_matrix = vectorizer.fit_transform(section_extraction)\n",
        "\n",
        "# 3. Create a TruncatedSVD object for LSA\n",
        "lsa = TruncatedSVD(n_components = 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2lRc78OC-Wv",
        "outputId": "2fd7109c-2adf-40db-8985-bb75a621dd67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.70876345 -0.28841418  0.42276639 -0.1745527  -0.40432219 -0.05196019\n",
            "  -0.19772526]\n",
            " [ 0.85133022 -0.0324269  -0.03201699 -0.09140927 -0.17124069  0.20806354\n",
            "   0.43839572]\n",
            " [ 0.74725656 -0.16071023 -0.45669857 -0.24428816  0.05612187 -0.3799713\n",
            "   0.00130866]\n",
            " [ 0.80619702 -0.168069   -0.24879    -0.0310489   0.22860714  0.38013932\n",
            "  -0.24934223]\n",
            " [ 0.70937023  0.04854717 -0.09776624  0.67183992 -0.15092214 -0.09784497\n",
            "  -0.03404113]\n",
            " [ 0.59119517  0.77748725  0.01882944 -0.16720318 -0.08072237 -0.00237555\n",
            "  -0.10568183]\n",
            " [ 0.70980384 -0.00911899  0.4616501   0.04420938  0.50844142 -0.12964386\n",
            "   0.07549738]]\n"
          ]
        }
      ],
      "source": [
        "# 4. Perform LSA on the TF-IDF matrix\n",
        "\n",
        "lsa_matrix = lsa.fit_transform(tfidf_matrix)\n",
        "print(lsa_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9RPKwL0ndZ_",
        "outputId": "f558cbfb-90f8-40ae-d44d-64c8e8c1b27d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Section Abstract sentences:\n",
            " ['Abstract\\nSmall perturbations in the input can\\nseverely distort intermediate representa-\\ntions and thus impact translation quality of\\nneural machine translation (NMT) mod-\\nels. In this paper, we propose to improve\\nthe robustness of NMT models with adver-\\nsarial stability training. The basic idea is\\nto make both the encoder and decoder in\\nNMT models robust against input pertur-\\nbations by enabling them to behave sim-\\nilarly for the original input and its per-\\nturbed counterpart. Experimental results\\non Chinese-English, English-German and\\nEnglish-French translation tasks show that\\nour approaches can not only achieve sig-\\nnicant improvements over strong NMT\\nsystems but also improve the robustness of\\nNMT models.']\n",
            "Section 1 Introduction sentences:\n",
            " ['1 Introduction\\nNeural machine translation (NMT) models have\\nadvanced the state of the art by building a sin-\\ngle neural network that can better learn represen-\\ntations (Cho et al., 2014; Sutskever et al., 2014).\\nThe neural network consists of two components:\\nan encoder network that encodes the input sen-\\ntence into a sequence of distributed representa-\\ntions, based on which a decoder network generates\\nthe translation with an attention model (Bahdanau\\net al., 2015; Luong et al., 2015). A variety of NMT\\nmodels derived from this encoder-decoder frame-\\nwork have further improved the performance of\\nmachine translation systems (Gehring et al., 2017;\\nVaswani et al., 2017). NMT is capable of general-\\nizing better to unseen text by exploiting word simi-\\nlarities in embeddings and capturing long-distance\\nreordering by conditioning on larger contexts in a\\ncontinuous way.Input tamen bupa kunnan zuochu weiqi AI.\\nOutputThey are not afraid of difculties to\\nmake Go AI.\\nInput tamen buwei kunnan zuochu weiqi AI.\\nOutput They are not afraid to make Go AI.\\nTable 1: The non-robustness problem of neural\\nmachine translation. Replacing a Chinese word\\nwith its synonym (i.e.,  bupa !buwei ) leads to\\nsignicant erroneous changes in the English trans-\\nlation. Both  bupa  and  buwei  can be translated\\nto the English phrase  be not afraid of .\\nHowever, studies reveal that very small changes\\nto the input can fool state-of-the-art neural net-\\nworks with high probability (Goodfellow et al.,\\n2015; Szegedy et al., 2014). Belinkov and Bisk\\n(2018) conrm this nding by pointing out that\\nNMT models are very brittle and easily falter\\nwhen presented with noisy input. In NMT, due\\nto the introduction of RNN and attention, each\\ncontextual word can inuence the model predic-\\ntion in a global context, which is analogous to the\\nbuttery effect. As shown in Table 1, although\\nwe only replace a source word with its synonym,\\nthe generated translation has been completely dis-\\ntorted. We investigate severe variations of trans-\\nlations caused by small input perturbations by re-\\nplacing one word in each sentence of a test set with\\nits synonym. We observe that 69:74% of transla-\\ntions have changed and the BLEU score is only\\n79:01between the translations of the original in-\\nputs and the translations of the perturbed inputs,\\nsuggesting that NMT models are very sensitive to\\nsmall perturbations in the input. The vulnerabil-\\nity and instability of NMT models limit their ap-\\nplicability to a broader range of tasks, which re-\\nquire robust performance on noisy inputs. For ex-\\nample, simultaneous translation systems use auto-arXiv:1805.06130v1  [cs.CL]  16 May 2018matic speech recognition (ASR) to transcribe in-\\nput speech into a sequence of hypothesized words,\\nwhich are subsequently fed to a translation sys-\\ntem. In this pipeline, ASR errors are presented as\\nsentences with noisy perturbations (the same pro-\\nnunciation but incorrect words), which is a signif-\\nicant challenge for current NMT models. More-\\nover, instability makes NMT models sensitive to\\nmisspellings and typos in text translation.\\nIn this paper, we address this challenge with\\nadversarial stability training for neural machine\\ntranslation. The basic idea is to improve the ro-\\nbustness of two important components in NMT:\\nthe encoder and decoder. To this end, we pro-\\npose two approaches to constructing noisy inputs\\nwith small perturbations to make NMT models re-\\nsist them. As important intermediate representa-\\ntions encoded by the encoder, they directly deter-\\nmine the accuracy of nal translations. We intro-\\nduce adversarial learning to make behaviors of the\\nencoder consistent for both an input and its per-\\nturbed counterpart. To improve the stability of the\\ndecoder, our method jointly maximizes the likeli-\\nhoods of original and perturbed data. Adversarial\\nstability training has the following advantages:\\n1.Improving both the robustness and transla-\\ntion performance : Our adversarial stability\\ntraining is capable of not only improving the\\nrobustness of NMT models but also achiev-\\ning better translation performance.\\n2.Applicable to arbitrary noisy perturbations :\\nIn this paper, we propose two approaches to\\nconstructing noisy perturbations for inputs.\\nHowever, our training framework can be eas-\\nily extended to arbitrary noisy perturbations.\\nEspecially, we can design task-specic per-\\nturbation methods.\\n3.Transparent to network architectures : Our\\nadversarial stability training does not depend\\non specic NMT architectures. It can be ap-\\nplied to arbitrary NMT systems.\\nExperiments on Chinese-English, English-\\nFrench and English-German translation tasks\\nshow that adversarial stability training achieves\\nsignicant improvements across different lan-\\nguages pairs. Our NMT system outperforms\\nthe state-of-the-art RNN-based NMT system\\n(GNMT) (Wu et al., 2016) and obtains compara-\\nble performance with the CNN-based NMT sys-tem (Gehring et al., 2017). Related experimen-\\ntal analyses validate that our training approach can\\nimprove the robustness of NMT models.']\n",
            "Section 2 Background sentences:\n",
            " ['2 Background\\nNMT is an end-to-end framework which directly\\noptimizes the translation probability of a target\\nsentence y=y1;:::;y Ngiven its corresponding\\nsource sentence x=x1;:::;x M:\\nP(yjx;\\x12) =NY\\nn=1P(ynjy<n;x;\\x12) (1)\\nwhere \\x12is a set of model parameters and y<nis a\\npartial translation. P(yjx;\\x12)is dened on a holis-\\ntic neural network which mainly includes two core\\ncomponents: an encoder encodes a source sen-\\ntencexinto a sequence of hidden representations\\nHx=H1;:::;HM, and a decoder generates the\\nn-th target word based on the sequence of hidden\\nrepresentations:\\nP(ynjy<n;x;\\x12)/expfg(yn\\x001;sn;Hx;\\x12)g(2)\\nwhere snis then-th hidden state on target side.\\nThus the model parameters of NMT include the\\nparameter sets of the encoder \\x12encand the decoder\\n\\x12dec:\\x12=f\\x12enc;\\x12decg. The standard training ob-\\njective is to minimize the negative log-likelihood\\nof the training corpus S=fhx(s);y(s)igjSj\\ns=1:\\n^\\x12= argmin\\n\\x12L(x;y;\\x12)\\n= argmin\\n\\x12nX\\nhx;yi2S\\x00logP(yjx;\\x12)o\\n(3)\\nDue to the vulnerability and instability of deep\\nneural networks, NMT models usually suffer from\\na drawback: small perturbations in the input can\\ndramatically deteriorate its translation results. Be-\\nlinkov and Bisk (2018) point out that character-\\nbased NMT models are very brittle and easily fal-\\nter when presented with noisy input. We nd\\nthat word-based and subword-based NMT mod-\\nels also confront with this shortcoming, as shown\\nin Table 1. We argue that the distributed repre-\\nsentations should fulll the stability expectation,\\nwhich is the underlying concept of the proposed\\napproach. Recent work has shown that adversar-\\nially trained models can be made robust to such\\nperturbations (Zheng et al., 2016; Madry et al.,\\n2018). Inspired by this, in this work, we im-\\nprove the robustness of encoder representations\\nagainst noisy perturbations with adversarial learn-\\ning (Goodfellow et al., 2014).xx+perturbations\\nEncoderHxHx\\nDecoder\\nDiscriminatorLinv(x, x)Ltrue(x, y)Lnoisy(x, y)Figure 1: The architecture of NMT with adversar-\\nial stability training. The dark solid arrow lines\\nrepresent the forward-pass information ow for\\nthe input sentence x, while the red dashed arrow\\nlines for the noisy input sentence x0, which is\\ntransformed from xby adding small perturbations.']\n",
            "Section 3 Approach sentences:\n",
            " ['3 Approach\\n3.1 Overview\\nThe goal of this work is to propose a general ap-\\nproach to make NMT models learned to be more\\nrobust to input perturbations. Our basic idea is\\nto maintain the consistency of behaviors through\\nthe NMT model for the source sentence xand its\\nperturbed counterpart x0. As aforementioned, the\\nNMT model contains two procedures for project-\\ning a source sentence xto its target sentence y:\\nthe encoder is responsible for encoding xas a se-\\nquence of representations Hx, while the decoder\\noutputs ywithHxas input. We aim at learning\\nthe perturbation-invariant encoder and decoder.\\nFigure 1 illustrates the architecture of our ap-\\nproach. Given a source sentence x, we construct a\\nset of perturbed sentences N(x), in which each\\nsentence x0is constructed by adding small per-\\nturbations to x. We require that x0is a subtle\\nvariation from xand they have similar semantics.\\nGiven the input pair ( x,x0), we have two expecta-\\ntions: (1) the encoded representation Hx0should\\nbe close to Hx; and (2) given Hx0, the decoder is\\nable to generate the robust output y. To this end,\\nwe introduce two additional objectives to improve\\nthe robustness of the encoder and decoder:\\nLinv(x;x0)to encourage the encoder to out-\\nput similar intermediate representations Hx\\nandHx0forxandx0to achieve an invariantencoder, which benets outputting the same\\ntranslations. We cast this objective in the ad-\\nversarial learning framework.\\nLnoisy(x0;y)to guide the decoder to generate\\noutput ygiven the noisy input x0, which is\\nmodeled as\\x00logP(yjx0). It can also be de-\\nned as KL divergence between P(yjx)and\\nP(yjx0)that indicates using P(yjx)to teach\\nP(yjx0).\\nAs seen, the two introduced objectives aim to im-\\nprove the robustness of the NMT model which can\\nbe free of high variances in target outputs caused\\nby small perturbations in inputs. It is also natural\\nto introduce the original training objective L(x;y)\\nonxandy, which can guarantee good transla-\\ntion performance while keeping the stability of the\\nNMT model.\\nFormally, given a training corpus S, the adver-\\nsarial stability training objective is\\nJ(\\x12)\\n=X\\nhx;yi2S\\x10\\nLtrue(x;y;\\x12enc;\\x12dec)\\n+\\x0bX\\nx02N(x)Linv(x;x0;\\x12enc;\\x12dis)\\n+\\x0cX\\nx02N(x)Lnoisy(x0;y;\\x12enc;\\x12dec)\\x11\\n(4)\\nwhereLtrue(x;y)andLnoisy(x0;y)are calculated\\nusing Equation 3, and Linv(x;x0)is the adversar-\\nial loss to be described in Section 3.3. \\x0band\\x0c\\ncontrol the balance between the original transla-\\ntion task and the stability of the NMT model. \\x12=\\nf\\x12enc;\\x12dec;\\x12disgare trainable parameters of the\\nencoder, decoder, and the newly introduced dis-\\ncriminator used in adversarial learning. As seen,\\nthe parameters of encoder \\x12encand decoder \\x12dec\\nare trained to minimize both the translation loss\\nLtrue(x;y)and the stability losses ( Lnoisy(x0;y)\\nandLinv(x;x0)).\\nSinceLnoisy(x0;y)evaluates the translation\\nloss on the perturbed neighbour x0and its corre-\\nsponding target sentence y, it means that we aug-\\nment the training data by adding perturbed neigh-\\nbours, which can potentially improve the transla-\\ntion performance. In this way, our approach not\\nonly makes the output of NMT models more ro-\\nbust, but also improves the performance on the\\noriginal translation task.In the following sections, we will rst describe\\nhow to construct perturbed inputs with different\\nstrategies to fulll different goals (Section 3.2),\\nfollowed by the proposed adversarial learning\\nmechanism for the perturbation-invariant encoder\\n(Section 3.3). We conclude this section with the\\ntraining strategy (Section 3.4).\\n3.2 Constructing Perturbed Inputs\\nAt each training step, we need to generate a per-\\nturbed neighbour set N(x)for each source sen-\\ntence xfor adversarial stability training. In this\\npaper, we propose two strategies to construct the\\nperturbed inputs at multiple levels of representa-\\ntions.\\nThe rst approach generates perturbed neigh-\\nbours at the lexical level. Given an input sentence\\nx, we randomly sample some word positions to\\nbe modied. Then we replace words at these posi-\\ntions with other words in the vocabulary according\\nto the following distribution:\\nP(xjxi) =expfcos (E[xi];E[x])gP\\nx2Vxnxiexpfcos (E[xi];E[x])g(5)\\nwhere E[xi]is the word embedding for word xi,\\nVxnxiis the source vocabulary set excluding the\\nwordxi, and cos (E[xi];E[x])measures the simi-\\nlarity between word xiandx. Thus we can change\\nthe word to another word with similar semantics.\\nOne potential problem of the above strategy is\\nthat it is hard to enumerate all possible positions\\nand possible types to generate perturbed neigh-\\nbours. Therefore, we propose a more general ap-\\nproach to modifying the sentence at the feature\\nlevel. Given a sentence, we can obtain the word\\nembedding for each word. We add the Gaussian\\nnoise to a word embedding to simulate possible\\ntypes of perturbations. That is\\nE[x0\\ni] =E[xi] +\\x0f;\\x0f\\x18N(0;\\x1b2I) (6)\\nwhere the vector \\x0fis sampled from a Gaussian dis-\\ntribution with variance \\x1b2.\\x1bis a hyper-parameter.\\nWe simply introduce Gaussian noise to all of word\\nembeddings in x.\\nThe proposed scheme is a general framework\\nwhere one can freely dene the strategies to con-\\nstruct perturbed inputs. We just present two pos-\\nsible examples here. The rst strategy is poten-\\ntially useful when the training data contains noisy\\nwords, while the latter is a more general strategyto improve the robustness of common NMT mod-\\nels. In practice, one can design specic strategies\\nfor particular tasks. For example, we can replace\\ncorrect words with their homonyms (same pronun-\\nciation but different meanings) to improve NMT\\nmodels for simultaneous translation systems.\\n3.3 Adversarial Learning for the\\nPerturbation-invariant Encoder\\nThe goal of the perturbation-invariant encoder is\\nto make the representations produced by the en-\\ncoder indistinguishable when fed with a correct\\nsentence xand its perturbed counterpart x0, which\\nis directly benecial to the output robustness of\\nthe decoder. We cast the problem in the adversar-\\nial learning framework (Goodfellow et al., 2014).\\nThe encoder serves as the generator G, which de-\\nnes the policy that generates a sequence of hid-\\nden representations Hxgiven an input sentence x.\\nWe introduce an additional discriminator Dto dis-\\ntinguish the representation of perturbed input Hx0\\nfrom that of the original input Hx. The goal of\\nthe generator G(i.e., encoder) is to produce sim-\\nilar representations for xandx0which could fool\\nthe discriminator, while the discriminator Dtries\\nto correctly distinguish the two representations.\\nFormally, the adversarial learning objective is\\nLinv(x;x0;\\x12enc;\\x12dis)\\n=Ex\\x18S[\\x00logD(G(x))] +\\nEx0\\x18N(x)\\x02\\n\\x00log(1\\x00D(G(x0)))\\x03\\n(7)\\nThe discriminator outputs a classication score\\ngiven an input representation, and tries to max-\\nimizeD(G(x))to 1 and minimize D(G(x0))to\\n0. The objective encourages the encoder to output\\nsimilar representations for xandx0, so that the\\ndiscriminator fails to distinguish them.\\nThe training procedure can be regarded as a\\nmin-max two-player game. The encoder parame-\\nters\\x12encare trained to maximize the loss function\\nto fool the discriminator. The discriminator pa-\\nrameters \\x12disare optimized to minimize this loss\\nfor improving the discriminating ability. For ef-\\nciency, we update both the encoder and the dis-\\ncriminator simultaneously at each iteration, rather\\nthan the periodical training strategy that is com-\\nmonly used in adversarial learning. Lamb et al.\\n(2016) also propose a similar idea to use Professor\\nForcing to make the behaviors of RNNs be indis-\\ntinguishable when training and sampling the net-\\nworks.3.4 Training\\nAs shown in Figure 1, our training objective in-\\ncludes three sets of model parameters for three\\nmodules. We use mini-batch stochastic gradient\\ndescent to optimize our model. In the forward\\npass, besides a mini-batch of xandy, we also\\nconstruct a mini-batch consisting of the perturbed\\nneighbour x0andy. We propagate the informa-\\ntion to calculate these three loss functions accord-\\ning to arrows. Then, gradients are collected to up-\\ndate three sets of model parameters. Except for\\nthe gradients ofLinvwith respect to \\x12encare mul-\\ntiplying by\\x001, other gradients are normally back-\\npropagated. Note that we update \\x12invand\\x12encsi-\\nmultaneously for training efciency.']\n",
            "Section 4 Experiments sentences:\n",
            " ['4 Experiments\\n4.1 Setup\\nWe evaluated our adversarial stability training on\\ntranslation tasks of several language pairs, and re-\\nported the 4-gram BLEU (Papineni et al., 2002)\\nscore as calculated by the multi-bleu.perl script.\\nChinese-English We used the LDC corpus con-\\nsisting of 1.25M sentence pairs with 27.9M Chi-\\nnese words and 34.5M English words respectively.\\nWe selected the best model using the NIST 2006\\nset as the validation set (hyper-parameter opti-\\nmization and model selection). The NIST 2002,\\n2003, 2004, 2005, and 2008 datasets are used as\\ntest sets.\\nEnglish-German We used the WMT 14 corpus\\ncontaining 4.5M sentence pairs with 118M En-\\nglish words and 111M German words. The vali-\\ndation set is newstest2013, and the test set is new-\\nstest2014.\\nEnglish-French We used the IWSLT corpus\\nwhich contains 0.22M sentence pairs with 4.03M\\nEnglish words and 4.12M French words. The\\nIWLST corpus is very dissimilar from the NIST\\nand WMT corpora. As they are collected from\\nTED talks and inclined to spoken language,\\nwe want to verify our approaches on the non-\\nnormative text. The IWSLT 14 test set is taken\\nas the validation set and 15 test set is used as the\\ntest set.\\nFor English-German and English-French, we\\ntokenize both English, German and French words\\nusing tokenize.perl script. We follow Sen-\\nnrich et al. (2016b) to split words into sub-\\nword units. The numbers of merge operations\\nin byte pair encoding (BPE) are set to 30K,40K and 30K respectively for Chinese-English,\\nEnglish-German, and English-French. We re-\\nport the case-sensitive tokenized BLEU score for\\nEnglish-German and English-French and the case-\\ninsensitive tokenized BLEU score for Chinese-\\nEnglish.\\nOur baseline system is an in-house NMT sys-\\ntem. Following Bahdanau et al. (2015), we im-\\nplement an RNN-based NMT in which both the\\nencoder and decoder are two-layer RNNs with\\nresidual connections between layers (He et al.,\\n2016b). The gating mechanism of RNNs is gated\\nrecurrent unit (GRUs) (Cho et al., 2014). We\\napply layer normalization (Ba et al., 2016) and\\ndropout (Hinton et al., 2012) to the hidden states\\nof GRUs. Dropout is also added to the source and\\ntarget word embeddings. We share the same ma-\\ntrix between the target word embeedings and the\\npre-softmax linear transformation (Vaswani et al.,\\n2017). We update the set of model parameters us-\\ning Adam SGD (Kingma and Ba, 2015). Its learn-\\ning rate is initially set to 0:05and varies according\\nto the formula in Vaswani et al. (2017).\\nOur adversarial stability training initializes the\\nmodel based on the parameters trained by maxi-\\nmum likelihood estimation (MLE). We denote ad-\\nversarial stability training based on lexical-level\\nperturbations and feature-level perturbations re-\\nspectively as AST lexical and AST feature . We only\\nsample one perturbed neighbour x02N (x)for\\ntraining efciency. For the discriminator used in\\nLinv, we adopt the CNN discriminator proposed\\nby Kim (2014) to address the variable-length prob-\\nlem of the sequence generated by the encoder. In\\nthe CNN discriminator, the lter windows are set\\nto 3, 4, 5 and rectied linear units are applied af-\\nter convolution operations. We tune the hyper-\\nparameters on the validation set through a grid\\nsearch. We nd that both the optimal values of\\n\\x0band\\x0care set to 1:0. The standard variance in\\nGaussian noise used in the formula (6) is set to\\n0:01. The number of words that are replaced in\\nthe sentence xduring lexical-level perturbations is\\ntaken as max(0:2jxj;1)in whichjxjis the length\\nofx. The default beam size for decoding is 10.\\n4.2 Translation Results\\n4.2.1 NIST Chinese-English Translation\\nTable 2 shows the results on Chinese-English\\ntranslation. Our strong baseline system signi-\\ncantly outperforms previously reported results onSystem Training MT06 MT02 MT03 MT04 MT05 MT08\\nShen et al. (2016) MRT 37.34 40.36 40.93 41.37 38.81 29.23\\nWang et al. (2017) MLE 37.29  39.35 41.15 38.07 \\nZhang et al. (2018) MLE 38.38  40.02 42.32 38.84 \\nthis workMLE 41.38 43.52 41.50 43.64 41.58 31.60\\nAST lexical 43.57 44.82 42.95 45.05 43.45 34.85\\nAST feature 44.44 46.10 44.07 45.61 44.06 34.94\\nTable 2: Case-insensitive BLEU scores on Chinese-English translation.\\nSystem Architecture Training BLEU\\nShen et al. (2016) Gated RNN with 1 layer MRT 20.45\\nLuong et al. (2015) LSTM with 4 layers MLE 20.90\\nKalchbrenner et al. (2017) ByteNet with 30 layers MLE 23.75\\nWang et al. (2017) DeepLAU with 4 layers MLE 23.80\\nWu et al. (2016) LSTM with 8 layers RL 24.60\\nGehring et al. (2017) CNN with 15 layers MLE 25.16\\nVaswani et al. (2017) Self-attention with 6 layers MLE 28.40\\nthis work Gated RNN with 2 layersMLE 24.06\\nAST lexical 25.17\\nAST feature 25.26\\nTable 3: Case-sensitive BLEU scores on WMT 14 English-German translation.\\nTraining tst2014 tst2015\\nMLE 36.92 36.90\\nAST lexical 37.35 37.03\\nAST feature 38.03 37.64\\nTable 4: Case-sensitive BLEU scores on IWSLT\\nEnglish-French translation.\\nChinese-English NIST datasets trained on RNN-\\nbased NMT. Shen et al. (2016) propose minimum\\nrisk training (MRT) for NMT, which directly op-\\ntimizes model parameters with respect to BLEU\\nscores. Wang et al. (2017) address the issue of\\nsevere gradient diffusion with linear associative\\nunits (LAU). Their system is deep with an encoder\\nof 4 layers and a decoder of 4 layers. Zhang et al.\\n(2018) propose to exploit both left-to-right and\\nright-to-left decoding strategies for NMT to cap-\\nture bidirectional dependencies. Compared with\\nthem, our NMT system trained by MLE outper-\\nforms their best models by around 3 BLEU points.\\nWe hope that the strong baseline systems used in\\nthis work make the evaluation convincing.\\nWe nd that introducing adversarial stability\\ntraining into NMT can bring substantial improve-\\nments over previous work (up to +3:16BLEUpoints over Shen et al. (2016), up to +3:51\\nBLEU points over Wang et al. (2017) and up to\\n+2:74BLEU points over Zhang et al. (2018))\\nand our system trained with MLE across all the\\ndatasets. Compared with our baseline system,\\nAST lexical achieves +1:75BLEU improvement on\\naverage. AST feature performs better, which can\\nobtain +2:59BLEU points on average and up to\\n+3:34BLEU points on NIST08.\\n4.2.2 WMT 14 English-German Translation\\nIn Table 3, we list existing NMT systems as com-\\nparisons. All these systems use the same WMT 14\\nEnglish-German corpus. Except that Shen et al.\\n(2016) and Wu et al. (2016) respectively adopt\\nMRT and reinforcement learning (RL), other sys-\\ntems all use MLE as training criterion. All the sys-\\ntems except for Shen et al. (2016) are deep NMT\\nmodels with no less than four layers. Googles\\nneural machine translation (GNMT) (Wu et al.,\\n2016) represents a strong RNN-based NMT sys-\\ntem. Compared with other RNN-based NMT sys-\\ntems except for GNMT, our baseline system with\\ntwo layers can achieve better performance than\\ntheirs.\\nWhen training our NMT system with\\nAST leixcal , signicant improvement ( +1:11Synthetic Type Training 0 Op. 1 Op. 2 Op. 3 Op. 4 Op. 5 Op.\\nSwapMLE 41.38 38.86 37.23 35.97 34.61 32.96\\nAST lexical 43.57 41.18 39.88 37.95 37.02 36.16\\nAST feature 44.44 42.08 40.20 38.67 36.89 35.81\\nReplacementMLE 41.38 37.21 31.40 27.43 23.94 21.03\\nAST lexical 43.57 40.53 37.59 35.19 32.56 30.42\\nAST feature 44.44 40.04 35.00 30.54 27.42 24.57\\nDeletionMLE 41.38 38.45 36.15 33.28 31.17 28.65\\nAST lexical 43.57 41.89 38.56 36.14 34.09 31.77\\nAST feature 44.44 41.75 39.06 36.16 33.49 30.90\\nTable 5: Translation results of synthetic perturbations on the validation set in Chinese-English translation.\\n1 Op. denotes that we conduct one operation (swap, replacement or deletion) on the original sentence.\\nSource zhongguo dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing\\nReference chinas new management rules for e-banking operations to take effect on march 1\\nMLE chinas electronic bank rules to be implemented on march 1\\nAST lexicalnew rules for business administration of china s electronic banking industry\\nwill come into effect on march 1 .\\nAST featurenew rules for business management of china s electronic banking industry to\\ncome into effect on march 1\\nPerturbed Source zhongfang dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing\\nMLE china to implement new regulations on business management\\nAST lexicalthe new regulations for the business administrations of the chinese electronics\\nbank will come into effect on march 1 .\\nAST featurenew rules for business management of chinas electronic banking industry to\\ncome into effect on march 1\\nTable 6: Example translations of a source sentence and its perturbed counterpart by replacing a Chinese\\nword zhongguo with its synonym zhongfang.\\nBLEU points) can be observed. AST feature\\ncan obtain slightly better performance. Our\\nNMT system outperforms the state-of-the-art\\nRNN-based NMT system, GNMT, with +0:66\\nBLEU point and performs comparably with\\nGehring et al. (2017) which is based on CNN\\nwith 15 layers. Given that our approach can be\\napplied to any NMT systems, we expect that\\nthe adversarial stability training mechanism can\\nfurther improve performance upon the advanced\\nNMT architectures. We leave this for future work.\\n4.2.3 IWSLT English-French Translation\\nTable 4 shows the results on IWSLT English-\\nFrench Translation. Compared with our strong\\nbaseline system trained by MLE, we observe that\\nour models consistently improve translation per-\\nformance in all datasets. AST feature can achieve\\nsignicant improvements on the tst2015 although\\nAST lexical obtains comparable results. Thesedemonstrate that our approach maintains good per-\\nformance on the non-normative text.\\n4.3 Results on Synthetic Perturbed Data\\nIn order to investigate the ability of our training\\napproaches to deal with perturbations, we experi-\\nment with three types of synthetic perturbations:\\nSwap : We randomly choose Npositions\\nfrom a sentence and then swap the chosen\\nwords with their right neighbours.\\nReplacement : We randomly replace sam-\\npled words in the sentence with other words.\\nDeletion : We randomly delete Nwords from\\neach sentence in the dataset.\\nAs shown in Table 5, we can nd that our train-\\ning approaches, AST lexical and AST feature , consis-\\ntently outperform MLE against perturbations on\\nall the numbers of operations. This means that ourLtrueLnoisyLinv BLEUp\\x02 \\x02 41.38p\\x02p41.91\\n\\x02p\\x02 42.20p p\\x02 42.93p p p43.57\\nTable 7: Ablation study of adversarial stabil-\\nity training AST lexical on Chinese-English trans-\\nlation. p means the loss function is included in\\nthe training objective while  \\x02 means it is not.\\napproaches have the capability of resisting pertur-\\nbations. Along with the number of operations in-\\ncreasing, the performance on MLE drops quickly.\\nAlthough the performance of our approaches also\\ndrops, we can see that our approaches consistently\\nsurpass MLE. In AST lexical , with 0 operation, the\\ndifference is +2.19 (43.57 Vs. 41.38) for all syn-\\nthetic types, but the differences are enlarged to\\n+3.20, +9.39, and +3.12 respectively for the three\\ntypes with 5 operations.\\nIn the Swap andDeletion types, AST lexical and\\nAST feature perform comparably after more than\\nfour operations. Interestingly, AST lexical per-\\nforms signicantly better than both of MLE and\\nAST feature after more than one operation in the\\nReplacement type. This is because AST lexical\\ntrains the model specically on perturbation data\\nthat is constructed by replacing words, which\\nagrees with the Replacement Type. Overall,\\nAST lexical performs better than AST feature against\\nperturbations after multiple operations. We spec-\\nulate that the perturbation method for AST lexical\\nand synthetic type are both discrete and they keep\\nmore consistent. Table 6 shows example transla-\\ntions of a Chinese sentence and its perturbed coun-\\nterpart.\\nThese ndings indicate that we can construct\\nspecic perturbations for a particular task. For\\nexample, in simultaneous translation, an auto-\\nmatic speech recognition system usually generates\\nwrong words with the same pronunciation of cor-\\nrect words, which dramatically affects the quality\\nof machine translation system. Therefore, we can\\ndesign specic perturbations aiming for this task.\\n4.4 Analysis\\n4.4.1 Ablation Study\\nOur training objective function Eq. (4) contains\\nthree loss functions. We perform an ablation\\nIterations0 20 40 60 80 100 120 140 160 180 200BLEU\\n34363840424446\\n 103ASTlexical\\nASTfeatureFigure 2: BLEU scores of AST lexical over itera-\\ntions on Chinese-English validation set.\\nIterations0 50 100 150 200Cost\\n0.511.522.533.544.55\\n 103Lnoisy\\nLtrue\\nLinv\\nFigure 3: Learning curves of three loss functions,\\nLtrue,LinvandLnoisy over iterations on Chinese-\\nEnglish validation set.\\nstudy on the Chinese-English translation to under-\\nstand the importance of these loss functions by\\nchoosing AST lexical as an example. As Table 7\\nshows, if we remove Ladv, the translation perfor-\\nmance decreases by 0:64BLEU point. However,\\nwhenLnoisy is excluded from the training objec-\\ntive function, it results in a signicant drop of 1:66\\nBLEU point. Surprisingly, only using Lnoisy is\\nable to lead to an increase of 0:88BLEU point.\\n4.4.2 BLEU Scores over Iterations\\nFigure 2 shows the changes of BLEU scores\\nover iterations respectively for AST lexical and\\nAST feature . They behave nearly consistently. Ini-\\ntialized by the model trained by MLE, their per-\\nformance drops rapidly. Then it starts to go up\\nquickly. Compared with the starting point, themaximal dropping points reach up to about 7:0\\nBLEU points. Basically, the curves present the\\nstate of oscillation. We think that introducing\\nrandom perturbations and adversarial learning can\\nmake the training not very stable like MLE.\\n4.4.3 Learning Curves of Loss Functions\\nFigure 3 shows the learning curves of three loss\\nfunctions,Ltrue,LinvandLnoisy. We can nd that\\ntheir costs of loss functions decrease not steadily.\\nSimilar to the Figure 2, there still exist oscilla-\\ntions in the learning curves although they do not\\nchange much sharply. We nd that Linvconverges\\nto around 0:68after about 100Kiterations, which\\nindicates that discriminator outputs probability 0:5\\nfor both positive and negative samples and it can-\\nnot distinguish them. Thus the behaviors of the\\nencoder for xand its perturbed neighbour x0per-\\nform nearly consistently.']\n",
            "Section 5 Related Work sentences:\n",
            " ['5 Related Work\\nOur work is inspired by two lines of research: (1)\\nadversarial learning and (2) data augmentation.\\nAdversarial Learning Generative Adversarial\\nNetwork (GAN) (Goodfellow et al., 2014) and\\nits related derivative have been widely applied\\nin computer vision (Radford et al., 2015; Sali-\\nmans et al., 2016) and natural language process-\\ning (Li et al., 2017; Yang et al., 2018). Previous\\nwork has constructed adversarial examples to at-\\ntack trained networks and make networks resist\\nthem, which has proved to improve the robust-\\nness of networks (Goodfellow et al., 2015; Miy-\\nato et al., 2016; Zheng et al., 2016). Belinkov\\nand Bisk (2018) introduce adversarial examples\\nto training data for character-based NMT models.\\nIn contrast to theirs, adversarial stability training\\naims to stabilize both the encoder and decoder in\\nNMT models. We adopt adversarial learning to\\nlearn the perturbation-invariant encoder.\\nData Augmentation Data augmentation has the\\ncapability to improve the robustness of NMT mod-\\nels. In NMT, there is a number of work that aug-\\nments the training data with monolingual corpora\\n(Sennrich et al., 2016a; Cheng et al., 2016; He\\net al., 2016a; Zhang and Zong, 2016). They all\\nleverage complex models such as inverse NMT\\nmodels to generate translation equivalents for\\nmonolingual corpora. Then they augment the par-\\nallel corpora with these pseudo corpora to improveNMT models. Some authors have recently en-\\ndeavored to achieve zero-shot NMT through trans-\\nferring knowledge from bilingual corpora of other\\nlanguage pairs (Chen et al., 2017; Zheng et al.,\\n2017; Cheng et al., 2017) or monolingual corpora\\n(Lample et al., 2018; Artetxe et al., 2018). Our\\nwork signicantly differs from these work. We do\\nnot resort to any complicated models to generate\\nperturbed data and do not depend on extra mono-\\nlingual or bilingual corpora. The way we exploit\\nis more convenient and easy to implement. We\\nfocus more on improving the robustness of NMT\\nmodels.']\n",
            "Section 6 Conclusion sentences:\n",
            " ['6 Conclusion\\nWe have proposed adversarial stability training to\\nimprove the robustness of NMT models. The ba-\\nsic idea is to train both the encoder and decoder\\nrobust to input perturbations by enabling them to\\nbehave similarly for the original input and its per-\\nturbed counterpart. We propose two approaches\\nto construct perturbed data to adversarially train\\nthe encoder and stabilize the decoder. Experi-\\nments on Chinese-English, English-German and\\nEnglish-French translation tasks show that the pro-\\nposed approach can improve both the robustness\\nand translation performance.\\nAs our training framework is not limited to spe-\\ncic perturbation types, it is interesting to evalu-\\nate our approach in natural noise existing in prac-\\ntical applications, such as homonym in the simul-\\ntaneous translation system. It is also necessary to\\nfurther validate our approach on more advanced\\nNMT architectures, such as CNN-based NMT\\n(Gehring et al., 2017) and Transformer (Vaswani\\net al., 2017).\\nAcknowledgments\\nWe thank the anonymous reviewers for their in-\\nsightful comments and suggestions. We also thank\\nXiaoling Li for analyzing experimental results and\\nproviding valuable examples. Yang Liu is sup-\\nported by the National Key R&D Program of\\nChina (No. 2017YFB0202204), National Natural\\nScience Foundation of China (No. 61761166008,\\nNo. 61522204), Beijing Advanced Innovation\\nCenter for Language Resources, and the NExT++\\nproject supported by the National Research Foun-\\ndation, Prime Ministers Ofce, Singapore under\\nits IRC@Singapore Funding Initiative.']\n"
          ]
        }
      ],
      "source": [
        "# Using LSA for summarizing the text of each individual section\n",
        "\n",
        "# Calculate LSA scores for each sentence\n",
        "lsa_scores = np.sum(np.abs(lsa_matrix), axis=1)\n",
        "\n",
        "# Group sentences by section and rank within each group\n",
        "grouped_sentences = {}\n",
        "for sentence, section, score in zip(section_extraction, sections, lsa_scores):\n",
        "    grouped_sentences.setdefault(section, []).append((score, sentence))\n",
        "\n",
        "# Sentence tokenization function\n",
        "\n",
        "def tokenize_sentences(text):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    return sentences\n",
        "\n",
        "# Tokenize sentences for each section\n",
        "section_sentences = {section: tokenize_sentences(' '.join(sentence[1] for sentence in sentences)) for section, sentences in grouped_sentences.items()}\n",
        "\n",
        "# Choose the top-ranked sentences from each section\n",
        "num_top_sentences = 5\n",
        "top_ranked_sentences = []\n",
        "\n",
        "for section, sentences in grouped_sentences.items():\n",
        "    # Sort sentences by score in descending order\n",
        "    sentences = sorted(sentences, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    # Choose the top-ranked sentences\n",
        "    top_sentences = [sentence[1] for sentence in sentences[:num_top_sentences]]\n",
        "\n",
        "    # Print the content of each sentence\n",
        "    print(f\"Section {section} sentences:\\n\", top_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LRAdACBhvli",
        "outputId": "dfebfd0a-aa97-4d19-9dee-cbc99ac3d14f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-ranked sentences for Section Abstract:\n",
            "The basic idea is\n",
            "to make both the encoder and decoder in\n",
            "NMT models robust against input pertur-\n",
            "bations by enabling them to behave sim-\n",
            "ilarly for the original input and its per-\n",
            "turbed counterpart.\n",
            "In this paper, we propose to improve\n",
            "the robustness of NMT models with adver-\n",
            "sarial stability training.\n",
            "Experimental results\n",
            "on Chinese-English, English-German and\n",
            "English-French translation tasks show that\n",
            "our approaches can not only achieve sig-\n",
            "nicant improvements over strong NMT\n",
            "systems but also improve the robustness of\n",
            "NMT models.\n",
            "Abstract\n",
            "Small perturbations in the input can\n",
            "severely distort intermediate representa-\n",
            "tions and thus impact translation quality of\n",
            "neural machine translation (NMT) mod-\n",
            "els.\n",
            "\n",
            "\n",
            "Top-ranked sentences for Section 1 Introduction:\n",
            "We investigate severe variations of trans-\n",
            "lations caused by small input perturbations by re-\n",
            "placing one word in each sentence of a test set with\n",
            "its synonym.\n",
            "We observe that 69:74% of transla-\n",
            "tions have changed and the BLEU score is only\n",
            "79:01between the translations of the original in-\n",
            "puts and the translations of the perturbed inputs,\n",
            "suggesting that NMT models are very sensitive to\n",
            "small perturbations in the input.\n",
            "We intro-\n",
            "duce adversarial learning to make behaviors of the\n",
            "encoder consistent for both an input and its per-\n",
            "turbed counterpart.\n",
            "The neural network consists of two components:\n",
            "an encoder network that encodes the input sen-\n",
            "tence into a sequence of distributed representa-\n",
            "tions, based on which a decoder network generates\n",
            "the translation with an attention model (Bahdanau\n",
            "et al., 2015; Luong et al., 2015).\n",
            "Table 1: The non-robustness problem of neural\n",
            "machine translation.\n",
            "\n",
            "\n",
            "Top-ranked sentences for Section 2 Background:\n",
            "We nd\n",
            "that word-based and subword-based NMT mod-\n",
            "els also confront with this shortcoming, as shown\n",
            "in Table 1.\n",
            "We argue that the distributed repre-\n",
            "sentations should fulll the stability expectation,\n",
            "which is the underlying concept of the proposed\n",
            "approach.\n",
            "Thus the model parameters of NMT include the\n",
            "parameter sets of the encoder \u0012encand the decoder\n",
            "\u0012dec:\u0012=f\u0012enc;\u0012decg.\n",
            "The standard training ob-\n",
            "jective is to minimize the negative log-likelihood\n",
            "of the training corpus S=fhx(s);y(s)igjSj\n",
            "s=1:\n",
            "^\u0012= argmin\n",
            "\u0012L(x;y;\u0012)\n",
            "= argmin\n",
            "\u0012nX\n",
            "hx;yi2S\u0000logP(yjx;\u0012)o\n",
            "(3)\n",
            "Due to the vulnerability and instability of deep\n",
            "neural networks, NMT models usually suffer from\n",
            "a drawback: small perturbations in the input can\n",
            "dramatically deteriorate its translation results.\n",
            "The dark solid arrow lines\n",
            "represent the forward-pass information ow for\n",
            "the input sentence x, while the red dashed arrow\n",
            "lines for the noisy input sentence x0, which is\n",
            "transformed from xby adding small perturbations.\n",
            "\n",
            "\n",
            "Top-ranked sentences for Section 3 Approach:\n",
            "We aim at learning\n",
            "the perturbation-invariant encoder and decoder.\n",
            "We require that x0is a subtle\n",
            "variation from xand they have similar semantics.\n",
            "We cast this objective in the ad-\n",
            "versarial learning framework.\n",
            "We conclude this section with the\n",
            "training strategy (Section 3.4).\n",
            "We add the Gaussian\n",
            "noise to a word embedding to simulate possible\n",
            "types of perturbations.\n",
            "\n",
            "\n",
            "Top-ranked sentences for Section 4 Experiments:\n",
            "study on the Chinese-English translation to under-\n",
            "stand the importance of these loss functions by\n",
            "choosing AST lexical as an example.\n",
            "p means the loss function is included in\n",
            "the training objective while  \u0002 means it is not.\n",
            "denotes that we conduct one operation (swap, replacement or deletion) on the original sentence.\n",
            "approaches have the capability of resisting pertur-\n",
            "bations.\n",
            "Zhang et al.\n",
            "\n",
            "\n",
            "Top-ranked sentences for Section 5 Related Work:\n",
            "We adopt adversarial learning to\n",
            "learn the perturbation-invariant encoder.\n",
            "We do\n",
            "not resort to any complicated models to generate\n",
            "perturbed data and do not depend on extra mono-\n",
            "lingual or bilingual corpora.\n",
            "We\n",
            "focus more on improving the robustness of NMT\n",
            "models.\n",
            "They all\n",
            "leverage complex models such as inverse NMT\n",
            "models to generate translation equivalents for\n",
            "monolingual corpora.\n",
            "Then they augment the par-\n",
            "allel corpora with these pseudo corpora to improveNMT models.\n",
            "\n",
            "\n",
            "Top-ranked sentences for Section 6 Conclusion:\n",
            "Yang Liu is sup-\n",
            "ported by the National Key R&D Program of\n",
            "China (No.\n",
            "We propose two approaches\n",
            "to construct perturbed data to adversarially train\n",
            "the encoder and stabilize the decoder.\n",
            "We also thank\n",
            "Xiaoling Li for analyzing experimental results and\n",
            "providing valuable examples.\n",
            "The ba-\n",
            "sic idea is to train both the encoder and decoder\n",
            "robust to input perturbations by enabling them to\n",
            "behave similarly for the original input and its per-\n",
            "turbed counterpart.\n",
            "It is also necessary to\n",
            "further validate our approach on more advanced\n",
            "NMT architectures, such as CNN-based NMT\n",
            "(Gehring et al., 2017) and Transformer (Vaswani\n",
            "et al., 2017).\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Creating a list to store the top-5 sentences of each section\n",
        "\n",
        "# Iterate through each section and extract the top-ranked sentences\n",
        "for section, sentences in section_sentences.items():\n",
        "    # Sort sentences by score in descending order\n",
        "    sentences = sorted(sentences, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    # Choose the top-ranked sentences\n",
        "    top_sentences = [sentence for sentence in sentences[:num_top_sentences]]\n",
        "\n",
        "    # Append the top sentences to the result list\n",
        "    top_ranked_sentences.extend(top_sentences)\n",
        "\n",
        "    print(f\"Top-ranked sentences for Section {section}:\\n\" + ''.join(sentence + '\\n' for sentence in top_sentences) + '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXFGDR1N2RkI",
        "outputId": "51ff5b03-06e4-4f76-a4c5-263b35bdde3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-ranked sentences for Section Abstract:\n",
            "The basic idea is\n",
            "to make both the encoder and decoder in\n",
            "NMT models robust against input pertur-\n",
            "bations by enabling them to behave sim-\n",
            "ilarly for the original input and its per-\n",
            "turbed counterpart.\n",
            "In this paper, we propose to improve\n",
            "the robustness of NMT models with adver-\n",
            "sarial stability training.\n",
            "Experimental results\n",
            "on Chinese-English, English-German and\n",
            "English-French translation tasks show that\n",
            "our approaches can not only achieve sig-\n",
            "nicant improvements over strong NMT\n",
            "systems but also improve the robustness of\n",
            "NMT models.\n",
            "Abstract\n",
            "Small perturbations in the input can\n",
            "severely distort intermediate representa-\n",
            "tions and thus impact translation quality of\n",
            "neural machine translation (NMT) mod-\n",
            "els.\n",
            "\n",
            "\n",
            "Top-ranked sentences for Section 1 Introduction:\n",
            "We investigate severe variations of trans-\n",
            "lations caused by small input perturbations by re-\n",
            "placing one word in each sentence of a test set with\n",
            "its synonym.\n",
            "We observe that 69:74% of transla-\n",
            "tions have changed and the BLEU score is only\n",
            "79:01between the translations of the original in-\n",
            "puts and the translations of the perturbed inputs,\n",
            "suggesting that NMT models are very sensitive to\n",
            "small perturbations in the input.\n",
            "We intro-\n",
            "duce adversarial learning to make behaviors of the\n",
            "encoder consistent for both an input and its per-\n",
            "turbed counterpart.\n",
            "The neural network consists of two components:\n",
            "an encoder network that encodes the input sen-\n",
            "tence into a sequence of distributed representa-\n",
            "tions, based on which a decoder network generates\n",
            "the translation with an attention model (Bahdanau\n",
            "et al., 2015; Luong et al., 2015).\n",
            "Table 1: The non-robustness problem of neural\n",
            "machine translation.\n",
            "\n",
            "\n",
            "Top-ranked sentences for Section 2 Background:\n",
            "We nd\n",
            "that word-based and subword-based NMT mod-\n",
            "els also confront with this shortcoming, as shown\n",
            "in Table 1.\n",
            "We argue that the distributed repre-\n",
            "sentations should fulll the stability expectation,\n",
            "which is the underlying concept of the proposed\n",
            "approach.\n",
            "Thus the model parameters of NMT include the\n",
            "parameter sets of the encoder \u0012encand the decoder\n",
            "\u0012dec:\u0012=f\u0012enc;\u0012decg.\n",
            "The standard training ob-\n",
            "jective is to minimize the negative log-likelihood\n",
            "of the training corpus S=fhx(s);y(s)igjSj\n",
            "s=1:\n",
            "^\u0012= argmin\n",
            "\u0012L(x;y;\u0012)\n",
            "= argmin\n",
            "\u0012nX\n",
            "hx;yi2S\u0000logP(yjx;\u0012)o\n",
            "(3)\n",
            "Due to the vulnerability and instability of deep\n",
            "neural networks, NMT models usually suffer from\n",
            "a drawback: small perturbations in the input can\n",
            "dramatically deteriorate its translation results.\n",
            "The dark solid arrow lines\n",
            "represent the forward-pass information ow for\n",
            "the input sentence x, while the red dashed arrow\n",
            "lines for the noisy input sentence x0, which is\n",
            "transformed from xby adding small perturbations.\n",
            "\n",
            "\n",
            "Top-ranked sentences for Section 3 Approach:\n",
            "We aim at learning\n",
            "the perturbation-invariant encoder and decoder.\n",
            "We require that x0is a subtle\n",
            "variation from xand they have similar semantics.\n",
            "We cast this objective in the ad-\n",
            "versarial learning framework.\n",
            "We conclude this section with the\n",
            "training strategy (Section 3.4).\n",
            "We add the Gaussian\n",
            "noise to a word embedding to simulate possible\n",
            "types of perturbations.\n",
            "\n",
            "\n",
            "Top-ranked sentences for Section 4 Experiments:\n",
            "study on the Chinese-English translation to under-\n",
            "stand the importance of these loss functions by\n",
            "choosing AST lexical as an example.\n",
            "p means the loss function is included in\n",
            "the training objective while  \u0002 means it is not.\n",
            "denotes that we conduct one operation (swap, replacement or deletion) on the original sentence.\n",
            "approaches have the capability of resisting pertur-\n",
            "bations.\n",
            "Zhang et al.\n",
            "\n",
            "\n",
            "Top-ranked sentences for Section 5 Related Work:\n",
            "We adopt adversarial learning to\n",
            "learn the perturbation-invariant encoder.\n",
            "We do\n",
            "not resort to any complicated models to generate\n",
            "perturbed data and do not depend on extra mono-\n",
            "lingual or bilingual corpora.\n",
            "We\n",
            "focus more on improving the robustness of NMT\n",
            "models.\n",
            "They all\n",
            "leverage complex models such as inverse NMT\n",
            "models to generate translation equivalents for\n",
            "monolingual corpora.\n",
            "Then they augment the par-\n",
            "allel corpora with these pseudo corpora to improveNMT models.\n",
            "\n",
            "\n",
            "Top-ranked sentences for Section 6 Conclusion:\n",
            "Yang Liu is sup-\n",
            "ported by the National Key R&D Program of\n",
            "China (No.\n",
            "We propose two approaches\n",
            "to construct perturbed data to adversarially train\n",
            "the encoder and stabilize the decoder.\n",
            "We also thank\n",
            "Xiaoling Li for analyzing experimental results and\n",
            "providing valuable examples.\n",
            "The ba-\n",
            "sic idea is to train both the encoder and decoder\n",
            "robust to input perturbations by enabling them to\n",
            "behave similarly for the original input and its per-\n",
            "turbed counterpart.\n",
            "It is also necessary to\n",
            "further validate our approach on more advanced\n",
            "NMT architectures, such as CNN-based NMT\n",
            "(Gehring et al., 2017) and Transformer (Vaswani\n",
            "et al., 2017).\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Creating a dictionary for stroing top-ranked sentences\n",
        "\n",
        "top_ranked_sentences = {}\n",
        "\n",
        "# Iterate through each section and extract the top-ranked sentences\n",
        "for section, sentences in section_sentences.items():\n",
        "    # Sort sentences by score in descending order\n",
        "    sentences = sorted(sentences, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    # Choose the top-ranked sentences\n",
        "    top_sentences = [sentence for sentence in sentences[:num_top_sentences]]\n",
        "\n",
        "    # Store the top sentences in the dictionary\n",
        "    top_ranked_sentences[section] = top_sentences\n",
        "\n",
        "    # Print the top-ranked sentences for each section\n",
        "    print(f\"Top-ranked sentences for Section {section}:\\n\" + ''.join(sentence + '\\n' for sentence in top_sentences) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-mwnjUKfomF"
      },
      "source": [
        "### Measuring the similarity score of each section summaries with user query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyHs2RHGQUTO"
      },
      "source": [
        "#### Using TF-IDF embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYl1-lYTpnY6",
        "outputId": "2546a02b-4c6a-4b0b-fe63-332995b0fd0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity score with Section 'Abstract': 0.21969401455243595\n",
            "Similarity score with Section '1 Introduction': 0.16707667138625515\n",
            "Similarity score with Section '2 Background': 0.09953452035868789\n",
            "Similarity score with Section '3 Approach': 0.027434434688052876\n",
            "Similarity score with Section '4 Experiments': 0.07698533809506916\n",
            "Similarity score with Section '5 Related Work': 0.04598916507931692\n",
            "Similarity score with Section '6 Conclusion': 0.11917591430622483\n"
          ]
        }
      ],
      "source": [
        "# Similarity score of query with each section containing entire text in that section before applying LSA\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def text_similarity(text1, text2):\n",
        "    # Ensure that the input is a string\n",
        "    text1 = str(text1)\n",
        "    text2 = str(text2)\n",
        "\n",
        "    # Tokenize and lemmatize the texts, applying lowercasing to individual words\n",
        "    tokens1 = [word.lower() for word in sent_tokenize(text1)]\n",
        "    tokens2 = [word.lower() for word in sent_tokenize(text2)]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens1 = [lemmatizer.lemmatize(token) for token in tokens1]\n",
        "    tokens2 = [lemmatizer.lemmatize(token) for token in tokens2]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = stopwords.words('english')\n",
        "    tokens1 = [token for token in tokens1 if token not in stop_words]\n",
        "    tokens2 = [token for token in tokens2 if token not in stop_words]\n",
        "\n",
        "    # Join tokens into strings\n",
        "    text1_processed = ' '.join(tokens1)\n",
        "    text2_processed = ' '.join(tokens2)\n",
        "\n",
        "    # Create the TF-IDF vectors\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vector1 = vectorizer.fit_transform([text1_processed])\n",
        "    vector2 = vectorizer.transform([text2_processed])\n",
        "\n",
        "    # Calculate the cosine similarity (single value for whole texts)\n",
        "    similarity = cosine_similarity(vector1, vector2)[0][0]\n",
        "\n",
        "    return similarity\n",
        "\n",
        "# Example usage:\n",
        "text2 = 'Neural Machine Translation; Attention Mechanism, Language Translation.'\n",
        "\n",
        "# Calculate similarity with each section header\n",
        "similarity_scores = {}\n",
        "for section in sections:\n",
        "    similarity_score = text_similarity(section_extraction[sections.index(section)], text2)\n",
        "    similarity_scores[section] = similarity_score\n",
        "\n",
        "# Display similarity scores\n",
        "for section, score in similarity_scores.items():\n",
        "    print(f\"Similarity score with Section '{section}': {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jzic4Rizo-kO",
        "outputId": "4cc3489d-936e-48d6-e355-b911583cccd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity score with Section after LSA'Abstract': 0.21969401455243598\n",
            "Similarity score with Section after LSA'1 Introduction': 0.15099716057227913\n",
            "Similarity score with Section after LSA'2 Background': 0.0586658554900754\n",
            "Similarity score with Section after LSA'3 Approach': 0.0\n",
            "Similarity score with Section after LSA'4 Experiments': 0.09901475429766744\n",
            "Similarity score with Section after LSA'5 Related Work': 0.0816496580927726\n",
            "Similarity score with Section after LSA'6 Conclusion': 0.0\n"
          ]
        }
      ],
      "source": [
        "# Similarity score of query with each section containing only top 5 ranked sentences in that section after applying LSA\n",
        "\n",
        "def text_similarity(text1, text2):\n",
        "    # Ensure that the input is a string\n",
        "    text1 = str(text1)\n",
        "    text2 = str(text2)\n",
        "\n",
        "    # Tokenize and lemmatize the texts, applying lowercasing to individual words\n",
        "    tokens1 = [word.lower() for word in sent_tokenize(text1)]\n",
        "    tokens2 = [word.lower() for word in sent_tokenize(text2)]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens1 = [lemmatizer.lemmatize(token) for token in tokens1]\n",
        "    tokens2 = [lemmatizer.lemmatize(token) for token in tokens2]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = stopwords.words('english')\n",
        "    tokens1 = [token for token in tokens1 if token not in stop_words]\n",
        "    tokens2 = [token for token in tokens2 if token not in stop_words]\n",
        "\n",
        "    # Join tokens into strings\n",
        "    text1_processed = ' '.join(tokens1)\n",
        "    text2_processed = ' '.join(tokens2)\n",
        "\n",
        "    # Create the TF-IDF vectors\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vector1 = vectorizer.fit_transform([text1_processed])\n",
        "    vector2 = vectorizer.transform([text2_processed])\n",
        "\n",
        "    # Calculate the cosine similarity (single value for whole texts)\n",
        "    similarity = cosine_similarity(vector1, vector2)[0][0]\n",
        "\n",
        "    return similarity\n",
        "\n",
        "# Example usage:\n",
        "text2 = 'Neural Machine Translation; Attention Mechanism, Language Translation.'\n",
        "\n",
        "# Calculate similarity with each section header\n",
        "similarity_scores = {}\n",
        "for section in sections:\n",
        "    similarity_score = text_similarity(' '.join(top_ranked_sentences[section]), text2)\n",
        "    similarity_scores[section] = similarity_score\n",
        "\n",
        "# Display similarity scores\n",
        "for section, score in similarity_scores.items():\n",
        "    print(f\"Similarity score with Section after LSA'{section}': {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jypg1727I15G",
        "outputId": "1d735a22-1453-421b-9129-44d4f315dffb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Similarity Score: 0.10798429406657754\n"
          ]
        }
      ],
      "source": [
        "# Getting average similarity score of the sections with entire text without LSA applied\n",
        "\n",
        "# Example text 2\n",
        "text2 = 'Neural Machine Translation; Attention Mechanism, Language Translation.'\n",
        "\n",
        "# Calculate similarity scores for each section header\n",
        "similarity_scores = []\n",
        "for section_text in section_extraction:\n",
        "    similarity_score = text_similarity(section_text, text2)\n",
        "    similarity_scores.append(similarity_score)\n",
        "\n",
        "# Calculate the average similarity score\n",
        "average_similarity = sum(similarity_scores) / len(similarity_scores)\n",
        "\n",
        "print(\"Average Similarity Score:\", average_similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J37Nj3l6pqOt",
        "outputId": "4e434c10-e383-4bc2-f91a-9a83f4597746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Similarity Score with Top Ranked Sentences after LSA: 0.08714592042931865\n"
          ]
        }
      ],
      "source": [
        "# Getting average similarity score of section only with top 5 ranked sentences after LSA applied\n",
        "\n",
        "def text_similarity(text1, text2):\n",
        "    # Ensure that the input is a string\n",
        "    text1 = str(text1)\n",
        "    text2 = str(text2)\n",
        "\n",
        "    # Tokenize and lemmatize the texts, applying lowercasing to individual words\n",
        "    tokens1 = [word.lower() for word in sent_tokenize(text1)]\n",
        "    tokens2 = [word.lower() for word in sent_tokenize(text2)]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens1 = [lemmatizer.lemmatize(token) for token in tokens1]\n",
        "    tokens2 = [lemmatizer.lemmatize(token) for token in tokens2]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = stopwords.words('english')\n",
        "    tokens1 = [token for token in tokens1 if token not in stop_words]\n",
        "    tokens2 = [token for token in tokens2 if token not in stop_words]\n",
        "\n",
        "    # Join tokens into strings\n",
        "    text1_processed = ' '.join(tokens1)\n",
        "    text2_processed = ' '.join(tokens2)\n",
        "\n",
        "    # Create the TF-IDF vectors\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vector1 = vectorizer.fit_transform([text1_processed])\n",
        "    vector2 = vectorizer.transform([text2_processed])\n",
        "\n",
        "    # Calculate the cosine similarity (single value for whole texts)\n",
        "    similarity = cosine_similarity(vector1, vector2)[0][0]\n",
        "\n",
        "    return similarity\n",
        "\n",
        "# Example usage:\n",
        "text2 = 'Neural Machine Translation; Attention Mechanism, Language Translation.'\n",
        "\n",
        "# Calculate similarity scores for each section header using top ranked sentences\n",
        "similarity_scores = []\n",
        "for section, top_sentences in top_ranked_sentences.items():\n",
        "    section_text = ' '.join(top_sentences)\n",
        "    similarity_score = text_similarity(section_text, text2)\n",
        "    similarity_scores.append(similarity_score)\n",
        "\n",
        "# Calculate the average similarity score\n",
        "average_similarity = sum(similarity_scores) / len(similarity_scores)\n",
        "\n",
        "print(\"Average Similarity Score with Top Ranked Sentences after LSA:\", average_similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWU99aqNOOlD",
        "outputId": "b8fa9d3b-dcef-4691-9251-4c7713cf5de5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: prettytable in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (3.9.0)\n",
            "Requirement already satisfied: wcwidth in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from prettytable) (0.2.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install prettytable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtPb0HnyLLjH",
        "outputId": "51759a34-27c1-4a3a-d0cf-a28af12279e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------------------------------+------------------+\n",
            "| Section with entire pdf text usinf TF-IDF | Similarity Score |\n",
            "+-------------------------------------------+------------------+\n",
            "|                  Abstract                 |     0.219694     |\n",
            "|               1 Introduction              |     0.167077     |\n",
            "|                2 Background               |     0.099535     |\n",
            "|                 3 Approach                |     0.027434     |\n",
            "|               4 Experiments               |     0.076985     |\n",
            "|               5 Related Work              |     0.045989     |\n",
            "|                6 Conclusion               |     0.119176     |\n",
            "|             Average Similarity            |     0.107984     |\n",
            "+-------------------------------------------+------------------+\n"
          ]
        }
      ],
      "source": [
        "# Table for displaying the similarity score of each section with entire text\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "# Example usage:\n",
        "text2 = 'Neural Machine Translation; Attention Mechanism, Language Translation.'\n",
        "\n",
        "# Calculate similarity with each section header\n",
        "similarity_scores = {}\n",
        "for section in sections:\n",
        "    similarity_score = text_similarity(section_extraction[sections.index(section)], text2)\n",
        "    similarity_scores[section] = similarity_score\n",
        "\n",
        "# Display similarity scores in a table\n",
        "table = PrettyTable()\n",
        "table.field_names = [\"Section with entire pdf text usinf TF-IDF\", \"Similarity Score\"]\n",
        "\n",
        "for section, score in similarity_scores.items():\n",
        "    table.add_row([section, f\"{score:.6f}\"])\n",
        "\n",
        "# Calculate and add the average similarity score to the table\n",
        "average_similarity = sum(similarity_scores.values()) / len(similarity_scores)\n",
        "table.add_row([\"Average Similarity\", f\"{average_similarity:.6f}\"])\n",
        "\n",
        "# Print the table\n",
        "print(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nB7uBzAqNU5",
        "outputId": "ddad28cf-0f20-46c5-c338-0fa95909f8f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------+------------------+\n",
            "|   Section with LSA for TF-IDF   | Similarity Score |\n",
            "+---------------------------------+------------------+\n",
            "|             Abstract            |     0.219694     |\n",
            "|          1 Introduction         |     0.150997     |\n",
            "|           2 Background          |     0.058666     |\n",
            "|            3 Approach           |     0.000000     |\n",
            "|          4 Experiments          |     0.099015     |\n",
            "|          5 Related Work         |     0.081650     |\n",
            "|           6 Conclusion          |     0.000000     |\n",
            "| Average Similarity (Top Ranked) |     0.087146     |\n",
            "+---------------------------------+------------------+\n"
          ]
        }
      ],
      "source": [
        "# Table for similarity score of sections with top ranked sentences of LSA\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "# Example text 2\n",
        "text2 = 'Neural Machine Translation; Attention Mechanism, Language Translation.'\n",
        "\n",
        "# Calculate similarity scores for each section using top-ranked sentences\n",
        "similarity_scores_top_ranked = {}\n",
        "for section, top_sentences in top_ranked_sentences.items():\n",
        "    section_text = ' '.join(top_sentences)\n",
        "    similarity_score = text_similarity(section_text, text2)\n",
        "    similarity_scores_top_ranked[section] = similarity_score\n",
        "\n",
        "# Display similarity scores in a table for top-ranked sentences\n",
        "table_top_ranked = PrettyTable()\n",
        "table_top_ranked.field_names = [\"Section with LSA for TF-IDF\", \"Similarity Score\"]\n",
        "\n",
        "for section, score in similarity_scores_top_ranked.items():\n",
        "    table_top_ranked.add_row([section, f\"{score:.6f}\"])\n",
        "\n",
        "# Calculate and add the average similarity score to the table\n",
        "average_similarity_top_ranked = sum(similarity_scores_top_ranked.values()) / len(similarity_scores_top_ranked)\n",
        "table_top_ranked.add_row([\"Average Similarity (Top Ranked)\", f\"{average_similarity_top_ranked:.6f}\"])\n",
        "\n",
        "# Print the table for top-ranked sentences\n",
        "print(table_top_ranked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCTbXl5CQ_Oo"
      },
      "source": [
        "### Evaluation Metric for validating the performance of LSA summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tue-DT9DMhLH",
        "outputId": "9ed3a689-7abf-4a02-fe7b-60fa28b2d5d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (3.8.1)\n",
            "Requirement already satisfied: py-rouge in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (1.1)\n",
            "Requirement already satisfied: click in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: colorama in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk py-rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hzcd6Fz8SMhc",
        "outputId": "5b792f46-27db-4900-e496-73ca29dcf058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge-score in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from rouge-score) (2.0.0)\n",
            "Requirement already satisfied: nltk in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from rouge-score) (1.26.2)\n",
            "Requirement already satisfied: six>=1.14.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from nltk->rouge-score) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from nltk->rouge-score) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from nltk->rouge-score) (4.66.1)\n",
            "Requirement already satisfied: colorama in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from click->nltk->rouge-score) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2znKFZQ0PX8",
        "outputId": "d75d516a-e963-4b0b-b68a-e23038725bee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scores for Section 'Abstract' (Sections have the entire text in the generated summary):\n",
            "BLEU Score: 0.24203006556309162\n",
            "METEOR Score: 0.5629651422531682\n",
            "ROUGE-1 F-measure: 0.6232558139534884\n",
            "ROUGE-2 F-measure: 0.36619718309859156\n",
            "ROUGE-L F-measure: 0.5674418604651164\n",
            "\n",
            "Scores for Section '1 Introduction' (Sections have the entire text in the generated summary):\n",
            "BLEU Score: 0.024943677360793858\n",
            "METEOR Score: 0.28088956765191936\n",
            "ROUGE-1 F-measure: 0.2035010940919037\n",
            "ROUGE-2 F-measure: 0.08552631578947367\n",
            "ROUGE-L F-measure: 0.13566739606126915\n",
            "\n",
            "Scores for Section '2 Background' (Sections have the entire text in the generated summary):\n",
            "BLEU Score: 0.07234728215674198\n",
            "METEOR Score: 0.4060530443860149\n",
            "ROUGE-1 F-measure: 0.38229376257545267\n",
            "ROUGE-2 F-measure: 0.1898989898989899\n",
            "ROUGE-L F-measure: 0.2776659959758551\n",
            "\n",
            "Scores for Section '3 Approach' (Sections have the entire text in the generated summary):\n",
            "BLEU Score: 0.021352657188482067\n",
            "METEOR Score: 0.20770392749244715\n",
            "ROUGE-1 F-measure: 0.1326949384404925\n",
            "ROUGE-2 F-measure: 0.0726027397260274\n",
            "ROUGE-L F-measure: 0.08481532147742818\n",
            "\n",
            "Scores for Section '4 Experiments' (Sections have the entire text in the generated summary):\n",
            "BLEU Score: 0.009434028095217631\n",
            "METEOR Score: 0.15009159437461533\n",
            "ROUGE-1 F-measure: 0.07114933541829556\n",
            "ROUGE-2 F-measure: 0.045383411580594675\n",
            "ROUGE-L F-measure: 0.06098514464425332\n",
            "\n",
            "Scores for Section '5 Related Work' (Sections have the entire text in the generated summary):\n",
            "BLEU Score: 0.08343667265762783\n",
            "METEOR Score: 0.4378751974723539\n",
            "ROUGE-1 F-measure: 0.35207823960880197\n",
            "ROUGE-2 F-measure: 0.19656019656019658\n",
            "ROUGE-L F-measure: 0.2836185819070905\n",
            "\n",
            "Scores for Section '6 Conclusion' (Sections have the entire text in the generated summary):\n",
            "BLEU Score: 0.12499748107985903\n",
            "METEOR Score: 0.5192088517052726\n",
            "ROUGE-1 F-measure: 0.4662576687116564\n",
            "ROUGE-2 F-measure: 0.2839506172839506\n",
            "ROUGE-L F-measure: 0.39877300613496935\n",
            "\n",
            "\n",
            "Generated Summary with Content of Top-Ranked Sentences:\n",
            "Abstract\n",
            "Small perturbations in the input can\n",
            "severely distort intermediate representa-\n",
            "tions and thus impact translation quality of\n",
            "neural machine translation (NMT) mod-\n",
            "els. In this paper, we propose to improve\n",
            "the robustness of NMT models with adver-\n",
            "sarial stability training. The basic idea is\n",
            "to make both the encoder and decoder in\n",
            "NMT models robust against input pertur-\n",
            "bations by enabling them to behave sim-\n",
            "ilarly for the original input and its per-\n",
            "turbed counterpart. Experimental results\n",
            "on Chinese-English, English-German and\n",
            "English-French translation tasks show that\n",
            "our approaches can not only achieve sig-\n",
            "nicant improvements over strong NMT\n",
            "systems but also improve the robustness of\n",
            "NMT models. 1 Introduction\n",
            "Neural machine translation (NMT) models have\n",
            "advanced the state of the art by building a sin-\n",
            "gle neural network that can better learn represen-\n",
            "tations (Cho et al., 2014; Sutskever et al., 2014). The neural network consists of two components:\n",
            "an encoder network that encodes the input sen-\n",
            "tence into a sequence of distributed representa-\n",
            "tions, based on which a decoder network generates\n",
            "the translation with an attention model (Bahdanau\n",
            "et al., 2015; Luong et al., 2015). A variety of NMT\n",
            "models derived from this encoder-decoder frame-\n",
            "work have further improved the performance of\n",
            "machine translation systems (Gehring et al., 2017;\n",
            "Vaswani et al., 2017). NMT is capable of general-\n",
            "izing better to unseen text by exploiting word simi-\n",
            "larities in embeddings and capturing long-distance\n",
            "reordering by conditioning on larger contexts in a\n",
            "continuous way.Input tamen bupa kunnan zuochu weiqi AI. OutputThey are not afraid of difculties to\n",
            "make Go AI. Input tamen buwei kunnan zuochu weiqi AI. Output They are not afraid to make Go AI. Table 1: The non-robustness problem of neural\n",
            "machine translation. Replacing a Chinese word\n",
            "with its synonym (i.e.,  bupa !buwei ) leads to\n",
            "signicant erroneous changes in the English trans-\n",
            "lation. Both  bupa  and  buwei  can be translated\n",
            "to the English phrase  be not afraid of . However, studies reveal that very small changes\n",
            "to the input can fool state-of-the-art neural net-\n",
            "works with high probability (Goodfellow et al.,\n",
            "2015; Szegedy et al., 2014). Belinkov and Bisk\n",
            "(2018) conrm this nding by pointing out that\n",
            "NMT models are very brittle and easily falter\n",
            "when presented with noisy input. In NMT, due\n",
            "to the introduction of RNN and attention, each\n",
            "contextual word can inuence the model predic-\n",
            "tion in a global context, which is analogous to the\n",
            "buttery effect. As shown in Table 1, although\n",
            "we only replace a source word with its synonym,\n",
            "the generated translation has been completely dis-\n",
            "torted. We investigate severe variations of trans-\n",
            "lations caused by small input perturbations by re-\n",
            "placing one word in each sentence of a test set with\n",
            "its synonym. We observe that 69:74% of transla-\n",
            "tions have changed and the BLEU score is only\n",
            "79:01between the translations of the original in-\n",
            "puts and the translations of the perturbed inputs,\n",
            "suggesting that NMT models are very sensitive to\n",
            "small perturbations in the input. The vulnerabil-\n",
            "ity and instability of NMT models limit their ap-\n",
            "plicability to a broader range of tasks, which re-\n",
            "quire robust performance on noisy inputs. For ex-\n",
            "ample, simultaneous translation systems use auto-arXiv:1805.06130v1  [cs.CL]  16 May 2018matic speech recognition (ASR) to transcribe in-\n",
            "put speech into a sequence of hypothesized words,\n",
            "which are subsequently fed to a translation sys-\n",
            "tem. In this pipeline, ASR errors are presented as\n",
            "sentences with noisy perturbations (the same pro-\n",
            "nunciation but incorrect words), which is a signif-\n",
            "icant challenge for current NMT models. More-\n",
            "over, instability makes NMT models sensitive to\n",
            "misspellings and typos in text translation. In this paper, we address this challenge with\n",
            "adversarial stability training for neural machine\n",
            "translation. The basic idea is to improve the ro-\n",
            "bustness of two important components in NMT:\n",
            "the encoder and decoder. To this end, we pro-\n",
            "pose two approaches to constructing noisy inputs\n",
            "with small perturbations to make NMT models re-\n",
            "sist them. As important intermediate representa-\n",
            "tions encoded by the encoder, they directly deter-\n",
            "mine the accuracy of nal translations. We intro-\n",
            "duce adversarial learning to make behaviors of the\n",
            "encoder consistent for both an input and its per-\n",
            "turbed counterpart. To improve the stability of the\n",
            "decoder, our method jointly maximizes the likeli-\n",
            "hoods of original and perturbed data. Adversarial\n",
            "stability training has the following advantages:\n",
            "1.Improving both the robustness and transla-\n",
            "tion performance : Our adversarial stability\n",
            "training is capable of not only improving the\n",
            "robustness of NMT models but also achiev-\n",
            "ing better translation performance. 2.Applicable to arbitrary noisy perturbations :\n",
            "In this paper, we propose two approaches to\n",
            "constructing noisy perturbations for inputs. However, our training framework can be eas-\n",
            "ily extended to arbitrary noisy perturbations. Especially, we can design task-specic per-\n",
            "turbation methods. 3.Transparent to network architectures : Our\n",
            "adversarial stability training does not depend\n",
            "on specic NMT architectures. It can be ap-\n",
            "plied to arbitrary NMT systems. Experiments on Chinese-English, English-\n",
            "French and English-German translation tasks\n",
            "show that adversarial stability training achieves\n",
            "signicant improvements across different lan-\n",
            "guages pairs. Our NMT system outperforms\n",
            "the state-of-the-art RNN-based NMT system\n",
            "(GNMT) (Wu et al., 2016) and obtains compara-\n",
            "ble performance with the CNN-based NMT sys-tem (Gehring et al., 2017). Related experimen-\n",
            "tal analyses validate that our training approach can\n",
            "improve the robustness of NMT models. 2 Background\n",
            "NMT is an end-to-end framework which directly\n",
            "optimizes the translation probability of a target\n",
            "sentence y=y1;:::;y Ngiven its corresponding\n",
            "source sentence x=x1;:::;x M:\n",
            "P(yjx;\u0012) =NY\n",
            "n=1P(ynjy<n;x;\u0012) (1)\n",
            "where \u0012is a set of model parameters and y<nis a\n",
            "partial translation. P(yjx;\u0012)is dened on a holis-\n",
            "tic neural network which mainly includes two core\n",
            "components: an encoder encodes a source sen-\n",
            "tencexinto a sequence of hidden representations\n",
            "Hx=H1;:::;HM, and a decoder generates the\n",
            "n-th target word based on the sequence of hidden\n",
            "representations:\n",
            "P(ynjy<n;x;\u0012)/expfg(yn\u00001;sn;Hx;\u0012)g(2)\n",
            "where snis then-th hidden state on target side. Thus the model parameters of NMT include the\n",
            "parameter sets of the encoder \u0012encand the decoder\n",
            "\u0012dec:\u0012=f\u0012enc;\u0012decg. The standard training ob-\n",
            "jective is to minimize the negative log-likelihood\n",
            "of the training corpus S=fhx(s);y(s)igjSj\n",
            "s=1:\n",
            "^\u0012= argmin\n",
            "\u0012L(x;y;\u0012)\n",
            "= argmin\n",
            "\u0012nX\n",
            "hx;yi2S\u0000logP(yjx;\u0012)o\n",
            "(3)\n",
            "Due to the vulnerability and instability of deep\n",
            "neural networks, NMT models usually suffer from\n",
            "a drawback: small perturbations in the input can\n",
            "dramatically deteriorate its translation results. Be-\n",
            "linkov and Bisk (2018) point out that character-\n",
            "based NMT models are very brittle and easily fal-\n",
            "ter when presented with noisy input. We nd\n",
            "that word-based and subword-based NMT mod-\n",
            "els also confront with this shortcoming, as shown\n",
            "in Table 1. We argue that the distributed repre-\n",
            "sentations should fulll the stability expectation,\n",
            "which is the underlying concept of the proposed\n",
            "approach. Recent work has shown that adversar-\n",
            "ially trained models can be made robust to such\n",
            "perturbations (Zheng et al., 2016; Madry et al.,\n",
            "2018). Inspired by this, in this work, we im-\n",
            "prove the robustness of encoder representations\n",
            "against noisy perturbations with adversarial learn-\n",
            "ing (Goodfellow et al., 2014).xx+perturbations\n",
            "EncoderHxHx\n",
            "Decoder\n",
            "DiscriminatorLinv(x, x)Ltrue(x, y)Lnoisy(x, y)Figure 1: The architecture of NMT with adversar-\n",
            "ial stability training. The dark solid arrow lines\n",
            "represent the forward-pass information ow for\n",
            "the input sentence x, while the red dashed arrow\n",
            "lines for the noisy input sentence x0, which is\n",
            "transformed from xby adding small perturbations. 3 Approach\n",
            "3.1 Overview\n",
            "The goal of this work is to propose a general ap-\n",
            "proach to make NMT models learned to be more\n",
            "robust to input perturbations. Our basic idea is\n",
            "to maintain the consistency of behaviors through\n",
            "the NMT model for the source sentence xand its\n",
            "perturbed counterpart x0. As aforementioned, the\n",
            "NMT model contains two procedures for project-\n",
            "ing a source sentence xto its target sentence y:\n",
            "the encoder is responsible for encoding xas a se-\n",
            "quence of representations Hx, while the decoder\n",
            "outputs ywithHxas input. We aim at learning\n",
            "the perturbation-invariant encoder and decoder. Figure 1 illustrates the architecture of our ap-\n",
            "proach. Given a source sentence x, we construct a\n",
            "set of perturbed sentences N(x), in which each\n",
            "sentence x0is constructed by adding small per-\n",
            "turbations to x. We require that x0is a subtle\n",
            "variation from xand they have similar semantics. Given the input pair ( x,x0), we have two expecta-\n",
            "tions: (1) the encoded representation Hx0should\n",
            "be close to Hx; and (2) given Hx0, the decoder is\n",
            "able to generate the robust output y. To this end,\n",
            "we introduce two additional objectives to improve\n",
            "the robustness of the encoder and decoder:\n",
            "Linv(x;x0)to encourage the encoder to out-\n",
            "put similar intermediate representations Hx\n",
            "andHx0forxandx0to achieve an invariantencoder, which benets outputting the same\n",
            "translations. We cast this objective in the ad-\n",
            "versarial learning framework. Lnoisy(x0;y)to guide the decoder to generate\n",
            "output ygiven the noisy input x0, which is\n",
            "modeled as\u0000logP(yjx0). It can also be de-\n",
            "ned as KL divergence between P(yjx)and\n",
            "P(yjx0)that indicates using P(yjx)to teach\n",
            "P(yjx0). As seen, the two introduced objectives aim to im-\n",
            "prove the robustness of the NMT model which can\n",
            "be free of high variances in target outputs caused\n",
            "by small perturbations in inputs. It is also natural\n",
            "to introduce the original training objective L(x;y)\n",
            "onxandy, which can guarantee good transla-\n",
            "tion performance while keeping the stability of the\n",
            "NMT model. Formally, given a training corpus S, the adver-\n",
            "sarial stability training objective is\n",
            "J(\u0012)\n",
            "=X\n",
            "hx;yi2S\u0010\n",
            "Ltrue(x;y;\u0012enc;\u0012dec)\n",
            "+\u000bX\n",
            "x02N(x)Linv(x;x0;\u0012enc;\u0012dis)\n",
            "+\fX\n",
            "x02N(x)Lnoisy(x0;y;\u0012enc;\u0012dec)\u0011\n",
            "(4)\n",
            "whereLtrue(x;y)andLnoisy(x0;y)are calculated\n",
            "using Equation 3, and Linv(x;x0)is the adversar-\n",
            "ial loss to be described in Section 3.3. \u000band\f\n",
            "control the balance between the original transla-\n",
            "tion task and the stability of the NMT model. \u0012=\n",
            "f\u0012enc;\u0012dec;\u0012disgare trainable parameters of the\n",
            "encoder, decoder, and the newly introduced dis-\n",
            "criminator used in adversarial learning. As seen,\n",
            "the parameters of encoder \u0012encand decoder \u0012dec\n",
            "are trained to minimize both the translation loss\n",
            "Ltrue(x;y)and the stability losses ( Lnoisy(x0;y)\n",
            "andLinv(x;x0)). SinceLnoisy(x0;y)evaluates the translation\n",
            "loss on the perturbed neighbour x0and its corre-\n",
            "sponding target sentence y, it means that we aug-\n",
            "ment the training data by adding perturbed neigh-\n",
            "bours, which can potentially improve the transla-\n",
            "tion performance. In this way, our approach not\n",
            "only makes the output of NMT models more ro-\n",
            "bust, but also improves the performance on the\n",
            "original translation task.In the following sections, we will rst describe\n",
            "how to construct perturbed inputs with different\n",
            "strategies to fulll different goals (Section 3.2),\n",
            "followed by the proposed adversarial learning\n",
            "mechanism for the perturbation-invariant encoder\n",
            "(Section 3.3). We conclude this section with the\n",
            "training strategy (Section 3.4). 3.2 Constructing Perturbed Inputs\n",
            "At each training step, we need to generate a per-\n",
            "turbed neighbour set N(x)for each source sen-\n",
            "tence xfor adversarial stability training. In this\n",
            "paper, we propose two strategies to construct the\n",
            "perturbed inputs at multiple levels of representa-\n",
            "tions. The rst approach generates perturbed neigh-\n",
            "bours at the lexical level. Given an input sentence\n",
            "x, we randomly sample some word positions to\n",
            "be modied. Then we replace words at these posi-\n",
            "tions with other words in the vocabulary according\n",
            "to the following distribution:\n",
            "P(xjxi) =expfcos (E[xi];E[x])gP\n",
            "x2Vxnxiexpfcos (E[xi];E[x])g(5)\n",
            "where E[xi]is the word embedding for word xi,\n",
            "Vxnxiis the source vocabulary set excluding the\n",
            "wordxi, and cos (E[xi];E[x])measures the simi-\n",
            "larity between word xiandx. Thus we can change\n",
            "the word to another word with similar semantics. One potential problem of the above strategy is\n",
            "that it is hard to enumerate all possible positions\n",
            "and possible types to generate perturbed neigh-\n",
            "bours. Therefore, we propose a more general ap-\n",
            "proach to modifying the sentence at the feature\n",
            "level. Given a sentence, we can obtain the word\n",
            "embedding for each word. We add the Gaussian\n",
            "noise to a word embedding to simulate possible\n",
            "types of perturbations. That is\n",
            "E[x0\n",
            "i] =E[xi] +\u000f;\u000f\u0018N(0;\u001b2I) (6)\n",
            "where the vector \u000fis sampled from a Gaussian dis-\n",
            "tribution with variance \u001b2.\u001bis a hyper-parameter. We simply introduce Gaussian noise to all of word\n",
            "embeddings in x. The proposed scheme is a general framework\n",
            "where one can freely dene the strategies to con-\n",
            "struct perturbed inputs. We just present two pos-\n",
            "sible examples here. The rst strategy is poten-\n",
            "tially useful when the training data contains noisy\n",
            "words, while the latter is a more general strategyto improve the robustness of common NMT mod-\n",
            "els. In practice, one can design specic strategies\n",
            "for particular tasks. For example, we can replace\n",
            "correct words with their homonyms (same pronun-\n",
            "ciation but different meanings) to improve NMT\n",
            "models for simultaneous translation systems. 3.3 Adversarial Learning for the\n",
            "Perturbation-invariant Encoder\n",
            "The goal of the perturbation-invariant encoder is\n",
            "to make the representations produced by the en-\n",
            "coder indistinguishable when fed with a correct\n",
            "sentence xand its perturbed counterpart x0, which\n",
            "is directly benecial to the output robustness of\n",
            "the decoder. We cast the problem in the adversar-\n",
            "ial learning framework (Goodfellow et al., 2014). The encoder serves as the generator G, which de-\n",
            "nes the policy that generates a sequence of hid-\n",
            "den representations Hxgiven an input sentence x. We introduce an additional discriminator Dto dis-\n",
            "tinguish the representation of perturbed input Hx0\n",
            "from that of the original input Hx. The goal of\n",
            "the generator G(i.e., encoder) is to produce sim-\n",
            "ilar representations for xandx0which could fool\n",
            "the discriminator, while the discriminator Dtries\n",
            "to correctly distinguish the two representations. Formally, the adversarial learning objective is\n",
            "Linv(x;x0;\u0012enc;\u0012dis)\n",
            "=Ex\u0018S[\u0000logD(G(x))] +\n",
            "Ex0\u0018N(x)\u0002\n",
            "\u0000log(1\u0000D(G(x0)))\u0003\n",
            "(7)\n",
            "The discriminator outputs a classication score\n",
            "given an input representation, and tries to max-\n",
            "imizeD(G(x))to 1 and minimize D(G(x0))to\n",
            "0. The objective encourages the encoder to output\n",
            "similar representations for xandx0, so that the\n",
            "discriminator fails to distinguish them. The training procedure can be regarded as a\n",
            "min-max two-player game. The encoder parame-\n",
            "ters\u0012encare trained to maximize the loss function\n",
            "to fool the discriminator. The discriminator pa-\n",
            "rameters \u0012disare optimized to minimize this loss\n",
            "for improving the discriminating ability. For ef-\n",
            "ciency, we update both the encoder and the dis-\n",
            "criminator simultaneously at each iteration, rather\n",
            "than the periodical training strategy that is com-\n",
            "monly used in adversarial learning. Lamb et al. (2016) also propose a similar idea to use Professor\n",
            "Forcing to make the behaviors of RNNs be indis-\n",
            "tinguishable when training and sampling the net-\n",
            "works.3.4 Training\n",
            "As shown in Figure 1, our training objective in-\n",
            "cludes three sets of model parameters for three\n",
            "modules. We use mini-batch stochastic gradient\n",
            "descent to optimize our model. In the forward\n",
            "pass, besides a mini-batch of xandy, we also\n",
            "construct a mini-batch consisting of the perturbed\n",
            "neighbour x0andy. We propagate the informa-\n",
            "tion to calculate these three loss functions accord-\n",
            "ing to arrows. Then, gradients are collected to up-\n",
            "date three sets of model parameters. Except for\n",
            "the gradients ofLinvwith respect to \u0012encare mul-\n",
            "tiplying by\u00001, other gradients are normally back-\n",
            "propagated. Note that we update \u0012invand\u0012encsi-\n",
            "multaneously for training efciency. 4 Experiments\n",
            "4.1 Setup\n",
            "We evaluated our adversarial stability training on\n",
            "translation tasks of several language pairs, and re-\n",
            "ported the 4-gram BLEU (Papineni et al., 2002)\n",
            "score as calculated by the multi-bleu.perl script. Chinese-English We used the LDC corpus con-\n",
            "sisting of 1.25M sentence pairs with 27.9M Chi-\n",
            "nese words and 34.5M English words respectively. We selected the best model using the NIST 2006\n",
            "set as the validation set (hyper-parameter opti-\n",
            "mization and model selection). The NIST 2002,\n",
            "2003, 2004, 2005, and 2008 datasets are used as\n",
            "test sets. English-German We used the WMT 14 corpus\n",
            "containing 4.5M sentence pairs with 118M En-\n",
            "glish words and 111M German words. The vali-\n",
            "dation set is newstest2013, and the test set is new-\n",
            "stest2014. English-French We used the IWSLT corpus\n",
            "which contains 0.22M sentence pairs with 4.03M\n",
            "English words and 4.12M French words. The\n",
            "IWLST corpus is very dissimilar from the NIST\n",
            "and WMT corpora. As they are collected from\n",
            "TED talks and inclined to spoken language,\n",
            "we want to verify our approaches on the non-\n",
            "normative text. The IWSLT 14 test set is taken\n",
            "as the validation set and 15 test set is used as the\n",
            "test set. For English-German and English-French, we\n",
            "tokenize both English, German and French words\n",
            "using tokenize.perl script. We follow Sen-\n",
            "nrich et al. (2016b) to split words into sub-\n",
            "word units. The numbers of merge operations\n",
            "in byte pair encoding (BPE) are set to 30K,40K and 30K respectively for Chinese-English,\n",
            "English-German, and English-French. We re-\n",
            "port the case-sensitive tokenized BLEU score for\n",
            "English-German and English-French and the case-\n",
            "insensitive tokenized BLEU score for Chinese-\n",
            "English. Our baseline system is an in-house NMT sys-\n",
            "tem. Following Bahdanau et al. (2015), we im-\n",
            "plement an RNN-based NMT in which both the\n",
            "encoder and decoder are two-layer RNNs with\n",
            "residual connections between layers (He et al.,\n",
            "2016b). The gating mechanism of RNNs is gated\n",
            "recurrent unit (GRUs) (Cho et al., 2014). We\n",
            "apply layer normalization (Ba et al., 2016) and\n",
            "dropout (Hinton et al., 2012) to the hidden states\n",
            "of GRUs. Dropout is also added to the source and\n",
            "target word embeddings. We share the same ma-\n",
            "trix between the target word embeedings and the\n",
            "pre-softmax linear transformation (Vaswani et al.,\n",
            "2017). We update the set of model parameters us-\n",
            "ing Adam SGD (Kingma and Ba, 2015). Its learn-\n",
            "ing rate is initially set to 0:05and varies according\n",
            "to the formula in Vaswani et al. (2017). Our adversarial stability training initializes the\n",
            "model based on the parameters trained by maxi-\n",
            "mum likelihood estimation (MLE). We denote ad-\n",
            "versarial stability training based on lexical-level\n",
            "perturbations and feature-level perturbations re-\n",
            "spectively as AST lexical and AST feature . We only\n",
            "sample one perturbed neighbour x02N (x)for\n",
            "training efciency. For the discriminator used in\n",
            "Linv, we adopt the CNN discriminator proposed\n",
            "by Kim (2014) to address the variable-length prob-\n",
            "lem of the sequence generated by the encoder. In\n",
            "the CNN discriminator, the lter windows are set\n",
            "to 3, 4, 5 and rectied linear units are applied af-\n",
            "ter convolution operations. We tune the hyper-\n",
            "parameters on the validation set through a grid\n",
            "search. We nd that both the optimal values of\n",
            "\u000band\fare set to 1:0. The standard variance in\n",
            "Gaussian noise used in the formula (6) is set to\n",
            "0:01. The number of words that are replaced in\n",
            "the sentence xduring lexical-level perturbations is\n",
            "taken as max(0:2jxj;1)in whichjxjis the length\n",
            "ofx. The default beam size for decoding is 10. 4.2 Translation Results\n",
            "4.2.1 NIST Chinese-English Translation\n",
            "Table 2 shows the results on Chinese-English\n",
            "translation. Our strong baseline system signi-\n",
            "cantly outperforms previously reported results onSystem Training MT06 MT02 MT03 MT04 MT05 MT08\n",
            "Shen et al. (2016) MRT 37.34 40.36 40.93 41.37 38.81 29.23\n",
            "Wang et al. (2017) MLE 37.29  39.35 41.15 38.07 \n",
            "Zhang et al. (2018) MLE 38.38  40.02 42.32 38.84 \n",
            "this workMLE 41.38 43.52 41.50 43.64 41.58 31.60\n",
            "AST lexical 43.57 44.82 42.95 45.05 43.45 34.85\n",
            "AST feature 44.44 46.10 44.07 45.61 44.06 34.94\n",
            "Table 2: Case-insensitive BLEU scores on Chinese-English translation. System Architecture Training BLEU\n",
            "Shen et al. (2016) Gated RNN with 1 layer MRT 20.45\n",
            "Luong et al. (2015) LSTM with 4 layers MLE 20.90\n",
            "Kalchbrenner et al. (2017) ByteNet with 30 layers MLE 23.75\n",
            "Wang et al. (2017) DeepLAU with 4 layers MLE 23.80\n",
            "Wu et al. (2016) LSTM with 8 layers RL 24.60\n",
            "Gehring et al. (2017) CNN with 15 layers MLE 25.16\n",
            "Vaswani et al. (2017) Self-attention with 6 layers MLE 28.40\n",
            "this work Gated RNN with 2 layersMLE 24.06\n",
            "AST lexical 25.17\n",
            "AST feature 25.26\n",
            "Table 3: Case-sensitive BLEU scores on WMT 14 English-German translation. Training tst2014 tst2015\n",
            "MLE 36.92 36.90\n",
            "AST lexical 37.35 37.03\n",
            "AST feature 38.03 37.64\n",
            "Table 4: Case-sensitive BLEU scores on IWSLT\n",
            "English-French translation. Chinese-English NIST datasets trained on RNN-\n",
            "based NMT. Shen et al. (2016) propose minimum\n",
            "risk training (MRT) for NMT, which directly op-\n",
            "timizes model parameters with respect to BLEU\n",
            "scores. Wang et al. (2017) address the issue of\n",
            "severe gradient diffusion with linear associative\n",
            "units (LAU). Their system is deep with an encoder\n",
            "of 4 layers and a decoder of 4 layers. Zhang et al. (2018) propose to exploit both left-to-right and\n",
            "right-to-left decoding strategies for NMT to cap-\n",
            "ture bidirectional dependencies. Compared with\n",
            "them, our NMT system trained by MLE outper-\n",
            "forms their best models by around 3 BLEU points. We hope that the strong baseline systems used in\n",
            "this work make the evaluation convincing. We nd that introducing adversarial stability\n",
            "training into NMT can bring substantial improve-\n",
            "ments over previous work (up to +3:16BLEUpoints over Shen et al. (2016), up to +3:51\n",
            "BLEU points over Wang et al. (2017) and up to\n",
            "+2:74BLEU points over Zhang et al. (2018))\n",
            "and our system trained with MLE across all the\n",
            "datasets. Compared with our baseline system,\n",
            "AST lexical achieves +1:75BLEU improvement on\n",
            "average. AST feature performs better, which can\n",
            "obtain +2:59BLEU points on average and up to\n",
            "+3:34BLEU points on NIST08. 4.2.2 WMT 14 English-German Translation\n",
            "In Table 3, we list existing NMT systems as com-\n",
            "parisons. All these systems use the same WMT 14\n",
            "English-German corpus. Except that Shen et al. (2016) and Wu et al. (2016) respectively adopt\n",
            "MRT and reinforcement learning (RL), other sys-\n",
            "tems all use MLE as training criterion. All the sys-\n",
            "tems except for Shen et al. (2016) are deep NMT\n",
            "models with no less than four layers. Googles\n",
            "neural machine translation (GNMT) (Wu et al.,\n",
            "2016) represents a strong RNN-based NMT sys-\n",
            "tem. Compared with other RNN-based NMT sys-\n",
            "tems except for GNMT, our baseline system with\n",
            "two layers can achieve better performance than\n",
            "theirs. When training our NMT system with\n",
            "AST leixcal , signicant improvement ( +1:11Synthetic Type Training 0 Op. 1 Op. 2 Op. 3 Op. 4 Op. 5 Op. SwapMLE 41.38 38.86 37.23 35.97 34.61 32.96\n",
            "AST lexical 43.57 41.18 39.88 37.95 37.02 36.16\n",
            "AST feature 44.44 42.08 40.20 38.67 36.89 35.81\n",
            "ReplacementMLE 41.38 37.21 31.40 27.43 23.94 21.03\n",
            "AST lexical 43.57 40.53 37.59 35.19 32.56 30.42\n",
            "AST feature 44.44 40.04 35.00 30.54 27.42 24.57\n",
            "DeletionMLE 41.38 38.45 36.15 33.28 31.17 28.65\n",
            "AST lexical 43.57 41.89 38.56 36.14 34.09 31.77\n",
            "AST feature 44.44 41.75 39.06 36.16 33.49 30.90\n",
            "Table 5: Translation results of synthetic perturbations on the validation set in Chinese-English translation. 1 Op. denotes that we conduct one operation (swap, replacement or deletion) on the original sentence. Source zhongguo dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing\n",
            "Reference chinas new management rules for e-banking operations to take effect on march 1\n",
            "MLE chinas electronic bank rules to be implemented on march 1\n",
            "AST lexicalnew rules for business administration of china s electronic banking industry\n",
            "will come into effect on march 1 . AST featurenew rules for business management of china s electronic banking industry to\n",
            "come into effect on march 1\n",
            "Perturbed Source zhongfang dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing\n",
            "MLE china to implement new regulations on business management\n",
            "AST lexicalthe new regulations for the business administrations of the chinese electronics\n",
            "bank will come into effect on march 1 . AST featurenew rules for business management of chinas electronic banking industry to\n",
            "come into effect on march 1\n",
            "Table 6: Example translations of a source sentence and its perturbed counterpart by replacing a Chinese\n",
            "word zhongguo with its synonym zhongfang. BLEU points) can be observed. AST feature\n",
            "can obtain slightly better performance. Our\n",
            "NMT system outperforms the state-of-the-art\n",
            "RNN-based NMT system, GNMT, with +0:66\n",
            "BLEU point and performs comparably with\n",
            "Gehring et al. (2017) which is based on CNN\n",
            "with 15 layers. Given that our approach can be\n",
            "applied to any NMT systems, we expect that\n",
            "the adversarial stability training mechanism can\n",
            "further improve performance upon the advanced\n",
            "NMT architectures. We leave this for future work. 4.2.3 IWSLT English-French Translation\n",
            "Table 4 shows the results on IWSLT English-\n",
            "French Translation. Compared with our strong\n",
            "baseline system trained by MLE, we observe that\n",
            "our models consistently improve translation per-\n",
            "formance in all datasets. AST feature can achieve\n",
            "signicant improvements on the tst2015 although\n",
            "AST lexical obtains comparable results. Thesedemonstrate that our approach maintains good per-\n",
            "formance on the non-normative text. 4.3 Results on Synthetic Perturbed Data\n",
            "In order to investigate the ability of our training\n",
            "approaches to deal with perturbations, we experi-\n",
            "ment with three types of synthetic perturbations:\n",
            "Swap : We randomly choose Npositions\n",
            "from a sentence and then swap the chosen\n",
            "words with their right neighbours. Replacement : We randomly replace sam-\n",
            "pled words in the sentence with other words. Deletion : We randomly delete Nwords from\n",
            "each sentence in the dataset. As shown in Table 5, we can nd that our train-\n",
            "ing approaches, AST lexical and AST feature , consis-\n",
            "tently outperform MLE against perturbations on\n",
            "all the numbers of operations. This means that ourLtrueLnoisyLinv BLEUp\u0002 \u0002 41.38p\u0002p41.91\n",
            "\u0002p\u0002 42.20p p\u0002 42.93p p p43.57\n",
            "Table 7: Ablation study of adversarial stabil-\n",
            "ity training AST lexical on Chinese-English trans-\n",
            "lation. p means the loss function is included in\n",
            "the training objective while  \u0002 means it is not. approaches have the capability of resisting pertur-\n",
            "bations. Along with the number of operations in-\n",
            "creasing, the performance on MLE drops quickly. Although the performance of our approaches also\n",
            "drops, we can see that our approaches consistently\n",
            "surpass MLE. In AST lexical , with 0 operation, the\n",
            "difference is +2.19 (43.57 Vs. 41.38) for all syn-\n",
            "thetic types, but the differences are enlarged to\n",
            "+3.20, +9.39, and +3.12 respectively for the three\n",
            "types with 5 operations. In the Swap andDeletion types, AST lexical and\n",
            "AST feature perform comparably after more than\n",
            "four operations. Interestingly, AST lexical per-\n",
            "forms signicantly better than both of MLE and\n",
            "AST feature after more than one operation in the\n",
            "Replacement type. This is because AST lexical\n",
            "trains the model specically on perturbation data\n",
            "that is constructed by replacing words, which\n",
            "agrees with the Replacement Type. Overall,\n",
            "AST lexical performs better than AST feature against\n",
            "perturbations after multiple operations. We spec-\n",
            "ulate that the perturbation method for AST lexical\n",
            "and synthetic type are both discrete and they keep\n",
            "more consistent. Table 6 shows example transla-\n",
            "tions of a Chinese sentence and its perturbed coun-\n",
            "terpart. These ndings indicate that we can construct\n",
            "specic perturbations for a particular task. For\n",
            "example, in simultaneous translation, an auto-\n",
            "matic speech recognition system usually generates\n",
            "wrong words with the same pronunciation of cor-\n",
            "rect words, which dramatically affects the quality\n",
            "of machine translation system. Therefore, we can\n",
            "design specic perturbations aiming for this task. 4.4 Analysis\n",
            "4.4.1 Ablation Study\n",
            "Our training objective function Eq. (4) contains\n",
            "three loss functions. We perform an ablation\n",
            "Iterations0 20 40 60 80 100 120 140 160 180 200BLEU\n",
            "34363840424446\n",
            " 103ASTlexical\n",
            "ASTfeatureFigure 2: BLEU scores of AST lexical over itera-\n",
            "tions on Chinese-English validation set. Iterations0 50 100 150 200Cost\n",
            "0.511.522.533.544.55\n",
            " 103Lnoisy\n",
            "Ltrue\n",
            "Linv\n",
            "Figure 3: Learning curves of three loss functions,\n",
            "Ltrue,LinvandLnoisy over iterations on Chinese-\n",
            "English validation set. study on the Chinese-English translation to under-\n",
            "stand the importance of these loss functions by\n",
            "choosing AST lexical as an example. As Table 7\n",
            "shows, if we remove Ladv, the translation perfor-\n",
            "mance decreases by 0:64BLEU point. However,\n",
            "whenLnoisy is excluded from the training objec-\n",
            "tive function, it results in a signicant drop of 1:66\n",
            "BLEU point. Surprisingly, only using Lnoisy is\n",
            "able to lead to an increase of 0:88BLEU point. 4.4.2 BLEU Scores over Iterations\n",
            "Figure 2 shows the changes of BLEU scores\n",
            "over iterations respectively for AST lexical and\n",
            "AST feature . They behave nearly consistently. Ini-\n",
            "tialized by the model trained by MLE, their per-\n",
            "formance drops rapidly. Then it starts to go up\n",
            "quickly. Compared with the starting point, themaximal dropping points reach up to about 7:0\n",
            "BLEU points. Basically, the curves present the\n",
            "state of oscillation. We think that introducing\n",
            "random perturbations and adversarial learning can\n",
            "make the training not very stable like MLE. 4.4.3 Learning Curves of Loss Functions\n",
            "Figure 3 shows the learning curves of three loss\n",
            "functions,Ltrue,LinvandLnoisy. We can nd that\n",
            "their costs of loss functions decrease not steadily. Similar to the Figure 2, there still exist oscilla-\n",
            "tions in the learning curves although they do not\n",
            "change much sharply. We nd that Linvconverges\n",
            "to around 0:68after about 100Kiterations, which\n",
            "indicates that discriminator outputs probability 0:5\n",
            "for both positive and negative samples and it can-\n",
            "not distinguish them. Thus the behaviors of the\n",
            "encoder for xand its perturbed neighbour x0per-\n",
            "form nearly consistently. 5 Related Work\n",
            "Our work is inspired by two lines of research: (1)\n",
            "adversarial learning and (2) data augmentation. Adversarial Learning Generative Adversarial\n",
            "Network (GAN) (Goodfellow et al., 2014) and\n",
            "its related derivative have been widely applied\n",
            "in computer vision (Radford et al., 2015; Sali-\n",
            "mans et al., 2016) and natural language process-\n",
            "ing (Li et al., 2017; Yang et al., 2018). Previous\n",
            "work has constructed adversarial examples to at-\n",
            "tack trained networks and make networks resist\n",
            "them, which has proved to improve the robust-\n",
            "ness of networks (Goodfellow et al., 2015; Miy-\n",
            "ato et al., 2016; Zheng et al., 2016). Belinkov\n",
            "and Bisk (2018) introduce adversarial examples\n",
            "to training data for character-based NMT models. In contrast to theirs, adversarial stability training\n",
            "aims to stabilize both the encoder and decoder in\n",
            "NMT models. We adopt adversarial learning to\n",
            "learn the perturbation-invariant encoder. Data Augmentation Data augmentation has the\n",
            "capability to improve the robustness of NMT mod-\n",
            "els. In NMT, there is a number of work that aug-\n",
            "ments the training data with monolingual corpora\n",
            "(Sennrich et al., 2016a; Cheng et al., 2016; He\n",
            "et al., 2016a; Zhang and Zong, 2016). They all\n",
            "leverage complex models such as inverse NMT\n",
            "models to generate translation equivalents for\n",
            "monolingual corpora. Then they augment the par-\n",
            "allel corpora with these pseudo corpora to improveNMT models. Some authors have recently en-\n",
            "deavored to achieve zero-shot NMT through trans-\n",
            "ferring knowledge from bilingual corpora of other\n",
            "language pairs (Chen et al., 2017; Zheng et al.,\n",
            "2017; Cheng et al., 2017) or monolingual corpora\n",
            "(Lample et al., 2018; Artetxe et al., 2018). Our\n",
            "work signicantly differs from these work. We do\n",
            "not resort to any complicated models to generate\n",
            "perturbed data and do not depend on extra mono-\n",
            "lingual or bilingual corpora. The way we exploit\n",
            "is more convenient and easy to implement. We\n",
            "focus more on improving the robustness of NMT\n",
            "models. 6 Conclusion\n",
            "We have proposed adversarial stability training to\n",
            "improve the robustness of NMT models. The ba-\n",
            "sic idea is to train both the encoder and decoder\n",
            "robust to input perturbations by enabling them to\n",
            "behave similarly for the original input and its per-\n",
            "turbed counterpart. We propose two approaches\n",
            "to construct perturbed data to adversarially train\n",
            "the encoder and stabilize the decoder. Experi-\n",
            "ments on Chinese-English, English-German and\n",
            "English-French translation tasks show that the pro-\n",
            "posed approach can improve both the robustness\n",
            "and translation performance. As our training framework is not limited to spe-\n",
            "cic perturbation types, it is interesting to evalu-\n",
            "ate our approach in natural noise existing in prac-\n",
            "tical applications, such as homonym in the simul-\n",
            "taneous translation system. It is also necessary to\n",
            "further validate our approach on more advanced\n",
            "NMT architectures, such as CNN-based NMT\n",
            "(Gehring et al., 2017) and Transformer (Vaswani\n",
            "et al., 2017). Acknowledgments\n",
            "We thank the anonymous reviewers for their in-\n",
            "sightful comments and suggestions. We also thank\n",
            "Xiaoling Li for analyzing experimental results and\n",
            "providing valuable examples. Yang Liu is sup-\n",
            "ported by the National Key R&D Program of\n",
            "China (No. 2017YFB0202204), National Natural\n",
            "Science Foundation of China (No. 61761166008,\n",
            "No. 61522204), Beijing Advanced Innovation\n",
            "Center for Language Resources, and the NExT++\n",
            "project supported by the National Research Foun-\n",
            "dation, Prime Ministers Ofce, Singapore under\n",
            "its IRC@Singapore Funding Initiative. \n"
          ]
        }
      ],
      "source": [
        "# Evaluation of section summaries without LSA applied and the reference summary has been taken from ChatGPT\n",
        "\n",
        "from nltk.translate import meteor_score\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Define reference summaries for each section\n",
        "reference_summaries = {\n",
        "    'Abstract': \"introduces the challenge of input perturbations negatively affecting the intermediate representations and subsequently impacting the translation quality of Neural Machine Translation (NMT) models. The proposed solution in the paper is adversarial stability training, aimed at enhancing the robustness of NMT models. The core concept involves making both the encoder and decoder of NMT models resilient to input perturbations, ensuring similar behavior for both the original input and its perturbed counterpart. The experimental findings, conducted on Chinese-English, English-German, and English-French translation tasks, demonstrate that the proposed approaches not only outperform strong NMT systems but also enhance the overall robustness of NMT models.\",\n",
        "    '1 Introduction': \"the progress of Neural Machine Translation (NMT) models in learning representations through a unified neural network. Despite their success, the paper addresses the non-robustness of NMT models, showcasing a critical problem through an example where replacing a word with its synonym leads to significant translation errors. The analogy of the butterfly effect is used to illustrate how small input changes can cause drastic alterations in the output. An investigation involving synonym replacements in a test set demonstrates that 69.74% of translations are altered, and the BLEU score drops to 79.01, emphasizing the models' sensitivity to small input perturbations. This sensitivity limits the applicability of NMT models to tasks requiring robust performance on noisy inputs.\",\n",
        "    '2 Background': \"The provided text describes the standard Neural Machine Translation (NMT) framework, emphasizing its end-to-end nature that optimizes the translation probability from a source sentence (x) to a target sentence (y). The model includes an encoder, which converts the source sentence into hidden representations (Hx), and a decoder, generating target words based on these representations. The training objective involves minimizing the negative log-likelihood of the training corpus. However, due to the vulnerability of deep neural networks, small input perturbations significantly impact translation results. To address this, the paper proposes an adversarial stability training approach, aiming to enhance the robustness of encoder representations against noisy perturbations. The architecture involves a discriminator and perturbations to achieve this stability.\",\n",
        "    '3 Approach': \"The proposed approach focuses on maintaining consistent behaviors in the NMT model for both the source sentence (x) and its perturbed counterpart (x0). The encoder and decoder are trained to be perturbation-invariant, ensuring that small changes in input do not significantly affect the translation output. The architecture involves constructing perturbed sentences from the source sentence and introducing two additional objectives: Linv encourages the encoder to output similar representations for x and x0, while Lnoisy guides the decoder to generate output y given the noisy input x0. The training objective combines these objectives with the original translation task, promoting both stability and good translation performance.\",\n",
        "    '4 Experiments': \"The evaluation of adversarial stability training was conducted on translation tasks for various language pairs, with 4-gram BLEU scores reported. For Chinese-English, the LDC corpus with 1.25M sentence pairs was used, and the NIST datasets served as test sets. English-German utilized the WMT 14 corpus, and English-French employed the IWSLT corpus, collected from TED talks, to assess non-normative text. The baseline system was an in-house NMT model with a two-layer RNN architecture, GRU gating mechanism, layer normalization, and dropout. Adversarial stability training involved lexical-level and feature-level perturbations, denoted as ASTlexical and ASTfeature. \",\n",
        "    '5 Related Work': \"In the realm of adversarial learning, the influence of Generative Adversarial Networks (GAN) and its derivatives has been extensive in computer vision and natural language processing. While prior work has used adversarial examples to attack and defend networks, the proposed adversarial stability training distinctively aims to stabilize both the encoder and decoder in NMT models. This approach utilizes adversarial learning to achieve a perturbation-invariant encoder. In the context of data augmentation, numerous methods have sought to enhance the robustness of NMT models by augmenting training data with monolingual corpora.\",\n",
        "    '6 Conclusion': \"The proposed adversarial stability training aims to enhance the robustness of NMT models by training both the encoder and decoder to handle input perturbations consistently. Two approaches for constructing perturbed data are introduced to adversarially train the encoder and stabilize the decoder. Experimental results on Chinese-English, English-German, and English-French translation tasks demonstrate that the proposed approach effectively improves both robustness and translation performance. To broaden the applicability, further evaluations are suggested in the context of natural noise present in practical applications, such as homonyms in simultaneous translation systems.\"\n",
        "}\n",
        "def calculate_scores_for_section(reference, hypothesis):\n",
        "    reference_tokens = word_tokenize(reference)\n",
        "    hypothesis_tokens = word_tokenize(hypothesis)\n",
        "\n",
        "    smoothing_function = SmoothingFunction().method1  # Define smoothing function\n",
        "    bleu_score = sentence_bleu([reference_tokens], hypothesis_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "    meteor_score_value = meteor_score.meteor_score([reference_tokens], hypothesis_tokens)\n",
        "\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = scorer.score(reference, hypothesis)\n",
        "    rouge1 = rouge_scores['rouge1'].fmeasure\n",
        "    rouge2 = rouge_scores['rouge2'].fmeasure\n",
        "    rougel = rouge_scores['rougeL'].fmeasure\n",
        "\n",
        "    return bleu_score, meteor_score_value, rouge1, rouge2, rougel\n",
        "\n",
        "# Initialize generated summary with the content of each section in top-ranked sentences\n",
        "generated_summary = \"\"\n",
        "\n",
        "# Calculate scores for each section using top-ranked sentences\n",
        "bleu_scores_top_ranked = {}\n",
        "meteor_scores_top_ranked = {}\n",
        "rouge1_scores_top_ranked = {}\n",
        "rouge2_scores_top_ranked = {}\n",
        "rougel_scores_top_ranked = {}\n",
        "\n",
        "for section, top_sentences in section_sentences.items():\n",
        "    section_text = ' '.join(top_sentences)\n",
        "    generated_summary += section_text + \" \"  # Include the content of each section\n",
        "\n",
        "    # Use the corresponding reference summary for each section\n",
        "    reference_summary_for_section = reference_summaries[section]\n",
        "\n",
        "    bleu_score, meteor_score_val, rouge1, rouge2, rougel = calculate_scores_for_section(reference_summary_for_section, section_text)\n",
        "\n",
        "    bleu_scores_top_ranked[section] = bleu_score\n",
        "    meteor_scores_top_ranked[section] = meteor_score_val\n",
        "    rouge1_scores_top_ranked[section] = rouge1\n",
        "    rouge2_scores_top_ranked[section] = rouge2\n",
        "    rougel_scores_top_ranked[section] = rougel\n",
        "\n",
        "# Display scores for each section using top-ranked sentences\n",
        "for section in section_sentences.keys():\n",
        "    print(f\"Scores for Section '{section}' (Sections have the entire text in the generated summary):\")\n",
        "    print(\"BLEU Score:\", bleu_scores_top_ranked[section])\n",
        "    print(\"METEOR Score:\", meteor_scores_top_ranked[section])\n",
        "    print(\"ROUGE-1 F-measure:\", rouge1_scores_top_ranked[section])\n",
        "    print(\"ROUGE-2 F-measure:\", rouge2_scores_top_ranked[section])\n",
        "    print(\"ROUGE-L F-measure:\", rougel_scores_top_ranked[section])\n",
        "    print()\n",
        "\n",
        "# Display the generated summary\n",
        "print(\"\\nGenerated Summary with Content of Top-Ranked Sentences:\")\n",
        "print(generated_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4P6TKn96apD",
        "outputId": "075b11a0-a010-44e1-af76-3d77f656af62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scores for Section 'Abstract' (LSA has been applied on the generated summary):\n",
            "BLEU Score: 0.24033150402998318\n",
            "METEOR Score: 0.43259591601015546\n",
            "ROUGE-1 F-measure: 0.6232558139534884\n",
            "ROUGE-2 F-measure: 0.36619718309859156\n",
            "ROUGE-L F-measure: 0.40930232558139534\n",
            "\n",
            "Scores for Section '1 Introduction' (LSA has been applied on the generated summary):\n",
            "BLEU Score: 0.05328448880095941\n",
            "METEOR Score: 0.3161929322413354\n",
            "ROUGE-1 F-measure: 0.48484848484848486\n",
            "ROUGE-2 F-measure: 0.17557251908396948\n",
            "ROUGE-L F-measure: 0.19696969696969696\n",
            "\n",
            "Scores for Section '2 Background' (LSA has been applied on the generated summary):\n",
            "BLEU Score: 0.0911142939497208\n",
            "METEOR Score: 0.33127475792253525\n",
            "ROUGE-1 F-measure: 0.4285714285714286\n",
            "ROUGE-2 F-measure: 0.14388489208633093\n",
            "ROUGE-L F-measure: 0.2571428571428572\n",
            "\n",
            "Scores for Section '3 Approach' (LSA has been applied on the generated summary):\n",
            "BLEU Score: 0.013076745800729542\n",
            "METEOR Score: 0.13035241279131865\n",
            "ROUGE-1 F-measure: 0.23170731707317072\n",
            "ROUGE-2 F-measure: 0.07407407407407408\n",
            "ROUGE-L F-measure: 0.14634146341463417\n",
            "\n",
            "Scores for Section '4 Experiments' (LSA has been applied on the generated summary):\n",
            "BLEU Score: 0.0032177637100373334\n",
            "METEOR Score: 0.1160541586073501\n",
            "ROUGE-1 F-measure: 0.24242424242424243\n",
            "ROUGE-2 F-measure: 0.012269938650306749\n",
            "ROUGE-L F-measure: 0.10909090909090909\n",
            "\n",
            "Scores for Section '5 Related Work' (LSA has been applied on the generated summary):\n",
            "BLEU Score: 0.08224283113027914\n",
            "METEOR Score: 0.19859374999999999\n",
            "ROUGE-1 F-measure: 0.31707317073170727\n",
            "ROUGE-2 F-measure: 0.13580246913580246\n",
            "ROUGE-L F-measure: 0.20731707317073172\n",
            "\n",
            "Scores for Section '6 Conclusion' (LSA has been applied on the generated summary):\n",
            "BLEU Score: 0.14388958448110875\n",
            "METEOR Score: 0.3472362525458249\n",
            "ROUGE-1 F-measure: 0.4387755102040816\n",
            "ROUGE-2 F-measure: 0.19587628865979378\n",
            "ROUGE-L F-measure: 0.2755102040816326\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluation of LSA applied summaries with reference summary of ChatGPT\n",
        "\n",
        "# Define reference summaries for each section\n",
        "reference_summaries = {\n",
        "    'Abstract': \"introduces the challenge of input perturbations negatively affecting the intermediate representations and subsequently impacting the translation quality of Neural Machine Translation (NMT) models. The proposed solution in the paper is adversarial stability training, aimed at enhancing the robustness of NMT models. The core concept involves making both the encoder and decoder of NMT models resilient to input perturbations, ensuring similar behavior for both the original input and its perturbed counterpart. The experimental findings, conducted on Chinese-English, English-German, and English-French translation tasks, demonstrate that the proposed approaches not only outperform strong NMT systems but also enhance the overall robustness of NMT models.\",\n",
        "    '1 Introduction': \"the progress of Neural Machine Translation (NMT) models in learning representations through a unified neural network. Despite their success, the paper addresses the non-robustness of NMT models, showcasing a critical problem through an example where replacing a word with its synonym leads to significant translation errors. The analogy of the butterfly effect is used to illustrate how small input changes can cause drastic alterations in the output. An investigation involving synonym replacements in a test set demonstrates that 69.74% of translations are altered, and the BLEU score drops to 79.01, emphasizing the models' sensitivity to small input perturbations. This sensitivity limits the applicability of NMT models to tasks requiring robust performance on noisy inputs.\",\n",
        "    '2 Background': \"The provided text describes the standard Neural Machine Translation (NMT) framework, emphasizing its end-to-end nature that optimizes the translation probability from a source sentence (x) to a target sentence (y). The model includes an encoder, which converts the source sentence into hidden representations (Hx), and a decoder, generating target words based on these representations. The training objective involves minimizing the negative log-likelihood of the training corpus. However, due to the vulnerability of deep neural networks, small input perturbations significantly impact translation results. To address this, the paper proposes an adversarial stability training approach, aiming to enhance the robustness of encoder representations against noisy perturbations. The architecture involves a discriminator and perturbations to achieve this stability.\",\n",
        "    '3 Approach': \"The proposed approach focuses on maintaining consistent behaviors in the NMT model for both the source sentence (x) and its perturbed counterpart (x0). The encoder and decoder are trained to be perturbation-invariant, ensuring that small changes in input do not significantly affect the translation output. The architecture involves constructing perturbed sentences from the source sentence and introducing two additional objectives: Linv encourages the encoder to output similar representations for x and x0, while Lnoisy guides the decoder to generate output y given the noisy input x0. The training objective combines these objectives with the original translation task, promoting both stability and good translation performance.\",\n",
        "    '4 Experiments': \"The evaluation of adversarial stability training was conducted on translation tasks for various language pairs, with 4-gram BLEU scores reported. For Chinese-English, the LDC corpus with 1.25M sentence pairs was used, and the NIST datasets served as test sets. English-German utilized the WMT 14 corpus, and English-French employed the IWSLT corpus, collected from TED talks, to assess non-normative text. The baseline system was an in-house NMT model with a two-layer RNN architecture, GRU gating mechanism, layer normalization, and dropout. Adversarial stability training involved lexical-level and feature-level perturbations, denoted as ASTlexical and ASTfeature. \",\n",
        "    '5 Related Work': \"In the realm of adversarial learning, the influence of Generative Adversarial Networks (GAN) and its derivatives has been extensive in computer vision and natural language processing. While prior work has used adversarial examples to attack and defend networks, the proposed adversarial stability training distinctively aims to stabilize both the encoder and decoder in NMT models. This approach utilizes adversarial learning to achieve a perturbation-invariant encoder. In the context of data augmentation, numerous methods have sought to enhance the robustness of NMT models by augmenting training data with monolingual corpora.\",\n",
        "    '6 Conclusion': \"The proposed adversarial stability training aims to enhance the robustness of NMT models by training both the encoder and decoder to handle input perturbations consistently. Two approaches for constructing perturbed data are introduced to adversarially train the encoder and stabilize the decoder. Experimental results on Chinese-English, English-German, and English-French translation tasks demonstrate that the proposed approach effectively improves both robustness and translation performance. To broaden the applicability, further evaluations are suggested in the context of natural noise present in practical applications, such as homonyms in simultaneous translation systems.\"\n",
        "}\n",
        "\n",
        "# Function to calculate scores for a section\n",
        "def calculate_scores_for_section(reference, hypothesis):\n",
        "    reference_tokens = word_tokenize(reference)\n",
        "    hypothesis_tokens = word_tokenize(hypothesis)\n",
        "\n",
        "    smoothing_function = SmoothingFunction().method1  # Define smoothing function\n",
        "    bleu_score = sentence_bleu([reference_tokens], hypothesis_tokens, smoothing_function=smoothing_function)\n",
        "    meteor_score_val = meteor_score.meteor_score([reference_tokens], hypothesis_tokens)\n",
        "\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = scorer.score(reference, hypothesis)\n",
        "    rouge1 = rouge_scores['rouge1'].fmeasure\n",
        "    rouge2 = rouge_scores['rouge2'].fmeasure\n",
        "    rougel = rouge_scores['rougeL'].fmeasure\n",
        "\n",
        "    return bleu_score, meteor_score_val, rouge1, rouge2, rougel\n",
        "\n",
        "# Example text 2\n",
        "generated_summary = top_ranked_sentences  # Use top-ranked sentences directly\n",
        "\n",
        "# Calculate scores for each section using top-ranked sentences\n",
        "scores_top_ranked = {}\n",
        "\n",
        "for section, sentences in generated_summary.items():\n",
        "    section_text = ' '.join(sentences)\n",
        "\n",
        "    # Use the corresponding reference summary for each section\n",
        "    reference_summary_for_section = reference_summaries[section]\n",
        "\n",
        "    bleu_score, meteor_score_val, rouge1, rouge2, rougel = calculate_scores_for_section(reference_summary_for_section, section_text)\n",
        "\n",
        "    scores_top_ranked[section] = {\n",
        "        'BLEU Score': bleu_score,\n",
        "        'METEOR Score': meteor_score_val,\n",
        "        'ROUGE-1 F-measure': rouge1,\n",
        "        'ROUGE-2 F-measure': rouge2,\n",
        "        'ROUGE-L F-measure': rougel\n",
        "    }\n",
        "\n",
        "# Display scores for each section using top-ranked sentences\n",
        "for section, scores in scores_top_ranked.items():\n",
        "    print(f\"Scores for Section '{section}' (LSA has been applied on the generated summary):\")\n",
        "    for metric, value in scores.items():\n",
        "        print(f\"{metric}: {value}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fia88zb2Qk2K"
      },
      "source": [
        "##### GLOVE Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryvhPmMZSCsf",
        "outputId": "b1c9c055-7536-47e4-bb95-a77391a29a27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (8.2.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (2.5.3)\n",
            "Requirement already satisfied: jinja2 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (68.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy) (1.26.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: colorama in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
            "Collecting en-core-web-md==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
            "     ---------------------------------------- 0.0/42.8 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.1/42.8 MB 2.3 MB/s eta 0:00:19\n",
            "     ---------------------------------------- 0.3/42.8 MB 3.7 MB/s eta 0:00:12\n",
            "     ---------------------------------------- 0.4/42.8 MB 3.4 MB/s eta 0:00:13\n",
            "      --------------------------------------- 0.6/42.8 MB 3.5 MB/s eta 0:00:13\n",
            "      --------------------------------------- 0.7/42.8 MB 3.2 MB/s eta 0:00:14\n",
            "     - -------------------------------------- 1.4/42.8 MB 5.0 MB/s eta 0:00:09\n",
            "     - -------------------------------------- 1.5/42.8 MB 4.8 MB/s eta 0:00:09\n",
            "     - -------------------------------------- 1.7/42.8 MB 4.6 MB/s eta 0:00:09\n",
            "     - -------------------------------------- 2.1/42.8 MB 5.0 MB/s eta 0:00:09\n",
            "     -- ------------------------------------- 2.4/42.8 MB 5.1 MB/s eta 0:00:08\n",
            "     -- ------------------------------------- 2.4/42.8 MB 4.8 MB/s eta 0:00:09\n",
            "     -- ------------------------------------- 2.6/42.8 MB 4.4 MB/s eta 0:00:10\n",
            "     -- ------------------------------------- 2.8/42.8 MB 4.5 MB/s eta 0:00:09\n",
            "     -- ------------------------------------- 2.9/42.8 MB 4.3 MB/s eta 0:00:10\n",
            "     --- ------------------------------------ 3.3/42.8 MB 4.6 MB/s eta 0:00:09\n",
            "     --- ------------------------------------ 3.7/42.8 MB 4.7 MB/s eta 0:00:09\n",
            "     --- ------------------------------------ 3.8/42.8 MB 4.6 MB/s eta 0:00:09\n",
            "     --- ------------------------------------ 3.9/42.8 MB 4.4 MB/s eta 0:00:09\n",
            "     --- ------------------------------------ 4.2/42.8 MB 4.5 MB/s eta 0:00:09\n",
            "     ---- ----------------------------------- 4.3/42.8 MB 4.5 MB/s eta 0:00:09\n",
            "     ---- ----------------------------------- 4.7/42.8 MB 4.6 MB/s eta 0:00:09\n",
            "     ---- ----------------------------------- 4.9/42.8 MB 4.6 MB/s eta 0:00:09\n",
            "     ---- ----------------------------------- 5.2/42.8 MB 4.6 MB/s eta 0:00:09\n",
            "     ---- ----------------------------------- 5.2/42.8 MB 4.6 MB/s eta 0:00:09\n",
            "     ----- ---------------------------------- 5.5/42.8 MB 4.5 MB/s eta 0:00:09\n",
            "     ----- ---------------------------------- 5.5/42.8 MB 4.5 MB/s eta 0:00:09\n",
            "     ----- ---------------------------------- 5.9/42.8 MB 4.4 MB/s eta 0:00:09\n",
            "     ----- ---------------------------------- 6.3/42.8 MB 4.6 MB/s eta 0:00:09\n",
            "     ------ --------------------------------- 6.7/42.8 MB 4.7 MB/s eta 0:00:08\n",
            "     ------ --------------------------------- 7.1/42.8 MB 4.8 MB/s eta 0:00:08\n",
            "     ------ --------------------------------- 7.4/42.8 MB 4.8 MB/s eta 0:00:08\n",
            "     ------- -------------------------------- 7.9/42.8 MB 5.0 MB/s eta 0:00:07\n",
            "     ------- -------------------------------- 8.4/42.8 MB 5.1 MB/s eta 0:00:07\n",
            "     -------- ------------------------------- 8.8/42.8 MB 5.2 MB/s eta 0:00:07\n",
            "     -------- ------------------------------- 9.2/42.8 MB 5.3 MB/s eta 0:00:07\n",
            "     -------- ------------------------------- 9.6/42.8 MB 5.4 MB/s eta 0:00:07\n",
            "     --------- ------------------------------ 9.9/42.8 MB 5.4 MB/s eta 0:00:07\n",
            "     --------- ------------------------------ 10.4/42.8 MB 5.6 MB/s eta 0:00:06\n",
            "     ---------- ----------------------------- 10.7/42.8 MB 5.8 MB/s eta 0:00:06\n",
            "     ---------- ----------------------------- 11.0/42.8 MB 5.9 MB/s eta 0:00:06\n",
            "     ---------- ----------------------------- 11.4/42.8 MB 5.7 MB/s eta 0:00:06\n",
            "     ---------- ----------------------------- 11.7/42.8 MB 5.8 MB/s eta 0:00:06\n",
            "     ----------- ---------------------------- 12.1/42.8 MB 6.1 MB/s eta 0:00:06\n",
            "     ----------- ---------------------------- 12.5/42.8 MB 6.0 MB/s eta 0:00:06\n",
            "     ------------ --------------------------- 12.9/42.8 MB 6.4 MB/s eta 0:00:05\n",
            "     ------------ --------------------------- 13.3/42.8 MB 6.5 MB/s eta 0:00:05\n",
            "     ------------ --------------------------- 13.6/42.8 MB 6.5 MB/s eta 0:00:05\n",
            "     ------------- -------------------------- 14.0/42.8 MB 6.6 MB/s eta 0:00:05\n",
            "     ------------- -------------------------- 14.1/42.8 MB 6.7 MB/s eta 0:00:05\n",
            "     ------------- -------------------------- 14.4/42.8 MB 6.5 MB/s eta 0:00:05\n",
            "     ------------- -------------------------- 14.8/42.8 MB 6.7 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 15.1/42.8 MB 6.8 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 15.5/42.8 MB 7.2 MB/s eta 0:00:04\n",
            "     -------------- ------------------------- 15.8/42.8 MB 7.4 MB/s eta 0:00:04\n",
            "     --------------- ------------------------ 16.2/42.8 MB 7.4 MB/s eta 0:00:04\n",
            "     --------------- ------------------------ 16.4/42.8 MB 7.3 MB/s eta 0:00:04\n",
            "     --------------- ------------------------ 16.8/42.8 MB 7.2 MB/s eta 0:00:04\n",
            "     --------------- ------------------------ 17.0/42.8 MB 7.0 MB/s eta 0:00:04\n",
            "     ---------------- ----------------------- 17.4/42.8 MB 7.1 MB/s eta 0:00:04\n",
            "     ---------------- ----------------------- 17.7/42.8 MB 7.0 MB/s eta 0:00:04\n",
            "     ---------------- ----------------------- 18.0/42.8 MB 7.0 MB/s eta 0:00:04\n",
            "     ----------------- ---------------------- 18.3/42.8 MB 6.8 MB/s eta 0:00:04\n",
            "     ----------------- ---------------------- 18.6/42.8 MB 6.8 MB/s eta 0:00:04\n",
            "     ----------------- ---------------------- 18.9/42.8 MB 6.7 MB/s eta 0:00:04\n",
            "     ----------------- ---------------------- 19.2/42.8 MB 6.5 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 19.4/42.8 MB 6.5 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 19.5/42.8 MB 6.4 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 19.7/42.8 MB 6.3 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 19.9/42.8 MB 6.2 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 20.0/42.8 MB 6.1 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 20.0/42.8 MB 5.9 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 20.2/42.8 MB 5.7 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 20.3/42.8 MB 5.7 MB/s eta 0:00:04\n",
            "     ------------------- -------------------- 20.3/42.8 MB 5.7 MB/s eta 0:00:04\n",
            "     ------------------- -------------------- 20.3/42.8 MB 5.7 MB/s eta 0:00:04\n",
            "     ------------------- -------------------- 20.6/42.8 MB 5.3 MB/s eta 0:00:05\n",
            "     ------------------- -------------------- 20.7/42.8 MB 5.3 MB/s eta 0:00:05\n",
            "     ------------------- -------------------- 20.8/42.8 MB 5.2 MB/s eta 0:00:05\n",
            "     ------------------- -------------------- 20.9/42.8 MB 5.0 MB/s eta 0:00:05\n",
            "     ------------------- -------------------- 21.0/42.8 MB 5.0 MB/s eta 0:00:05\n",
            "     ------------------- -------------------- 21.1/42.8 MB 4.9 MB/s eta 0:00:05\n",
            "     ------------------- -------------------- 21.3/42.8 MB 4.8 MB/s eta 0:00:05\n",
            "     -------------------- ------------------- 21.5/42.8 MB 4.8 MB/s eta 0:00:05\n",
            "     -------------------- ------------------- 21.7/42.8 MB 4.7 MB/s eta 0:00:05\n",
            "     -------------------- ------------------- 21.9/42.8 MB 4.7 MB/s eta 0:00:05\n",
            "     -------------------- ------------------- 22.1/42.8 MB 4.7 MB/s eta 0:00:05\n",
            "     -------------------- ------------------- 22.3/42.8 MB 4.6 MB/s eta 0:00:05\n",
            "     --------------------- ------------------ 22.5/42.8 MB 4.6 MB/s eta 0:00:05\n",
            "     --------------------- ------------------ 22.8/42.8 MB 4.5 MB/s eta 0:00:05\n",
            "     --------------------- ------------------ 23.0/42.8 MB 4.5 MB/s eta 0:00:05\n",
            "     --------------------- ------------------ 23.2/42.8 MB 4.5 MB/s eta 0:00:05\n",
            "     --------------------- ------------------ 23.4/42.8 MB 4.4 MB/s eta 0:00:05\n",
            "     ---------------------- ----------------- 23.7/42.8 MB 4.4 MB/s eta 0:00:05\n",
            "     ---------------------- ----------------- 24.0/42.8 MB 4.4 MB/s eta 0:00:05\n",
            "     ---------------------- ----------------- 24.2/42.8 MB 4.4 MB/s eta 0:00:05\n",
            "     ---------------------- ----------------- 24.5/42.8 MB 4.4 MB/s eta 0:00:05\n",
            "     ----------------------- ---------------- 24.7/42.8 MB 4.4 MB/s eta 0:00:05\n",
            "     ----------------------- ---------------- 24.9/42.8 MB 4.4 MB/s eta 0:00:05\n",
            "     ----------------------- ---------------- 25.1/42.8 MB 4.4 MB/s eta 0:00:05\n",
            "     ----------------------- ---------------- 25.3/42.8 MB 4.3 MB/s eta 0:00:05\n",
            "     ----------------------- ---------------- 25.5/42.8 MB 4.3 MB/s eta 0:00:05\n",
            "     ------------------------ --------------- 25.7/42.8 MB 4.2 MB/s eta 0:00:05\n",
            "     ------------------------ --------------- 25.9/42.8 MB 4.2 MB/s eta 0:00:04\n",
            "     ------------------------ --------------- 26.1/42.8 MB 4.2 MB/s eta 0:00:04\n",
            "     ------------------------ --------------- 26.3/42.8 MB 4.1 MB/s eta 0:00:04\n",
            "     ------------------------ --------------- 26.5/42.8 MB 4.1 MB/s eta 0:00:04\n",
            "     ------------------------ --------------- 26.7/42.8 MB 4.1 MB/s eta 0:00:04\n",
            "     ------------------------- -------------- 26.9/42.8 MB 4.1 MB/s eta 0:00:04\n",
            "     ------------------------- -------------- 27.1/42.8 MB 4.0 MB/s eta 0:00:04\n",
            "     ------------------------- -------------- 27.4/42.8 MB 4.0 MB/s eta 0:00:04\n",
            "     ------------------------- -------------- 27.6/42.8 MB 4.0 MB/s eta 0:00:04\n",
            "     -------------------------- ------------- 27.8/42.8 MB 3.9 MB/s eta 0:00:04\n",
            "     -------------------------- ------------- 28.0/42.8 MB 4.0 MB/s eta 0:00:04\n",
            "     -------------------------- ------------- 28.2/42.8 MB 4.0 MB/s eta 0:00:04\n",
            "     -------------------------- ------------- 28.4/42.8 MB 3.9 MB/s eta 0:00:04\n",
            "     -------------------------- ------------- 28.6/42.8 MB 3.9 MB/s eta 0:00:04\n",
            "     -------------------------- ------------- 28.8/42.8 MB 3.8 MB/s eta 0:00:04\n",
            "     --------------------------- ------------ 29.0/42.8 MB 3.9 MB/s eta 0:00:04\n",
            "     --------------------------- ------------ 29.2/42.8 MB 3.8 MB/s eta 0:00:04\n",
            "     --------------------------- ------------ 29.4/42.8 MB 3.8 MB/s eta 0:00:04\n",
            "     --------------------------- ------------ 29.7/42.8 MB 3.9 MB/s eta 0:00:04\n",
            "     --------------------------- ------------ 29.9/42.8 MB 3.9 MB/s eta 0:00:04\n",
            "     ---------------------------- ----------- 30.1/42.8 MB 3.9 MB/s eta 0:00:04\n",
            "     ---------------------------- ----------- 30.3/42.8 MB 4.0 MB/s eta 0:00:04\n",
            "     ---------------------------- ----------- 30.5/42.8 MB 3.9 MB/s eta 0:00:04\n",
            "     ---------------------------- ----------- 30.7/42.8 MB 4.1 MB/s eta 0:00:03\n",
            "     ---------------------------- ----------- 30.9/42.8 MB 4.2 MB/s eta 0:00:03\n",
            "     ----------------------------- ---------- 31.2/42.8 MB 4.3 MB/s eta 0:00:03\n",
            "     ----------------------------- ---------- 31.4/42.8 MB 4.4 MB/s eta 0:00:03\n",
            "     ----------------------------- ---------- 31.6/42.8 MB 4.5 MB/s eta 0:00:03\n",
            "     ----------------------------- ---------- 31.8/42.8 MB 4.4 MB/s eta 0:00:03\n",
            "     ----------------------------- ---------- 32.0/42.8 MB 4.4 MB/s eta 0:00:03\n",
            "     ----------------------------- ---------- 32.0/42.8 MB 4.5 MB/s eta 0:00:03\n",
            "     ------------------------------ --------- 32.3/42.8 MB 4.4 MB/s eta 0:00:03\n",
            "     ------------------------------ --------- 32.6/42.8 MB 4.4 MB/s eta 0:00:03\n",
            "     ------------------------------ --------- 33.0/42.8 MB 4.4 MB/s eta 0:00:03\n",
            "     ------------------------------- -------- 33.2/42.8 MB 4.4 MB/s eta 0:00:03\n",
            "     ------------------------------- -------- 33.5/42.8 MB 4.4 MB/s eta 0:00:03\n",
            "     ------------------------------- -------- 33.7/42.8 MB 4.5 MB/s eta 0:00:03\n",
            "     ------------------------------- -------- 34.0/42.8 MB 4.5 MB/s eta 0:00:02\n",
            "     -------------------------------- ------- 34.3/42.8 MB 4.4 MB/s eta 0:00:02\n",
            "     -------------------------------- ------- 34.5/42.8 MB 4.5 MB/s eta 0:00:02\n",
            "     -------------------------------- ------- 34.8/42.8 MB 4.4 MB/s eta 0:00:02\n",
            "     -------------------------------- ------- 35.1/42.8 MB 4.5 MB/s eta 0:00:02\n",
            "     --------------------------------- ------ 35.4/42.8 MB 4.5 MB/s eta 0:00:02\n",
            "     --------------------------------- ------ 35.7/42.8 MB 4.5 MB/s eta 0:00:02\n",
            "     --------------------------------- ------ 36.0/42.8 MB 4.5 MB/s eta 0:00:02\n",
            "     --------------------------------- ------ 36.3/42.8 MB 4.5 MB/s eta 0:00:02\n",
            "     ---------------------------------- ----- 36.6/42.8 MB 4.6 MB/s eta 0:00:02\n",
            "     ---------------------------------- ----- 36.6/42.8 MB 4.6 MB/s eta 0:00:02\n",
            "     ---------------------------------- ----- 36.6/42.8 MB 4.6 MB/s eta 0:00:02\n",
            "     ---------------------------------- ----- 37.4/42.8 MB 4.6 MB/s eta 0:00:02\n",
            "     ----------------------------------- ---- 37.6/42.8 MB 4.7 MB/s eta 0:00:02\n",
            "     ----------------------------------- ---- 37.8/42.8 MB 4.8 MB/s eta 0:00:02\n",
            "     ----------------------------------- ---- 38.1/42.8 MB 4.7 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 38.3/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 38.6/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 38.8/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 39.0/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 39.2/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 39.4/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 39.6/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 39.8/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 40.0/42.8 MB 4.9 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 40.2/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 40.4/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 40.6/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 40.8/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 41.0/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 41.3/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 41.5/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 41.7/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  41.9/42.8 MB 4.7 MB/s eta 0:00:01\n",
            "     ---------------------------------------  42.1/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  42.4/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  42.5/42.8 MB 4.9 MB/s eta 0:00:01\n",
            "     ---------------------------------------  42.8/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  42.8/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  42.8/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  42.8/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  42.8/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  42.8/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  42.8/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  42.8/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  42.8/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  42.8/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  42.8/42.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 42.8/42.8 MB 3.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from en-core-web-md==3.7.1) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.5.3)\n",
            "Requirement already satisfied: jinja2 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (68.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.14.6)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: colorama in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.4.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in d:\\msc. ai (7th - 8th term)\\dissertation\\code\\lsa\\denv\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ],
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RenomK72SFRn"
      },
      "source": [
        "### Similarity scores using GLOVE embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN3bmYub-_wr",
        "outputId": "75161351-e8e9-478d-a172-3cc0740144ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity score with Section with entire text and Glove 'Abstract': 0.8609182238578796\n",
            "Similarity score with Section with entire text and Glove '1 Introduction': 0.8844263553619385\n",
            "Similarity score with Section with entire text and Glove '2 Background': 0.8665162920951843\n",
            "Similarity score with Section with entire text and Glove '3 Approach': 0.8512067794799805\n",
            "Similarity score with Section with entire text and Glove '4 Experiments': 0.870236873626709\n",
            "Similarity score with Section with entire text and Glove '5 Related Work': 0.8806079030036926\n",
            "Similarity score with Section with entire text and Glove '6 Conclusion': 0.8750537633895874\n"
          ]
        }
      ],
      "source": [
        "# Using Glove for sections with entire text( Query is being matched with the sections but the sections have all the text)\n",
        "\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the pre-trained model with GloVe vectors\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "def text_similarity_with_glove(text1, text2):\n",
        "    # Ensure that the input is a string\n",
        "    text1 = str(text1)\n",
        "    text2 = str(text2)\n",
        "\n",
        "    # Tokenize and lemmatize the texts, applying lowercasing to individual words\n",
        "    tokens1 = [word.lower() for word in sent_tokenize(text1)]\n",
        "    tokens2 = [word.lower() for word in sent_tokenize(text2)]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens1 = [lemmatizer.lemmatize(token) for token in tokens1]\n",
        "    tokens2 = [lemmatizer.lemmatize(token) for token in tokens2]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = stopwords.words('english')\n",
        "    tokens1 = [token for token in tokens1 if token not in stop_words]\n",
        "    tokens2 = [token for token in tokens2 if token not in stop_words]\n",
        "\n",
        "    # Join tokens into strings\n",
        "    text1_processed = ' '.join(tokens1)\n",
        "    text2_processed = ' '.join(tokens2)\n",
        "\n",
        "    # Use spacy to get GloVe vectors for the processed texts\n",
        "    vector1 = nlp(text1_processed).vector\n",
        "    vector2 = nlp(text2_processed).vector\n",
        "\n",
        "    # Calculate the cosine similarity\n",
        "    similarity = cosine_similarity([vector1], [vector2])[0][0]\n",
        "\n",
        "    return similarity\n",
        "\n",
        "# Example usage:\n",
        "text2 = 'Neural Machine Translation; Attention Mechanism, Language Translation.'\n",
        "\n",
        "# Calculate similarity with each section header\n",
        "similarity_scores_glove = {}\n",
        "for section in sections:\n",
        "    similarity_score = text_similarity_with_glove(section_extraction[sections.index(section)], text2)\n",
        "    similarity_scores_glove[section] = similarity_score\n",
        "\n",
        "# Display similarity scores\n",
        "for section, score in similarity_scores_glove.items():\n",
        "    print(f\"Similarity score with Section with entire text and Glove '{section}': {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng9RXHTAsGCb",
        "outputId": "d738335a-fd9d-4e7d-cb09-add276e88673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity score with Section using LSA and Glove 'Abstract': 0.5400400757789612\n",
            "Similarity score with Section using LSA and Glove '1 Introduction': 0.24933794140815735\n",
            "Similarity score with Section using LSA and Glove '2 Background': 0.20433813333511353\n",
            "Similarity score with Section using LSA and Glove '3 Approach': 0.2322176843881607\n",
            "Similarity score with Section using LSA and Glove '4 Experiments': 0.2505641579627991\n",
            "Similarity score with Section using LSA and Glove '5 Related Work': 0.42708203196525574\n",
            "Similarity score with Section using LSA and Glove '6 Conclusion': 0.1734970659017563\n"
          ]
        }
      ],
      "source": [
        "# Using Glove with only top ranked sentences(Matching the query to the sections and LSA has been applied)\n",
        "\n",
        "# Load the pre-trained model with GloVe vectors\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "def text_similarity_with_glove(text1, text2):\n",
        "    # Ensure that the input is a string\n",
        "    text1 = str(text1)\n",
        "    text2 = str(text2)\n",
        "\n",
        "    # Tokenize and lemmatize the texts, applying lowercasing to individual words\n",
        "    tokens1 = [word.lower() for word in sent_tokenize(text1)]\n",
        "    tokens2 = [word.lower() for word in sent_tokenize(text2)]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens1 = [lemmatizer.lemmatize(token) for token in tokens1]\n",
        "    tokens2 = [lemmatizer.lemmatize(token) for token in tokens2]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = stopwords.words('english')\n",
        "    tokens1 = [token for token in tokens1 if token not in stop_words]\n",
        "    tokens2 = [token for token in tokens2 if token not in stop_words]\n",
        "\n",
        "    # Join tokens into strings\n",
        "    text1_processed = ' '.join(tokens1)\n",
        "    text2_processed = ' '.join(tokens2)\n",
        "\n",
        "    # Use spacy to get GloVe vectors for the processed texts\n",
        "    vector1 = nlp(text1_processed).vector\n",
        "    vector2 = nlp(text2_processed).vector\n",
        "\n",
        "    # Calculate the cosine similarity\n",
        "    similarity = cosine_similarity([vector1], [vector2])[0][0]\n",
        "\n",
        "    return similarity\n",
        "\n",
        "# Example usage:\n",
        "text2 = 'Neural Machine Translation; Attention Mechanism, Language Translation.'\n",
        "\n",
        "# Calculate similarity with each section header\n",
        "similarity_scores_glove = {}\n",
        "for section, top_sentence in zip(sections, top_ranked_sentences):\n",
        "    similarity_score = text_similarity_with_glove(top_sentence, text2)\n",
        "    similarity_scores_glove[section] = similarity_score\n",
        "\n",
        "# Display similarity scores\n",
        "for section, score in similarity_scores_glove.items():\n",
        "    print(f\"Similarity score with Section using LSA and Glove '{section}': {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRadm7dqQrNa"
      },
      "source": [
        "### Measuring Similarity Scores of user query with Title of pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8GPC2WcQwiY"
      },
      "source": [
        "##### GLOVE embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLMrbHNkAlfC",
        "outputId": "a18aabb1-e168-4c2f-d90a-7759707d4510"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity score with Title 'towards robust neural machine translation yong cheng zhaopeng tu fandong meng junjie zhai yang liuy' using GloVe: 0.4928518715080658\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy model with GloVe vectors\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Your text2\n",
        "text2 = 'Neural Machine Translation; Attention Mechanism, Language Translation.'\n",
        "\n",
        "# Function to calculate similarity score between title and text2 using GloVe vectors\n",
        "def glove_similarity(title, text2):\n",
        "    # Ensure that the input is a string\n",
        "    title = str(title)\n",
        "    text2 = str(text2)\n",
        "\n",
        "    # Process the texts using spaCy\n",
        "    doc_title = nlp(title)\n",
        "    doc_text2 = nlp(text2)\n",
        "\n",
        "    # Calculate the similarity between doc_title and doc_text2\n",
        "    similarity = doc_title.similarity(doc_text2)\n",
        "\n",
        "    return similarity\n",
        "\n",
        "# Calculate similarity between clean_title and text2\n",
        "similarity_score = glove_similarity(clean_title, text2)\n",
        "\n",
        "# Display similarity score\n",
        "print(f\"Similarity score with Title '{clean_title}' using GloVe: {similarity_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asu7TXm9QzUZ"
      },
      "source": [
        "##### TF-IDF embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg0RcgxmE3Q7",
        "outputId": "ef26af91-32c8-4d7d-c3fc-27c0bc49d44d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity score with Title 'towards robust neural machine translation yong cheng zhaopeng tu fandong meng junjie zhai yang liuy' using TF-IDF: 0.421637021355784\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import spacy\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Your text2\n",
        "text2 = 'Neural Machine Translation; Attention Mechanism, Language Translation.'\n",
        "\n",
        "# Function to calculate similarity score between title and text2 using TF-IDF\n",
        "def tfidf_similarity(title, text2):\n",
        "    # Ensure that the input is a string\n",
        "    title = str(title)\n",
        "    text2 = str(text2)\n",
        "\n",
        "    # Process the texts using spaCy\n",
        "    doc_title = nlp(title)\n",
        "    doc_text2 = nlp(text2)\n",
        "\n",
        "    # Create the TF-IDF vectors\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vector_title = vectorizer.fit_transform([title])\n",
        "    vector_text2 = vectorizer.transform([text2])\n",
        "\n",
        "    # Calculate the cosine similarity\n",
        "    similarity = cosine_similarity(vector_title, vector_text2)[0][0]\n",
        "\n",
        "    return similarity\n",
        "\n",
        "# Calculate similarity between clean_title and text2 using TF-IDF\n",
        "similarity_score_tfidf = tfidf_similarity(clean_title, text2)\n",
        "\n",
        "# Display similarity score\n",
        "print(f\"Similarity score with Title '{clean_title}' using TF-IDF: {similarity_score_tfidf}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uMfO_y-Sxju"
      },
      "source": [
        "### Using BART for Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715,
          "referenced_widgets": [
            "53a2c605aa6c48d9a477640d8ab6a626",
            "9c5baf9354404c5797ea71382dd6dd9e",
            "234432e1ecde44b6896e79f59b131212",
            "e927c13aa3f3435b99246d971b9eb991",
            "e4cae05ffe9c40af91e0355ca9270144",
            "001fbb24fb174287a626b59746db20a8",
            "9c5f66606e914a438b83021c9d92e528",
            "18d0ac2e72834627a029b72014658dff",
            "ba1a3da3d58448329ae51cf22bdec942",
            "7c62e52a054c45138e2367760436292f",
            "b4ade3c36eec40ac8f2e561dd49f782e",
            "13c8700811ac4085b4b4bc0a6e2d1fdc",
            "f88ca7783c0e4cf1b8c48416954be9fa",
            "503ad6c38a36404187e603bb7c19f09a",
            "d24312bd58cd46f8bd67dcad7f7c0abf",
            "78f738debafb41e187df36fb0c0dd95d",
            "cd4dc2877e6b4476933f30a9c85dd505",
            "79f7cf49f34f43e0ba5d34c24e16eb79",
            "f3d7fb2ae6d5443c8ce9fdd86efa9dc5",
            "ab010386bdbc49d390b6c6f38748ecf9",
            "928fd9a7d22343868a3e4d7ac1894b3d",
            "bd184e8978ff4e478dbc55b7913db520",
            "084d950233944c23969c6149d0ba3339",
            "b732b5efa06c40919ec56e32615001dd",
            "3d7504dd6bc84023bf4146d2ef9dd943",
            "f6c970d581f64eb384314aea681e7fab",
            "16fc798327944ed48a61a92abe428cfb",
            "54f7ddaf3bfc4167ad9f79e9532c97d9",
            "33bea5a6f1d8476fbadd9a31c3c19b28",
            "f3c815cec1c746d99ba87b4301b28533",
            "e6d3087d159c47e091c84b68f8445909",
            "7b142f541b674f39943fdb608eb6b609",
            "39b237685f0349c793aa174031b713e5",
            "3dcec7100df8494f86b40ae9a0c9c5be",
            "a240eee2bb2247e28fb277c3a21d6d94",
            "3b66b37c69a34bad88b1883b7c427c5c",
            "eb79129176a04e588a91d6af832dc102",
            "c61875b24178469da8f5d981e40757f6",
            "1925738060e143b59d6fe2fe410180d6",
            "a8410f78c7dd430c9ab5492474dd484e",
            "ca864117c4954faf810cb7dcd46f6ef8",
            "25f6229d98da414b823619208c126971",
            "9e8f07b07ff1446a9870b495e53bc5d5",
            "e3122766de1040108c7ec4d21fa1b4e7",
            "8daabe287199404d8312c4a4a16ab776",
            "8f71244c651c4845b6097977ef57ae7a",
            "7be6b2658dda4252b5736fa498de47c1",
            "0a0838f5f5074777ab8aa36090b3c4b7",
            "bb4dbb1612a34e078da04d9f6bc30499",
            "5f6eabe89e2b4644abdb802cc0586344",
            "b0e4082b87924dbd95ac77971cc1c469",
            "bf993f82b629477eb717c69578269dc9",
            "271215ea98e14dbd87dda26c91c80570",
            "a6955e5406d54c428d924b7ee11e9fa6",
            "9d8408c03a17455a853f8260df5262d8",
            "886bc3ebb2db481b82a47a18e3e665f0",
            "0e71d683940046a98f708eb322b27c17",
            "6f79848242864262ab5327db8e225ca5",
            "8cbbe888ba9149a7b1f63c151d72b221",
            "63a5e3ff7c0841afb02c1adaf939f021",
            "50d2845af39d453cab95402dcd29a320",
            "ae25132809e8489cb0023a85d70b51db",
            "95f08c1da9d541978379c85a79fcf787",
            "5b540e3b6d3f404392c6666206c73fff",
            "5572a83ddb46419288be031db81905a0",
            "553a9003a69b4d109ef45320eb42ade8"
          ]
        },
        "id": "Gr-sn1WkU7s7",
        "outputId": "23c6d972-8b68-4071-801c-21cb1a6d199e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\MSc. AI (7th - 8th term)\\Dissertation\\code\\LSA\\denv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary for Abstract:\n",
            "Small perturbations in the input canseverely distort intermediate representa-tions and thus impact translation quality. We propose to improve the robustness of NMT models with adver-                sarial stability training. The basic idea is to make both the encoder and decoder in                NMT models robust against input pertur-                bations by enabling them to behave sim-                ilarly for the original input and its per-                turbed counterpart. We present our results on Chinese-English, English-German and English-French translation tasks in the next issue of the Journal of Machine Translation (JMT) (http://www.jtimes.com/2013/01/29/science-translating-tasks-in-chinese-English-German-and-french.html#storylink=cpy. Back to the page you came from. Click here to read the rest of the article. The first part of this article was published in the journal of JMT (January 2013).\n",
            "\n",
            "Summary for 1 Introduction:\n",
            "Neural machine translation (NMT) models haveadvanced the state of the art by building a sin-ophobicgle neural network. Adversarial stability training has the following advantages: improving robustness and translating performance. We observe that 69:74% of transla-estyletions have changed and the BLEU score is only 79:01. This suggests that NMT models are very sensitive to small perturbations in the input. We conclude that adversarial stabilitytraining is capable of not only improving therobustness of N MT models but also achiev-ing better translation performance. The next step is to develop a more robust version of the adversarial Stability Training (AST) tool. We will share our findings with the public in an open-source version of our AST tool, which we hope will be available in the next few months. For more information, please visit the AST website or contact us by emailing jennifer.smith@mailonline.co.uk\n",
            "\n",
            "Summary for 2 Background:\n",
            "NMT is an end-to-end framework which directlyoptimizes the translation probability of a target sentence. NMT models usually suffer from a drawback: small perturbations in the input can deteriorate its translation results. Inspired by this, in this work, we show the robustness of encoder representations against noisy perturbation with adversarial learn-                ing (Goodfellow et al., 2014).xx+perturbations+EncoderHxHxDecoderDecoderDiscriminatorLinv(x, x, y)Lnoisy(x and y)Figure 1: The architecture of NMT with adversar-outheastern stability training. Figure 2: NMT model with noisy input sentence x0, which is transformed from x by adding small perturations. The dark solid arrow lines represent the forward-pass information for the input sentence. The red dashed arrow lines for the noisy input sentences x0 and x1, which are translated from x0 to x1.\n",
            "\n",
            "Summary for 3 Approach:\n",
            "The training objective in-cludes three sets of model parameters for three modules. The encoder is responsible for encoding xas a se-quence of representations Hx, while the decoderoutputs ywithHxas input. We introduce two additional objectives to improve the robustness of the encoder and decoder:Linv(x;x0)to encourage theencoder to out-put similar intermediate representations HXandHx0forx andx0. To achieve an invariantencoder, which benets outputting the same translate-able, we use Professor Lamb et al.’s ‘Forcing’ technique. We will describe how to construct perturbed inputs with different goals to fulll different goals (Section 3.2), following by the proposed adversarial learning Mechanism for the perturbation-invariant encoder ( section 3.3). As aforementioned, the NMT model contains two procedures for project-phthaling a source sentence xto its target sentence y.\n",
            "\n",
            "Summary for 4 Experiments:\n",
            "BLEU scores of AST lexical over itera-tions on Chinese-English validation set. Cost 0.511.522.544.55 103LnoisyLtrue,LinvandL noisy over iterations. Learning curves of three loss functions,                L true, Linvand and Lnoisy, over iterations on Chinese. English. We perform an ablation on the Chinese. translation to under-stand the importance of these loss functions by. choosing AST lexicals as an example. Source zhongguo dianzi yinhang yewu guanli xingui jiangyu sanyue yiri qi shixing.reference chinas new management rules for e-banking operations to take effect on march 1. New rules for business administration of china s electronic banking industry. will come into effect on March 1. NEW regulations for the business administrations of the chinese electronics. bank will come in effect on the same day.\n",
            "\n",
            "Summary for 5 Related Work:\n",
            "Adversarial Learning Generative AdversarialNetwork (GAN) and its related derivative have been widely applied in computer vision. Previous work has constructed adversarial examples to at-                tack trained networks and make networks resist them. We do not resort to any complicated models to generateperturbed data and do not depend on extra mono-                lingual or bilingual corpora. In NMT, there is a number of work that aug-                ments the training data with monolingual corpora or bilingual Corpora of other language pairs. We don't need to use complicated models for adversarial learning, we just need to know how to use them to train networks. We also don't have to use complex models to teach networks how to deal with adversarial data. We just need the ability to learn from the data to make networks resistant to adversarial attacks. We can do this through trans-                ferring knowledge from bilingual and monolingually-speaking corpora, or by using other language-pair-based models.\n",
            "\n",
            "Summary for 6 Conclusion:\n",
            "Yang Liu and his team have developed a training framework to improve translation performance. The training framework is not limited to spe-                cic perturbation types. It is also necessary to validate our approach on more advanced NMT architectures, such as CNN-based NMTs and Transformer. The project is supported by the National Key R&D Program of China and the Prime Ministers Ofce, Singapore under IRC@Singapore Funding Initiative. For more information on the project, visit the NExT++ project website or go to: http://www.next++project.org/NExT ++Project.html. For confidential support, call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or click here. For support in the U.S., call the National Suicide Prevention Lifeline on 1-800-273-8255 or visit www.suicidepreventionlifeline.org. For help in the UK, contact Samaritans.org on 0300 123 90 90 or visit their website.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "import spacy\n",
        "\n",
        "# Load spaCy English model with word embeddings\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "def extract_sentences_from_sections(sections):\n",
        "    section_sentences = {}\n",
        "\n",
        "    for idx, text in enumerate(sections):\n",
        "        # Use spaCy to extract sentences\n",
        "        doc = nlp(text)\n",
        "\n",
        "        # Extract individual sentences\n",
        "        sentences = [sent.text for sent in doc.sents]\n",
        "\n",
        "        # Store sentences in the dictionary\n",
        "        section_sentences[f\"Section {idx + 1}\"] = sentences\n",
        "\n",
        "    return section_sentences\n",
        "\n",
        "def extract_section_name(section_text):\n",
        "    section_name = section_text.split('\\n')[0].strip()\n",
        "    return section_name\n",
        "\n",
        "def summarize_sentences(sentences, max_summary_length=1000):\n",
        "    # Concatenate selected sentences\n",
        "    concatenated_text = ' '.join(sentences)\n",
        "\n",
        "    # Encode and generate summary\n",
        "    inputs = tokenizer.encode(\"summarize: \" + concatenated_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=max_summary_length, min_length=int(max_summary_length/5),\n",
        "                                 length_penalty=10.0, num_beams=4, early_stopping=True)\n",
        "\n",
        "    # Decode and return the summary\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "def select_top_sentences(section_sentences, num_top_sentences=5):\n",
        "    # Sort sentences by some criterion (e.g., semantic similarity, importance, etc.)\n",
        "    # Here, we simply sort by length for demonstration purposes\n",
        "    sorted_sentences = sorted(section_sentences, key=len, reverse=True)\n",
        "\n",
        "    # Select the top sentences\n",
        "    top_sentences = sorted_sentences[:num_top_sentences]\n",
        "\n",
        "    return top_sentences\n",
        "\n",
        "# Extract sentences from sections\n",
        "section_sentences = extract_sentences_from_sections(section_extraction)\n",
        "\n",
        "# Generate summaries for each section based on semantic similarity\n",
        "section_summaries = {}\n",
        "for section, sentences in section_sentences.items():\n",
        "    # Extract the section name using the heuristic\n",
        "    section_name = extract_section_name('\\n'.join(sentences))\n",
        "\n",
        "    # Select the top sentences based on some criterion\n",
        "    top_sentences = select_top_sentences(sentences, num_top_sentences=5)\n",
        "\n",
        "    # Generate summary for the selected sentences\n",
        "    section_summary = summarize_sentences(top_sentences)\n",
        "\n",
        "    # Store the section summary\n",
        "    section_summaries[section_name] = section_summary\n",
        "\n",
        "    # Print the section summary with the section name\n",
        "    print(f\"Summary for {section_name}:\\n{section_summary}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzDuTuGTd-6S",
        "outputId": "c556490b-78c0-4407-e330-88f094acb1cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity score with 'Abstract' using summaries from BART: 0.15517288448251548\n",
            "Similarity score with '1 Introduction' using summaries from BART: 0.15341141561162125\n",
            "Similarity score with '2 Background' using summaries from BART: 0.11785113019775796\n",
            "Similarity score with '3 Approach' using summaries from BART: 0.060858061945018464\n",
            "Similarity score with '4 Experiments' using summaries from BART: 0.06274558051381587\n",
            "Similarity score with '5 Related Work' using summaries from BART: 0.0897122608032513\n",
            "Similarity score with '6 Conclusion' using summaries from BART: 0.05063696835418335\n"
          ]
        }
      ],
      "source": [
        "# Define your query\n",
        "query = \"Neural Machine Translation; Attention Mechanism, Language Translation.\"\n",
        "\n",
        "# Calculate similarity with each section header\n",
        "similarity_scores = {}\n",
        "for section, summary in section_summaries.items():\n",
        "    # Calculate similarity score between the summary and the query\n",
        "    similarity_score = text_similarity(summary, query)\n",
        "\n",
        "    # Store the similarity score for each section\n",
        "    similarity_scores[section] = similarity_score\n",
        "\n",
        "# Display similarity scores\n",
        "for section, score in similarity_scores.items():\n",
        "    print(f\"Similarity score with '{section}' using summaries from BART: {score}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XOjPXPcpbl5",
        "outputId": "dd51a51c-7fbb-44f7-d5f7-d08d47bbdf06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average similarity score for the query 'Neural Machine Translation; Attention Mechanism, Language Translation.': 0.09862690027259481\n"
          ]
        }
      ],
      "source": [
        "# Calculate the average similarity score\n",
        "total_similarity_score = sum(similarity_scores.values())\n",
        "average_similarity_score = total_similarity_score / len(similarity_scores)\n",
        "\n",
        "print(f\"Average similarity score for the query '{query}': {average_similarity_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HevIkBiVpq5N",
        "outputId": "6eaf6a28-71e8-45c9-d300-36bb33940eac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------+-------------------------+\n",
            "|          Section          | Similarity Score (BART) |\n",
            "+---------------------------+-------------------------+\n",
            "|          Abstract         |         0.155173        |\n",
            "|       1 Introduction      |         0.153411        |\n",
            "|        2 Background       |         0.117851        |\n",
            "|         3 Approach        |         0.060858        |\n",
            "|       4 Experiments       |         0.062746        |\n",
            "|       5 Related Work      |         0.089712        |\n",
            "|        6 Conclusion       |         0.050637        |\n",
            "| Average Similarity (BART) |         0.098627        |\n",
            "+---------------------------+-------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Calculate the average similarity score for BART summaries\n",
        "average_similarity_bart = sum(similarity_scores.values()) / len(similarity_scores)\n",
        "\n",
        "# Table for similarity score of sections with top ranked sentences\n",
        "table_combined = PrettyTable()\n",
        "table_combined.field_names = [\"Section\", \"Similarity Score (BART)\"]\n",
        "\n",
        "# Add similarity scores from BART summaries to the table\n",
        "for section, score in similarity_scores.items():\n",
        "    table_combined.add_row([section, f\"{score:.6f}\"])\n",
        "\n",
        "# Add the average similarity score for BART summaries to the table\n",
        "table_combined.add_row([\"Average Similarity (BART)\", f\"{average_similarity_bart:.6f}\"])\n",
        "\n",
        "# Print the table\n",
        "print(table_combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QhsqkUhd-9P",
        "outputId": "b443fbfd-fb74-44d2-beb3-b937eea2fbfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scores for Section 'Abstract' (BART-Generated Summaries):\n",
            "BLEU Score: 0.1551165129197201\n",
            "METEOR Score: 0.39366334394069474\n",
            "ROUGE-1 F-measure: 0.49382716049382713\n",
            "ROUGE-2 F-measure: 0.22406639004149378\n",
            "ROUGE-L F-measure: 0.35390946502057613\n",
            "\n",
            "Scores for Section '1 Introduction' (BART-Generated Summaries):\n",
            "BLEU Score: 0.061805111645554335\n",
            "METEOR Score: 0.2881513286726028\n",
            "ROUGE-1 F-measure: 0.4075471698113208\n",
            "ROUGE-2 F-measure: 0.12927756653992395\n",
            "ROUGE-L F-measure: 0.23396226415094337\n",
            "\n",
            "Scores for Section '2 Background' (BART-Generated Summaries):\n",
            "BLEU Score: 0.10118466532025051\n",
            "METEOR Score: 0.3021960805378741\n",
            "ROUGE-1 F-measure: 0.435483870967742\n",
            "ROUGE-2 F-measure: 0.13821138211382114\n",
            "ROUGE-L F-measure: 0.23387096774193553\n",
            "\n",
            "Scores for Section '3 Approach' (BART-Generated Summaries):\n",
            "BLEU Score: 0.03210590969309506\n",
            "METEOR Score: 0.303743963127016\n",
            "ROUGE-1 F-measure: 0.4152542372881356\n",
            "ROUGE-2 F-measure: 0.13675213675213677\n",
            "ROUGE-L F-measure: 0.1864406779661017\n",
            "\n",
            "Scores for Section '4 Experiments' (BART-Generated Summaries):\n",
            "BLEU Score: 0.005243083517368183\n",
            "METEOR Score: 0.14982291034203601\n",
            "ROUGE-1 F-measure: 0.2\n",
            "ROUGE-2 F-measure: 0.017543859649122806\n",
            "ROUGE-L F-measure: 0.10434782608695652\n",
            "\n",
            "Scores for Section '5 Related Work' (BART-Generated Summaries):\n",
            "BLEU Score: 0.08176327385724026\n",
            "METEOR Score: 0.3729250284921461\n",
            "ROUGE-1 F-measure: 0.4112903225806452\n",
            "ROUGE-2 F-measure: 0.11382113821138211\n",
            "ROUGE-L F-measure: 0.25806451612903225\n",
            "\n",
            "Scores for Section '6 Conclusion' (BART-Generated Summaries):\n",
            "BLEU Score: 0.015846018245388737\n",
            "METEOR Score: 0.22045700844943802\n",
            "ROUGE-1 F-measure: 0.25833333333333336\n",
            "ROUGE-2 F-measure: 0.025210084033613446\n",
            "ROUGE-L F-measure: 0.14166666666666666\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define reference summaries for each section\n",
        "reference_summaries = {\n",
        "    'Abstract': \"introduces the challenge of input perturbations negatively affecting the intermediate representations and subsequently impacting the translation quality of Neural Machine Translation (NMT) models. The proposed solution in the paper is adversarial stability training, aimed at enhancing the robustness of NMT models. The core concept involves making both the encoder and decoder of NMT models resilient to input perturbations, ensuring similar behavior for both the original input and its perturbed counterpart. The experimental findings, conducted on Chinese-English, English-German, and English-French translation tasks, demonstrate that the proposed approaches not only outperform strong NMT systems but also enhance the overall robustness of NMT models.\",\n",
        "    '1 Introduction': \"the progress of Neural Machine Translation (NMT) models in learning representations through a unified neural network. Despite their success, the paper addresses the non-robustness of NMT models, showcasing a critical problem through an example where replacing a word with its synonym leads to significant translation errors. The analogy of the butterfly effect is used to illustrate how small input changes can cause drastic alterations in the output. An investigation involving synonym replacements in a test set demonstrates that 69.74% of translations are altered, and the BLEU score drops to 79.01, emphasizing the models' sensitivity to small input perturbations. This sensitivity limits the applicability of NMT models to tasks requiring robust performance on noisy inputs.\",\n",
        "    '2 Background': \"The provided text describes the standard Neural Machine Translation (NMT) framework, emphasizing its end-to-end nature that optimizes the translation probability from a source sentence (x) to a target sentence (y). The model includes an encoder, which converts the source sentence into hidden representations (Hx), and a decoder, generating target words based on these representations. The training objective involves minimizing the negative log-likelihood of the training corpus. However, due to the vulnerability of deep neural networks, small input perturbations significantly impact translation results. To address this, the paper proposes an adversarial stability training approach, aiming to enhance the robustness of encoder representations against noisy perturbations. The architecture involves a discriminator and perturbations to achieve this stability.\",\n",
        "    '3 Approach': \"The proposed approach focuses on maintaining consistent behaviors in the NMT model for both the source sentence (x) and its perturbed counterpart (x0). The encoder and decoder are trained to be perturbation-invariant, ensuring that small changes in input do not significantly affect the translation output. The architecture involves constructing perturbed sentences from the source sentence and introducing two additional objectives: Linv encourages the encoder to output similar representations for x and x0, while Lnoisy guides the decoder to generate output y given the noisy input x0. The training objective combines these objectives with the original translation task, promoting both stability and good translation performance.\",\n",
        "    '4 Experiments': \"The evaluation of adversarial stability training was conducted on translation tasks for various language pairs, with 4-gram BLEU scores reported. For Chinese-English, the LDC corpus with 1.25M sentence pairs was used, and the NIST datasets served as test sets. English-German utilized the WMT 14 corpus, and English-French employed the IWSLT corpus, collected from TED talks, to assess non-normative text. The baseline system was an in-house NMT model with a two-layer RNN architecture, GRU gating mechanism, layer normalization, and dropout. Adversarial stability training involved lexical-level and feature-level perturbations, denoted as ASTlexical and ASTfeature. \",\n",
        "    '5 Related Work': \"In the realm of adversarial learning, the influence of Generative Adversarial Networks (GAN) and its derivatives has been extensive in computer vision and natural language processing. While prior work has used adversarial examples to attack and defend networks, the proposed adversarial stability training distinctively aims to stabilize both the encoder and decoder in NMT models. This approach utilizes adversarial learning to achieve a perturbation-invariant encoder. In the context of data augmentation, numerous methods have sought to enhance the robustness of NMT models by augmenting training data with monolingual corpora.\",\n",
        "    '6 Conclusion': \"The proposed adversarial stability training aims to enhance the robustness of NMT models by training both the encoder and decoder to handle input perturbations consistently. Two approaches for constructing perturbed data are introduced to adversarially train the encoder and stabilize the decoder. Experimental results on Chinese-English, English-German, and English-French translation tasks demonstrate that the proposed approach effectively improves both robustness and translation performance. To broaden the applicability, further evaluations are suggested in the context of natural noise present in practical applications, such as homonyms in simultaneous translation systems.\"\n",
        "}\n",
        "\n",
        "# Update reference_summaries keys to match the format in generated_summaries_bart\n",
        "updated_reference_summaries = {f\"Section {idx + 1}\": summary for idx, summary in enumerate(reference_summaries.values())}\n",
        "\n",
        "# Function to calculate scores for a section\n",
        "def calculate_scores_for_section(reference, hypothesis):\n",
        "    reference_tokens = word_tokenize(reference)\n",
        "    hypothesis_tokens = word_tokenize(hypothesis)\n",
        "\n",
        "    smoothing_function = SmoothingFunction().method1  # Define smoothing function\n",
        "    bleu_score = sentence_bleu([reference_tokens], hypothesis_tokens, smoothing_function=smoothing_function)\n",
        "    meteor_score_val = meteor_score.meteor_score([reference_tokens], hypothesis_tokens)\n",
        "\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = scorer.score(reference, hypothesis)\n",
        "    rouge1 = rouge_scores['rouge1'].fmeasure\n",
        "    rouge2 = rouge_scores['rouge2'].fmeasure\n",
        "    rougel = rouge_scores['rougeL'].fmeasure\n",
        "\n",
        "    return bleu_score, meteor_score_val, rouge1, rouge2, rougel\n",
        "\n",
        "# Example text 2\n",
        "generated_summary = section_summaries  # Use section summaries generated by BART\n",
        "\n",
        "# Calculate scores for each section using BART-generated summaries\n",
        "scores_bart_generated = {}\n",
        "\n",
        "for section, summary in generated_summary.items():\n",
        "    section_text = summary  # Use the summary directly\n",
        "\n",
        "    # Use the corresponding reference summary for each section\n",
        "    reference_summary_for_section = reference_summaries[section]\n",
        "\n",
        "    bleu_score, meteor_score_val, rouge1, rouge2, rougel = calculate_scores_for_section(reference_summary_for_section, section_text)\n",
        "\n",
        "    scores_bart_generated[section] = {\n",
        "        'BLEU Score': bleu_score,\n",
        "        'METEOR Score': meteor_score_val,\n",
        "        'ROUGE-1 F-measure': rouge1,\n",
        "        'ROUGE-2 F-measure': rouge2,\n",
        "        'ROUGE-L F-measure': rougel\n",
        "    }\n",
        "\n",
        "# Display scores for each section using BART-generated summaries\n",
        "for section, scores in scores_bart_generated.items():\n",
        "    print(f\"Scores for Section '{section}' (BART-Generated Summaries):\")\n",
        "    for metric, value in scores.items():\n",
        "        print(f\"{metric}: {value}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwoE-mrTd-_5",
        "outputId": "bd50a8e8-f911-4fe2-949a-5538744530f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------+------------------+\n",
            "|         Section          | Similarity Score |\n",
            "+--------------------------+------------------+\n",
            "|         Abstract         |     0.219694     |\n",
            "|      1 Introduction      |     0.150997     |\n",
            "|       2 Background       |     0.058666     |\n",
            "|        3 Approach        |     0.000000     |\n",
            "|      4 Experiments       |     0.099015     |\n",
            "|      5 Related Work      |     0.081650     |\n",
            "|       6 Conclusion       |     0.000000     |\n",
            "| Average Similarity (LSA) |     0.087146     |\n",
            "+--------------------------+------------------+\n",
            "\n",
            "\n",
            "+---------------------------+-------------------------+\n",
            "|          Section          | Similarity Score (BART) |\n",
            "+---------------------------+-------------------------+\n",
            "|          Abstract         |         0.155173        |\n",
            "|       1 Introduction      |         0.153411        |\n",
            "|        2 Background       |         0.117851        |\n",
            "|         3 Approach        |         0.060858        |\n",
            "|       4 Experiments       |         0.062746        |\n",
            "|       5 Related Work      |         0.089712        |\n",
            "|        6 Conclusion       |         0.050637        |\n",
            "| Average Similarity (BART) |         0.098627        |\n",
            "+---------------------------+-------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Calculate average similarity score for top-ranked sentences of LSA\n",
        "average_similarity_top_ranked = sum(similarity_scores_top_ranked.values()) / len(similarity_scores_top_ranked)\n",
        "\n",
        "# Table for similarity score of sections with top ranked sentences of LSA\n",
        "table_top_ranked = PrettyTable()\n",
        "table_top_ranked.field_names = [\"Section\", \"Similarity Score\"]\n",
        "\n",
        "for section, score in similarity_scores_top_ranked.items():\n",
        "    table_top_ranked.add_row([section, f\"{score:.6f}\"])\n",
        "\n",
        "# Add average similarity score for top-ranked sentences of LSA to the table\n",
        "table_top_ranked.add_row([\"Average Similarity (LSA)\", f\"{average_similarity_top_ranked:.6f}\"])\n",
        "\n",
        "# Calculate average similarity score for BART summaries\n",
        "average_similarity_bart = sum(similarity_scores.values()) / len(similarity_scores)\n",
        "\n",
        "# Table for similarity score of sections with BART summaries\n",
        "table_combined = PrettyTable()\n",
        "table_combined.field_names = [\"Section\", \"Similarity Score (BART)\"]\n",
        "\n",
        "# Add similarity scores from BART summaries to the table\n",
        "for section, score in similarity_scores.items():\n",
        "    table_combined.add_row([section, f\"{score:.6f}\"])\n",
        "\n",
        "# Add the average similarity score for BART summaries to the table\n",
        "table_combined.add_row([\"Average Similarity (BART)\", f\"{average_similarity_bart:.6f}\"])\n",
        "\n",
        "# Print the tables\n",
        "print(table_top_ranked)\n",
        "print(\"\\n\")  # Separate the tables with a newline\n",
        "print(table_combined)\n",
        "\n",
        "# Write tables to CSV file\n",
        "with open('lsa_scores.csv', 'w') as file:\n",
        "    file.write(str(table_top_ranked))\n",
        "    file.write(\"\\n\\n\")  # Add a newline between the tables\n",
        "    file.write(str(table_combined))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W34scMod2RkW"
      },
      "source": [
        "### Converting the similarity output into a Python package, Convert and show into CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ScSL3-is0UR"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Save tables to CSV file\n",
        "csv_file_path = 'output.csv'\n",
        "with open(csv_file_path, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the top-ranked sentences table\n",
        "    writer.writerow(['Table for LSA'])\n",
        "    writer.writerow(['Section', 'Similarity Score(LSA)'])\n",
        "    writer.writerow(['Title',f\"{similarity_score_tfidf:.6f}\"])\n",
        "    for section, score in similarity_scores_top_ranked.items():\n",
        "        writer.writerow([section, f\"{score:.6f}\"])\n",
        "    writer.writerow([\"Average Similarity (LSA)\", f\"{average_similarity_top_ranked:.6f}\"])\n",
        "    writer.writerow([])\n",
        "\n",
        "    # Write the BART summaries table\n",
        "    writer.writerow(['Table for BART summaries'])\n",
        "    writer.writerow(['Section', 'Similarity Score (BART)'])\n",
        "    for section, score in similarity_scores.items():\n",
        "        writer.writerow([section, f\"{score:.6f}\"])\n",
        "    writer.writerow([\"Average Similarity (BART)\", f\"{average_similarity_bart:.6f}\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o388bGGp2RkX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "001fbb24fb174287a626b59746db20a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "084d950233944c23969c6149d0ba3339": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b732b5efa06c40919ec56e32615001dd",
              "IPY_MODEL_3d7504dd6bc84023bf4146d2ef9dd943",
              "IPY_MODEL_f6c970d581f64eb384314aea681e7fab"
            ],
            "layout": "IPY_MODEL_16fc798327944ed48a61a92abe428cfb"
          }
        },
        "0a0838f5f5074777ab8aa36090b3c4b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6955e5406d54c428d924b7ee11e9fa6",
            "placeholder": "​",
            "style": "IPY_MODEL_9d8408c03a17455a853f8260df5262d8",
            "value": " 456k/456k [00:00&lt;00:00, 31.7MB/s]"
          }
        },
        "0e71d683940046a98f708eb322b27c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50d2845af39d453cab95402dcd29a320",
            "placeholder": "​",
            "style": "IPY_MODEL_ae25132809e8489cb0023a85d70b51db",
            "value": "tokenizer.json: 100%"
          }
        },
        "13c8700811ac4085b4b4bc0a6e2d1fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f88ca7783c0e4cf1b8c48416954be9fa",
              "IPY_MODEL_503ad6c38a36404187e603bb7c19f09a",
              "IPY_MODEL_d24312bd58cd46f8bd67dcad7f7c0abf"
            ],
            "layout": "IPY_MODEL_78f738debafb41e187df36fb0c0dd95d"
          }
        },
        "16fc798327944ed48a61a92abe428cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18d0ac2e72834627a029b72014658dff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1925738060e143b59d6fe2fe410180d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "234432e1ecde44b6896e79f59b131212": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18d0ac2e72834627a029b72014658dff",
            "max": 1585,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba1a3da3d58448329ae51cf22bdec942",
            "value": 1585
          }
        },
        "25f6229d98da414b823619208c126971": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "271215ea98e14dbd87dda26c91c80570": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33bea5a6f1d8476fbadd9a31c3c19b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39b237685f0349c793aa174031b713e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b66b37c69a34bad88b1883b7c427c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca864117c4954faf810cb7dcd46f6ef8",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25f6229d98da414b823619208c126971",
            "value": 898823
          }
        },
        "3d7504dd6bc84023bf4146d2ef9dd943": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3c815cec1c746d99ba87b4301b28533",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6d3087d159c47e091c84b68f8445909",
            "value": 363
          }
        },
        "3dcec7100df8494f86b40ae9a0c9c5be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a240eee2bb2247e28fb277c3a21d6d94",
              "IPY_MODEL_3b66b37c69a34bad88b1883b7c427c5c",
              "IPY_MODEL_eb79129176a04e588a91d6af832dc102"
            ],
            "layout": "IPY_MODEL_c61875b24178469da8f5d981e40757f6"
          }
        },
        "503ad6c38a36404187e603bb7c19f09a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3d7fb2ae6d5443c8ce9fdd86efa9dc5",
            "max": 1625222120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab010386bdbc49d390b6c6f38748ecf9",
            "value": 1625222120
          }
        },
        "50d2845af39d453cab95402dcd29a320": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53a2c605aa6c48d9a477640d8ab6a626": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c5baf9354404c5797ea71382dd6dd9e",
              "IPY_MODEL_234432e1ecde44b6896e79f59b131212",
              "IPY_MODEL_e927c13aa3f3435b99246d971b9eb991"
            ],
            "layout": "IPY_MODEL_e4cae05ffe9c40af91e0355ca9270144"
          }
        },
        "54f7ddaf3bfc4167ad9f79e9532c97d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "553a9003a69b4d109ef45320eb42ade8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5572a83ddb46419288be031db81905a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b540e3b6d3f404392c6666206c73fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f6eabe89e2b4644abdb802cc0586344": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63a5e3ff7c0841afb02c1adaf939f021": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f79848242864262ab5327db8e225ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95f08c1da9d541978379c85a79fcf787",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b540e3b6d3f404392c6666206c73fff",
            "value": 1355863
          }
        },
        "78f738debafb41e187df36fb0c0dd95d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79f7cf49f34f43e0ba5d34c24e16eb79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b142f541b674f39943fdb608eb6b609": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7be6b2658dda4252b5736fa498de47c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf993f82b629477eb717c69578269dc9",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_271215ea98e14dbd87dda26c91c80570",
            "value": 456318
          }
        },
        "7c62e52a054c45138e2367760436292f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "886bc3ebb2db481b82a47a18e3e665f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e71d683940046a98f708eb322b27c17",
              "IPY_MODEL_6f79848242864262ab5327db8e225ca5",
              "IPY_MODEL_8cbbe888ba9149a7b1f63c151d72b221"
            ],
            "layout": "IPY_MODEL_63a5e3ff7c0841afb02c1adaf939f021"
          }
        },
        "8cbbe888ba9149a7b1f63c151d72b221": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5572a83ddb46419288be031db81905a0",
            "placeholder": "​",
            "style": "IPY_MODEL_553a9003a69b4d109ef45320eb42ade8",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 2.77MB/s]"
          }
        },
        "8daabe287199404d8312c4a4a16ab776": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f71244c651c4845b6097977ef57ae7a",
              "IPY_MODEL_7be6b2658dda4252b5736fa498de47c1",
              "IPY_MODEL_0a0838f5f5074777ab8aa36090b3c4b7"
            ],
            "layout": "IPY_MODEL_bb4dbb1612a34e078da04d9f6bc30499"
          }
        },
        "8f71244c651c4845b6097977ef57ae7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f6eabe89e2b4644abdb802cc0586344",
            "placeholder": "​",
            "style": "IPY_MODEL_b0e4082b87924dbd95ac77971cc1c469",
            "value": "merges.txt: 100%"
          }
        },
        "928fd9a7d22343868a3e4d7ac1894b3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95f08c1da9d541978379c85a79fcf787": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c5baf9354404c5797ea71382dd6dd9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_001fbb24fb174287a626b59746db20a8",
            "placeholder": "​",
            "style": "IPY_MODEL_9c5f66606e914a438b83021c9d92e528",
            "value": "config.json: 100%"
          }
        },
        "9c5f66606e914a438b83021c9d92e528": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d8408c03a17455a853f8260df5262d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e8f07b07ff1446a9870b495e53bc5d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a240eee2bb2247e28fb277c3a21d6d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1925738060e143b59d6fe2fe410180d6",
            "placeholder": "​",
            "style": "IPY_MODEL_a8410f78c7dd430c9ab5492474dd484e",
            "value": "vocab.json: 100%"
          }
        },
        "a6955e5406d54c428d924b7ee11e9fa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8410f78c7dd430c9ab5492474dd484e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab010386bdbc49d390b6c6f38748ecf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae25132809e8489cb0023a85d70b51db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0e4082b87924dbd95ac77971cc1c469": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4ade3c36eec40ac8f2e561dd49f782e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b732b5efa06c40919ec56e32615001dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54f7ddaf3bfc4167ad9f79e9532c97d9",
            "placeholder": "​",
            "style": "IPY_MODEL_33bea5a6f1d8476fbadd9a31c3c19b28",
            "value": "generation_config.json: 100%"
          }
        },
        "ba1a3da3d58448329ae51cf22bdec942": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb4dbb1612a34e078da04d9f6bc30499": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd184e8978ff4e478dbc55b7913db520": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf993f82b629477eb717c69578269dc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c61875b24178469da8f5d981e40757f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca864117c4954faf810cb7dcd46f6ef8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd4dc2877e6b4476933f30a9c85dd505": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d24312bd58cd46f8bd67dcad7f7c0abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_928fd9a7d22343868a3e4d7ac1894b3d",
            "placeholder": "​",
            "style": "IPY_MODEL_bd184e8978ff4e478dbc55b7913db520",
            "value": " 1.63G/1.63G [00:21&lt;00:00, 267MB/s]"
          }
        },
        "e3122766de1040108c7ec4d21fa1b4e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4cae05ffe9c40af91e0355ca9270144": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d3087d159c47e091c84b68f8445909": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e927c13aa3f3435b99246d971b9eb991": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c62e52a054c45138e2367760436292f",
            "placeholder": "​",
            "style": "IPY_MODEL_b4ade3c36eec40ac8f2e561dd49f782e",
            "value": " 1.58k/1.58k [00:00&lt;00:00, 49.2kB/s]"
          }
        },
        "eb79129176a04e588a91d6af832dc102": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e8f07b07ff1446a9870b495e53bc5d5",
            "placeholder": "​",
            "style": "IPY_MODEL_e3122766de1040108c7ec4d21fa1b4e7",
            "value": " 899k/899k [00:00&lt;00:00, 3.67MB/s]"
          }
        },
        "f3c815cec1c746d99ba87b4301b28533": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d7fb2ae6d5443c8ce9fdd86efa9dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6c970d581f64eb384314aea681e7fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b142f541b674f39943fdb608eb6b609",
            "placeholder": "​",
            "style": "IPY_MODEL_39b237685f0349c793aa174031b713e5",
            "value": " 363/363 [00:00&lt;00:00, 20.6kB/s]"
          }
        },
        "f88ca7783c0e4cf1b8c48416954be9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd4dc2877e6b4476933f30a9c85dd505",
            "placeholder": "​",
            "style": "IPY_MODEL_79f7cf49f34f43e0ba5d34c24e16eb79",
            "value": "model.safetensors: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
